{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_T2LCfAN_XF"
   },
   "source": [
    "### Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K1li4zpPN_XH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import display\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0t7965zN_XH"
   },
   "source": [
    "Panda Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "brXljTxkN_XI"
   },
   "outputs": [],
   "source": [
    "# Set options for displaying maximum columns and rows\n",
    "pd.set_option('display.max_columns', None)  \n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoPy7wczN_XI"
   },
   "source": [
    "**Read CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YM-QslAnN_XI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (6,7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id.orig_h</th>\n",
       "      <th>id.orig_p</th>\n",
       "      <th>id.resp_h</th>\n",
       "      <th>id.resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>local_orig</th>\n",
       "      <th>local_resp</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>history</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>tunnel_parents</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>fwd_header_size_max</th>\n",
       "      <th>bwd_header_size_tot</th>\n",
       "      <th>bwd_header_size_min</th>\n",
       "      <th>bwd_header_size_max</th>\n",
       "      <th>flow_FIN_flag_count</th>\n",
       "      <th>flow_SYN_flag_count</th>\n",
       "      <th>flow_RST_flag_count</th>\n",
       "      <th>fwd_PSH_flag_count</th>\n",
       "      <th>bwd_PSH_flag_count</th>\n",
       "      <th>flow_ACK_flag_count</th>\n",
       "      <th>fwd_URG_flag_count</th>\n",
       "      <th>bwd_URG_flag_count</th>\n",
       "      <th>flow_CWR_flag_count</th>\n",
       "      <th>flow_ECE_flag_count</th>\n",
       "      <th>fwd_pkts_payload.min</th>\n",
       "      <th>fwd_pkts_payload.max</th>\n",
       "      <th>fwd_pkts_payload.tot</th>\n",
       "      <th>fwd_pkts_payload.avg</th>\n",
       "      <th>fwd_pkts_payload.std</th>\n",
       "      <th>bwd_pkts_payload.min</th>\n",
       "      <th>bwd_pkts_payload.max</th>\n",
       "      <th>bwd_pkts_payload.tot</th>\n",
       "      <th>bwd_pkts_payload.avg</th>\n",
       "      <th>bwd_pkts_payload.std</th>\n",
       "      <th>flow_pkts_payload.min</th>\n",
       "      <th>flow_pkts_payload.max</th>\n",
       "      <th>flow_pkts_payload.tot</th>\n",
       "      <th>flow_pkts_payload.avg</th>\n",
       "      <th>flow_pkts_payload.std</th>\n",
       "      <th>fwd_iat.min</th>\n",
       "      <th>fwd_iat.max</th>\n",
       "      <th>fwd_iat.tot</th>\n",
       "      <th>fwd_iat.avg</th>\n",
       "      <th>fwd_iat.std</th>\n",
       "      <th>bwd_iat.min</th>\n",
       "      <th>bwd_iat.max</th>\n",
       "      <th>bwd_iat.tot</th>\n",
       "      <th>bwd_iat.avg</th>\n",
       "      <th>bwd_iat.std</th>\n",
       "      <th>flow_iat.min</th>\n",
       "      <th>flow_iat.max</th>\n",
       "      <th>flow_iat.tot</th>\n",
       "      <th>flow_iat.avg</th>\n",
       "      <th>flow_iat.std</th>\n",
       "      <th>payload_bytes_per_second</th>\n",
       "      <th>fwd_subflow_pkts</th>\n",
       "      <th>bwd_subflow_pkts</th>\n",
       "      <th>fwd_subflow_bytes</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>fwd_bulk_bytes</th>\n",
       "      <th>bwd_bulk_bytes</th>\n",
       "      <th>fwd_bulk_packets</th>\n",
       "      <th>bwd_bulk_packets</th>\n",
       "      <th>fwd_bulk_rate</th>\n",
       "      <th>bwd_bulk_rate</th>\n",
       "      <th>active.min</th>\n",
       "      <th>active.max</th>\n",
       "      <th>active.tot</th>\n",
       "      <th>active.avg</th>\n",
       "      <th>active.std</th>\n",
       "      <th>idle.min</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>traffic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.10.10.252</td>\n",
       "      <td>33540</td>\n",
       "      <td>224.0.0.251</td>\n",
       "      <td>5353</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>S0</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>arpspoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.10.10.252</td>\n",
       "      <td>50435</td>\n",
       "      <td>224.0.0.251</td>\n",
       "      <td>5353</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>S0</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>arpspoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.10.10.252</td>\n",
       "      <td>47976</td>\n",
       "      <td>224.0.0.251</td>\n",
       "      <td>5353</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>S0</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>arpspoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.10.10.252</td>\n",
       "      <td>37995</td>\n",
       "      <td>10.10.10.0</td>\n",
       "      <td>137</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>S0</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>arpspoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.10.10.252</td>\n",
       "      <td>38680</td>\n",
       "      <td>224.0.0.251</td>\n",
       "      <td>5353</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>S0</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>arpspoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325373</th>\n",
       "      <td>42.32.107.34</td>\n",
       "      <td>32572</td>\n",
       "      <td>148.94.193.65</td>\n",
       "      <td>52545</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>OTH</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>camoverflow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325374</th>\n",
       "      <td>101.16.71.87</td>\n",
       "      <td>24711</td>\n",
       "      <td>140.132.36.68</td>\n",
       "      <td>64950</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>OTH</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>camoverflow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325375</th>\n",
       "      <td>180.167.106.59</td>\n",
       "      <td>42487</td>\n",
       "      <td>233.22.169.101</td>\n",
       "      <td>42090</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>OTH</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>camoverflow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325376</th>\n",
       "      <td>233.188.148.20</td>\n",
       "      <td>60383</td>\n",
       "      <td>198.201.14.75</td>\n",
       "      <td>61891</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>OTH</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>camoverflow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325377</th>\n",
       "      <td>21.95.75.42</td>\n",
       "      <td>35597</td>\n",
       "      <td>79.22.74.54</td>\n",
       "      <td>59677</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>OTH</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>camoverflow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4325378 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id.orig_h  id.orig_p       id.resp_h  id.resp_p proto service  \\\n",
       "0          10.10.10.252      33540     224.0.0.251       5353   udp     dns   \n",
       "1          10.10.10.252      50435     224.0.0.251       5353   udp     dns   \n",
       "2          10.10.10.252      47976     224.0.0.251       5353   udp     dns   \n",
       "3          10.10.10.252      37995      10.10.10.0        137   udp     dns   \n",
       "4          10.10.10.252      38680     224.0.0.251       5353   udp     dns   \n",
       "...                 ...        ...             ...        ...   ...     ...   \n",
       "4325373    42.32.107.34      32572   148.94.193.65      52545   tcp       -   \n",
       "4325374    101.16.71.87      24711   140.132.36.68      64950   tcp       -   \n",
       "4325375  180.167.106.59      42487  233.22.169.101      42090   tcp       -   \n",
       "4325376  233.188.148.20      60383   198.201.14.75      61891   tcp       -   \n",
       "4325377     21.95.75.42      35597     79.22.74.54      59677   tcp       -   \n",
       "\n",
       "        duration orig_bytes resp_bytes conn_state local_orig local_resp  \\\n",
       "0              -          -          -         S0          T          F   \n",
       "1              -          -          -         S0          T          F   \n",
       "2              -          -          -         S0          T          F   \n",
       "3              -          -          -         S0          T          T   \n",
       "4              -          -          -         S0          T          F   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "4325373        -          -          -        OTH          F          F   \n",
       "4325374        -          -          -        OTH          F          F   \n",
       "4325375        -          -          -        OTH          F          F   \n",
       "4325376        -          -          -        OTH          F          F   \n",
       "4325377        -          -          -        OTH          F          F   \n",
       "\n",
       "         missed_bytes history  orig_pkts  orig_ip_bytes  resp_pkts  \\\n",
       "0                   0       D          1             73          0   \n",
       "1                   0       D          1             74          0   \n",
       "2                   0       D          1             57          0   \n",
       "3                   0       D          1             78          0   \n",
       "4                   0       D          1             67          0   \n",
       "...               ...     ...        ...            ...        ...   \n",
       "4325373             0       -          0              0          0   \n",
       "4325374             0       -          0              0          0   \n",
       "4325375             0       -          0              0          0   \n",
       "4325376             0       -          0              0          0   \n",
       "4325377             0       -          0              0          0   \n",
       "\n",
       "         resp_ip_bytes tunnel_parents  flow_duration  fwd_pkts_tot  \\\n",
       "0                    0              -            0.0             1   \n",
       "1                    0              -            0.0             1   \n",
       "2                    0              -            0.0             1   \n",
       "3                    0              -            0.0             1   \n",
       "4                    0              -            0.0             1   \n",
       "...                ...            ...            ...           ...   \n",
       "4325373              0              -            0.0             1   \n",
       "4325374              0              -            0.0             1   \n",
       "4325375              0              -            0.0             1   \n",
       "4325376              0              -            0.0             1   \n",
       "4325377              0              -            0.0             1   \n",
       "\n",
       "         bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  fwd_pkts_per_sec  \\\n",
       "0                   0                  1                  0               0.0   \n",
       "1                   0                  1                  0               0.0   \n",
       "2                   0                  1                  0               0.0   \n",
       "3                   0                  1                  0               0.0   \n",
       "4                   0                  1                  0               0.0   \n",
       "...               ...                ...                ...               ...   \n",
       "4325373             0                  0                  0               0.0   \n",
       "4325374             0                  0                  0               0.0   \n",
       "4325375             0                  0                  0               0.0   \n",
       "4325376             0                  0                  0               0.0   \n",
       "4325377             0                  0                  0               0.0   \n",
       "\n",
       "         bwd_pkts_per_sec  flow_pkts_per_sec  down_up_ratio  \\\n",
       "0                     0.0                0.0            0.0   \n",
       "1                     0.0                0.0            0.0   \n",
       "2                     0.0                0.0            0.0   \n",
       "3                     0.0                0.0            0.0   \n",
       "4                     0.0                0.0            0.0   \n",
       "...                   ...                ...            ...   \n",
       "4325373               0.0                0.0            0.0   \n",
       "4325374               0.0                0.0            0.0   \n",
       "4325375               0.0                0.0            0.0   \n",
       "4325376               0.0                0.0            0.0   \n",
       "4325377               0.0                0.0            0.0   \n",
       "\n",
       "         fwd_header_size_tot  fwd_header_size_min  fwd_header_size_max  \\\n",
       "0                          8                    8                    8   \n",
       "1                          8                    8                    8   \n",
       "2                          8                    8                    8   \n",
       "3                          8                    8                    8   \n",
       "4                          8                    8                    8   \n",
       "...                      ...                  ...                  ...   \n",
       "4325373                    0                    0                    0   \n",
       "4325374                    0                    0                    0   \n",
       "4325375                    0                    0                    0   \n",
       "4325376                    0                    0                    0   \n",
       "4325377                    0                    0                    0   \n",
       "\n",
       "         bwd_header_size_tot  bwd_header_size_min  bwd_header_size_max  \\\n",
       "0                          0                    0                    0   \n",
       "1                          0                    0                    0   \n",
       "2                          0                    0                    0   \n",
       "3                          0                    0                    0   \n",
       "4                          0                    0                    0   \n",
       "...                      ...                  ...                  ...   \n",
       "4325373                    0                    0                    0   \n",
       "4325374                    0                    0                    0   \n",
       "4325375                    0                    0                    0   \n",
       "4325376                    0                    0                    0   \n",
       "4325377                    0                    0                    0   \n",
       "\n",
       "         flow_FIN_flag_count  flow_SYN_flag_count  flow_RST_flag_count  \\\n",
       "0                          0                    0                    0   \n",
       "1                          0                    0                    0   \n",
       "2                          0                    0                    0   \n",
       "3                          0                    0                    0   \n",
       "4                          0                    0                    0   \n",
       "...                      ...                  ...                  ...   \n",
       "4325373                    0                    0                    0   \n",
       "4325374                    0                    0                    0   \n",
       "4325375                    0                    0                    0   \n",
       "4325376                    0                    0                    0   \n",
       "4325377                    0                    0                    0   \n",
       "\n",
       "         fwd_PSH_flag_count  bwd_PSH_flag_count  flow_ACK_flag_count  \\\n",
       "0                         0                   0                    0   \n",
       "1                         0                   0                    0   \n",
       "2                         0                   0                    0   \n",
       "3                         0                   0                    0   \n",
       "4                         0                   0                    0   \n",
       "...                     ...                 ...                  ...   \n",
       "4325373                   0                   0                    0   \n",
       "4325374                   0                   0                    0   \n",
       "4325375                   0                   0                    0   \n",
       "4325376                   0                   0                    0   \n",
       "4325377                   0                   0                    0   \n",
       "\n",
       "         fwd_URG_flag_count  bwd_URG_flag_count  flow_CWR_flag_count  \\\n",
       "0                         0                   0                    0   \n",
       "1                         0                   0                    0   \n",
       "2                         0                   0                    0   \n",
       "3                         0                   0                    0   \n",
       "4                         0                   0                    0   \n",
       "...                     ...                 ...                  ...   \n",
       "4325373                   0                   0                    0   \n",
       "4325374                   0                   0                    0   \n",
       "4325375                   0                   0                    0   \n",
       "4325376                   0                   0                    0   \n",
       "4325377                   0                   0                    0   \n",
       "\n",
       "         flow_ECE_flag_count  fwd_pkts_payload.min  fwd_pkts_payload.max  \\\n",
       "0                          0                  45.0                  45.0   \n",
       "1                          0                  46.0                  46.0   \n",
       "2                          0                  29.0                  29.0   \n",
       "3                          0                  50.0                  50.0   \n",
       "4                          0                  39.0                  39.0   \n",
       "...                      ...                   ...                   ...   \n",
       "4325373                    0                   0.0                   0.0   \n",
       "4325374                    0                   0.0                   0.0   \n",
       "4325375                    0                   0.0                   0.0   \n",
       "4325376                    0                   0.0                   0.0   \n",
       "4325377                    0                   0.0                   0.0   \n",
       "\n",
       "         fwd_pkts_payload.tot  fwd_pkts_payload.avg  fwd_pkts_payload.std  \\\n",
       "0                        45.0                  45.0                   0.0   \n",
       "1                        46.0                  46.0                   0.0   \n",
       "2                        29.0                  29.0                   0.0   \n",
       "3                        50.0                  50.0                   0.0   \n",
       "4                        39.0                  39.0                   0.0   \n",
       "...                       ...                   ...                   ...   \n",
       "4325373                   0.0                   0.0                   0.0   \n",
       "4325374                   0.0                   0.0                   0.0   \n",
       "4325375                   0.0                   0.0                   0.0   \n",
       "4325376                   0.0                   0.0                   0.0   \n",
       "4325377                   0.0                   0.0                   0.0   \n",
       "\n",
       "         bwd_pkts_payload.min  bwd_pkts_payload.max  bwd_pkts_payload.tot  \\\n",
       "0                         0.0                   0.0                   0.0   \n",
       "1                         0.0                   0.0                   0.0   \n",
       "2                         0.0                   0.0                   0.0   \n",
       "3                         0.0                   0.0                   0.0   \n",
       "4                         0.0                   0.0                   0.0   \n",
       "...                       ...                   ...                   ...   \n",
       "4325373                   0.0                   0.0                   0.0   \n",
       "4325374                   0.0                   0.0                   0.0   \n",
       "4325375                   0.0                   0.0                   0.0   \n",
       "4325376                   0.0                   0.0                   0.0   \n",
       "4325377                   0.0                   0.0                   0.0   \n",
       "\n",
       "         bwd_pkts_payload.avg  bwd_pkts_payload.std  flow_pkts_payload.min  \\\n",
       "0                         0.0                   0.0                   45.0   \n",
       "1                         0.0                   0.0                   46.0   \n",
       "2                         0.0                   0.0                   29.0   \n",
       "3                         0.0                   0.0                   50.0   \n",
       "4                         0.0                   0.0                   39.0   \n",
       "...                       ...                   ...                    ...   \n",
       "4325373                   0.0                   0.0                    0.0   \n",
       "4325374                   0.0                   0.0                    0.0   \n",
       "4325375                   0.0                   0.0                    0.0   \n",
       "4325376                   0.0                   0.0                    0.0   \n",
       "4325377                   0.0                   0.0                    0.0   \n",
       "\n",
       "         flow_pkts_payload.max  flow_pkts_payload.tot  flow_pkts_payload.avg  \\\n",
       "0                         45.0                   45.0                   45.0   \n",
       "1                         46.0                   46.0                   46.0   \n",
       "2                         29.0                   29.0                   29.0   \n",
       "3                         50.0                   50.0                   50.0   \n",
       "4                         39.0                   39.0                   39.0   \n",
       "...                        ...                    ...                    ...   \n",
       "4325373                    0.0                    0.0                    0.0   \n",
       "4325374                    0.0                    0.0                    0.0   \n",
       "4325375                    0.0                    0.0                    0.0   \n",
       "4325376                    0.0                    0.0                    0.0   \n",
       "4325377                    0.0                    0.0                    0.0   \n",
       "\n",
       "         flow_pkts_payload.std  fwd_iat.min  fwd_iat.max  fwd_iat.tot  \\\n",
       "0                          0.0          0.0          0.0          0.0   \n",
       "1                          0.0          0.0          0.0          0.0   \n",
       "2                          0.0          0.0          0.0          0.0   \n",
       "3                          0.0          0.0          0.0          0.0   \n",
       "4                          0.0          0.0          0.0          0.0   \n",
       "...                        ...          ...          ...          ...   \n",
       "4325373                    0.0          0.0          0.0          0.0   \n",
       "4325374                    0.0          0.0          0.0          0.0   \n",
       "4325375                    0.0          0.0          0.0          0.0   \n",
       "4325376                    0.0          0.0          0.0          0.0   \n",
       "4325377                    0.0          0.0          0.0          0.0   \n",
       "\n",
       "         fwd_iat.avg  fwd_iat.std  bwd_iat.min  bwd_iat.max  bwd_iat.tot  \\\n",
       "0                0.0          0.0          0.0          0.0          0.0   \n",
       "1                0.0          0.0          0.0          0.0          0.0   \n",
       "2                0.0          0.0          0.0          0.0          0.0   \n",
       "3                0.0          0.0          0.0          0.0          0.0   \n",
       "4                0.0          0.0          0.0          0.0          0.0   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "4325373          0.0          0.0          0.0          0.0          0.0   \n",
       "4325374          0.0          0.0          0.0          0.0          0.0   \n",
       "4325375          0.0          0.0          0.0          0.0          0.0   \n",
       "4325376          0.0          0.0          0.0          0.0          0.0   \n",
       "4325377          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "         bwd_iat.avg  bwd_iat.std  flow_iat.min  flow_iat.max  flow_iat.tot  \\\n",
       "0                0.0          0.0           0.0           0.0           0.0   \n",
       "1                0.0          0.0           0.0           0.0           0.0   \n",
       "2                0.0          0.0           0.0           0.0           0.0   \n",
       "3                0.0          0.0           0.0           0.0           0.0   \n",
       "4                0.0          0.0           0.0           0.0           0.0   \n",
       "...              ...          ...           ...           ...           ...   \n",
       "4325373          0.0          0.0           0.0           0.0           0.0   \n",
       "4325374          0.0          0.0           0.0           0.0           0.0   \n",
       "4325375          0.0          0.0           0.0           0.0           0.0   \n",
       "4325376          0.0          0.0           0.0           0.0           0.0   \n",
       "4325377          0.0          0.0           0.0           0.0           0.0   \n",
       "\n",
       "         flow_iat.avg  flow_iat.std  payload_bytes_per_second  \\\n",
       "0                 0.0           0.0                       0.0   \n",
       "1                 0.0           0.0                       0.0   \n",
       "2                 0.0           0.0                       0.0   \n",
       "3                 0.0           0.0                       0.0   \n",
       "4                 0.0           0.0                       0.0   \n",
       "...               ...           ...                       ...   \n",
       "4325373           0.0           0.0                       0.0   \n",
       "4325374           0.0           0.0                       0.0   \n",
       "4325375           0.0           0.0                       0.0   \n",
       "4325376           0.0           0.0                       0.0   \n",
       "4325377           0.0           0.0                       0.0   \n",
       "\n",
       "         fwd_subflow_pkts  bwd_subflow_pkts  fwd_subflow_bytes  \\\n",
       "0                     1.0               0.0               45.0   \n",
       "1                     1.0               0.0               46.0   \n",
       "2                     1.0               0.0               29.0   \n",
       "3                     1.0               0.0               50.0   \n",
       "4                     1.0               0.0               39.0   \n",
       "...                   ...               ...                ...   \n",
       "4325373               1.0               0.0                0.0   \n",
       "4325374               1.0               0.0                0.0   \n",
       "4325375               1.0               0.0                0.0   \n",
       "4325376               1.0               0.0                0.0   \n",
       "4325377               1.0               0.0                0.0   \n",
       "\n",
       "         bwd_subflow_bytes  fwd_bulk_bytes  bwd_bulk_bytes  fwd_bulk_packets  \\\n",
       "0                      0.0             0.0             0.0               0.0   \n",
       "1                      0.0             0.0             0.0               0.0   \n",
       "2                      0.0             0.0             0.0               0.0   \n",
       "3                      0.0             0.0             0.0               0.0   \n",
       "4                      0.0             0.0             0.0               0.0   \n",
       "...                    ...             ...             ...               ...   \n",
       "4325373                0.0             0.0             0.0               0.0   \n",
       "4325374                0.0             0.0             0.0               0.0   \n",
       "4325375                0.0             0.0             0.0               0.0   \n",
       "4325376                0.0             0.0             0.0               0.0   \n",
       "4325377                0.0             0.0             0.0               0.0   \n",
       "\n",
       "         bwd_bulk_packets  fwd_bulk_rate  bwd_bulk_rate  active.min  \\\n",
       "0                     0.0            0.0            0.0         0.0   \n",
       "1                     0.0            0.0            0.0         0.0   \n",
       "2                     0.0            0.0            0.0         0.0   \n",
       "3                     0.0            0.0            0.0         0.0   \n",
       "4                     0.0            0.0            0.0         0.0   \n",
       "...                   ...            ...            ...         ...   \n",
       "4325373               0.0            0.0            0.0         0.0   \n",
       "4325374               0.0            0.0            0.0         0.0   \n",
       "4325375               0.0            0.0            0.0         0.0   \n",
       "4325376               0.0            0.0            0.0         0.0   \n",
       "4325377               0.0            0.0            0.0         0.0   \n",
       "\n",
       "         active.max  active.tot  active.avg  active.std  idle.min  idle.max  \\\n",
       "0               0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "1               0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "2               0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "3               0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "4               0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "...             ...         ...         ...         ...       ...       ...   \n",
       "4325373         0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "4325374         0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "4325375         0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "4325376         0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "4325377         0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "\n",
       "         idle.tot  idle.avg  idle.std  fwd_init_window_size  \\\n",
       "0             0.0       0.0       0.0                     0   \n",
       "1             0.0       0.0       0.0                     0   \n",
       "2             0.0       0.0       0.0                     0   \n",
       "3             0.0       0.0       0.0                     0   \n",
       "4             0.0       0.0       0.0                     0   \n",
       "...           ...       ...       ...                   ...   \n",
       "4325373       0.0       0.0       0.0                     0   \n",
       "4325374       0.0       0.0       0.0                     0   \n",
       "4325375       0.0       0.0       0.0                     0   \n",
       "4325376       0.0       0.0       0.0                     0   \n",
       "4325377       0.0       0.0       0.0                     0   \n",
       "\n",
       "         bwd_init_window_size  fwd_last_window_size  bwd_last_window_size  \\\n",
       "0                           0                     0                     0   \n",
       "1                           0                     0                     0   \n",
       "2                           0                     0                     0   \n",
       "3                           0                     0                     0   \n",
       "4                           0                     0                     0   \n",
       "...                       ...                   ...                   ...   \n",
       "4325373                     0                     0                     0   \n",
       "4325374                     0                     0                     0   \n",
       "4325375                     0                     0                     0   \n",
       "4325376                     0                     0                     0   \n",
       "4325377                     0                     0                     0   \n",
       "\n",
       "             traffic  label  \n",
       "0        arpspoofing      1  \n",
       "1        arpspoofing      1  \n",
       "2        arpspoofing      1  \n",
       "3        arpspoofing      1  \n",
       "4        arpspoofing      1  \n",
       "...              ...    ...  \n",
       "4325373  camoverflow      1  \n",
       "4325374  camoverflow      1  \n",
       "4325375  camoverflow      1  \n",
       "4325376  camoverflow      1  \n",
       "4325377  camoverflow      1  \n",
       "\n",
       "[4325378 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"../../../../Datasets/Flows/iomt_flows.csv\")\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xEU9UPRN_XI"
   },
   "source": [
    "Fix Dataframe Mixed Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        361\n",
       "1    4038048\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('is_attack')['is_attack'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SDKSZ_89N_XJ"
   },
   "outputs": [],
   "source": [
    "# Remove rows with '-' character in columns 6, 7 and 8\n",
    "cols_to_check = ['duration', 'orig_bytes', 'resp_bytes']\n",
    "\n",
    "# Create a boolean mask to identify rows with '-' character\n",
    "mask = df[cols_to_check].apply(lambda x: x.str.contains('-', na=False)).any(axis=1)\n",
    "\n",
    "# Use the mask to filter out rows with '-' character\n",
    "df = df[~mask]\n",
    "\n",
    "# Replace comma with period as decimal separator\n",
    "cols_to_float = ['duration']\n",
    "\n",
    "# Replace ',' with '.' in specified columns\n",
    "df[cols_to_float] = df[cols_to_float].replace(',', '.', regex=True)\n",
    "\n",
    "# Convert columns 7 and 8 to float and int data types\n",
    "cols_to_int = ['orig_bytes', 'resp_bytes']\n",
    "\n",
    "# Convert specified columns to float and int types\n",
    "df[cols_to_float] = df[cols_to_float].astype(float)\n",
    "df[cols_to_int] = df[cols_to_int].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        407\n",
       "1    4324971\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('is_attack')['is_attack'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3OxjJEb6fxi"
   },
   "source": [
    "-----------------------------------------------------------\n",
    "\n",
    "## DF Statistics and Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ljdybTvfN_XJ"
   },
   "outputs": [],
   "source": [
    "def display_information_dataframe(df_cop):\n",
    "    # Create a summary of data types, column names, and unique values\n",
    "    summary_data = [{'Data Type': dtype, 'Column Name': col, 'Unique Values': df_cop[col].unique()} for col, dtype in df_cop.dtypes.iteritems()]\n",
    "    \n",
    "    # Create a DataFrame from the summary data\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Set display options to show all rows and columns\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.options.display.max_columns = None\n",
    "    \n",
    "    # Return the summary DataFrame\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4BJ-3JT66fxi",
    "outputId": "38be4775-5564-4772-f561-ed34f559bdd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>object</td>\n",
       "      <td>id.orig_h</td>\n",
       "      <td>[10.10.10.252, ::1, 10.10.10.1, 10.10.10.249, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>int64</td>\n",
       "      <td>id.orig_p</td>\n",
       "      <td>[33540, 50435, 47976, 37995, 38680, 53906, 520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>object</td>\n",
       "      <td>id.resp_h</td>\n",
       "      <td>[224.0.0.251, 10.10.10.0, 10.10.10.249, 10.10....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>int64</td>\n",
       "      <td>id.resp_p</td>\n",
       "      <td>[5353, 137, 57621, 80, 22, 256, 143, 23, 8080,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>object</td>\n",
       "      <td>proto</td>\n",
       "      <td>[udp, tcp, icmp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>object</td>\n",
       "      <td>service</td>\n",
       "      <td>[dns, -, http, mqtt, dhcp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>object</td>\n",
       "      <td>duration</td>\n",
       "      <td>[-, 57.262413, 3.002431, 0.208294, 0.209607, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>object</td>\n",
       "      <td>orig_bytes</td>\n",
       "      <td>[-, 1515, 75, 406, 405, 586, 569, 759, 763, 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>object</td>\n",
       "      <td>resp_bytes</td>\n",
       "      <td>[-, 0, 851, 0, 712, 310, 1111456671, 128716506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>object</td>\n",
       "      <td>conn_state</td>\n",
       "      <td>[S0, SH, RSTR, OTH, RSTRH, S2, RSTOS0, REJ, SH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>object</td>\n",
       "      <td>local_orig</td>\n",
       "      <td>[T, F]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>object</td>\n",
       "      <td>local_resp</td>\n",
       "      <td>[F, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>int64</td>\n",
       "      <td>missed_bytes</td>\n",
       "      <td>[0, 712, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>object</td>\n",
       "      <td>history</td>\n",
       "      <td>[D, ScAD, ScADF, ^cAFr, ScADdFr, DcAc, ^c, ^cA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>int64</td>\n",
       "      <td>orig_pkts</td>\n",
       "      <td>[1, 34, 2, 7, 10, 13, 55, 5, 472, 117, 6, 4, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>int64</td>\n",
       "      <td>orig_ip_bytes</td>\n",
       "      <td>[73, 74, 57, 78, 67, 71, 68, 75, 2467, 131, 60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>int64</td>\n",
       "      <td>resp_pkts</td>\n",
       "      <td>[0, 1, 2, 3, 240, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>int64</td>\n",
       "      <td>resp_ip_bytes</td>\n",
       "      <td>[0, 40, 80, 668, 60, 763, 361, 52, 120, 39120,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>object</td>\n",
       "      <td>tunnel_parents</td>\n",
       "      <td>[-]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_duration</td>\n",
       "      <td>[0.0, 57.262413, 3.002431, 0.208294, 0.2096070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_pkts_tot</td>\n",
       "      <td>[1, 34, 2, 7, 10, 13, 55, 5, 472, 117, 6, 4, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_pkts_tot</td>\n",
       "      <td>[0, 4, 5, 2, 3, 6, 26, 1, 7, 8, 240, 10614, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_data_pkts_tot</td>\n",
       "      <td>[1, 34, 2, 7, 10, 13, 55, 5, 472, 117, 0, 74, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_data_pkts_tot</td>\n",
       "      <td>[0, 2, 1, 3, 26, 4, 240, 10614, 16, 19, 18, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_per_sec</td>\n",
       "      <td>[0.0, 0.593758, 0.666127, 33.606359000000005, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_per_sec</td>\n",
       "      <td>[0.0, 60.843008, 61.064015000000005, 61.214630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_per_sec</td>\n",
       "      <td>[0.0, 0.593758, 0.666127, 33.606359000000005, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>float64</td>\n",
       "      <td>down_up_ratio</td>\n",
       "      <td>[0.0, 0.8, 0.666667, 1.0, 1.25, 0.857143, 0.74...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_header_size_tot</td>\n",
       "      <td>[8, 272, 16, 56, 80, 104, 440, 40, 3776, 936, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_header_size_min</td>\n",
       "      <td>[8, 32, 0, 20, 24, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_header_size_max</td>\n",
       "      <td>[8, 40, 44, 32, 0, 24, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_header_size_tot</td>\n",
       "      <td>[0, 136, 168, 52, 72, 188, 832, 32, 104, 64, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_header_size_min</td>\n",
       "      <td>[0, 32, 20, 40, 24, 36, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_header_size_max</td>\n",
       "      <td>[0, 40, 32, 44, 20, 24, 36, 8, 52]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_FIN_flag_count</td>\n",
       "      <td>[0, 2, 3, 1, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_SYN_flag_count</td>\n",
       "      <td>[0, 2, 1, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_RST_flag_count</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_PSH_flag_count</td>\n",
       "      <td>[0, 1, 10, 2, 3, 292, 281, 293, 287, 288, 283,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_PSH_flag_count</td>\n",
       "      <td>[0, 1, 2, 26, 3, 4, 16, 19, 18, 6, 14, 9, 7, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_ACK_flag_count</td>\n",
       "      <td>[0, 8, 9, 7, 3, 4, 11, 61, 1, 2, 6, 5, 10, 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_URG_flag_count</td>\n",
       "      <td>[0, 1, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_URG_flag_count</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_CWR_flag_count</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_ECE_flag_count</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_payload.min</td>\n",
       "      <td>[45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_payload.max</td>\n",
       "      <td>[45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_payload.tot</td>\n",
       "      <td>[45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_payload.avg</td>\n",
       "      <td>[45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_payload.std</td>\n",
       "      <td>[0.0, 1.439511, 12.020814999999999, 5.291503, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_payload.min</td>\n",
       "      <td>[0.0, 36.0, 120.0, 300.0, 94.0, 477.0, 34.0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_payload.max</td>\n",
       "      <td>[0.0, 576.0, 850.0, 324.0, 711.0, 309.0, 40.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_payload.tot</td>\n",
       "      <td>[0.0, 850.0, 1124.0, 2168.0, 711.0, 309.0, 142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_payload.avg</td>\n",
       "      <td>[0.0, 212.5, 224.8, 141.666667, 83.384615, 237...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_payload.std</td>\n",
       "      <td>[0.0, 274.606992, 425.0, 239.401754, 239.34716...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_payload.min</td>\n",
       "      <td>[45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_payload.max</td>\n",
       "      <td>[45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_payload.tot</td>\n",
       "      <td>[45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_payload.avg</td>\n",
       "      <td>[45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_payload.std</td>\n",
       "      <td>[0.0, 1.439511, 12.020814999999999, 5.291503, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_iat.min</td>\n",
       "      <td>[0.0, 38684.129714999995, 3002430.915833, 5.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_iat.max</td>\n",
       "      <td>[0.0, 2000760.07843, 3002430.915833, 207557.91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_iat.tot</td>\n",
       "      <td>[0.0, 57262413.024902, 3002430.915833, 208293....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_iat.avg</td>\n",
       "      <td>[0.0, 1735224.637118, 3002430.915833, 34715.65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_iat.std</td>\n",
       "      <td>[0.0, 642472.5112739999, 84675.319676, 84982.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_iat.min</td>\n",
       "      <td>[0.0, 664.949417, 368.118286, 550.031662, 1080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_iat.max</td>\n",
       "      <td>[0.0, 20202.875137, 20545.005798, 20215.034485...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_iat.tot</td>\n",
       "      <td>[0.0, 21582.841872999998, 21459.102631, 21322....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_iat.avg</td>\n",
       "      <td>[0.0, 7194.280623999999, 7153.03421, 7107.3373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_iat.std</td>\n",
       "      <td>[0.0, 11265.80113, 11598.128549, 11351.5992599...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_iat.min</td>\n",
       "      <td>[0.0, 38684.129714999995, 3002430.915833, 5.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_iat.max</td>\n",
       "      <td>[0.0, 2000760.07843, 3002430.915833, 207557.91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_iat.tot</td>\n",
       "      <td>[0.0, 57262413.024902, 3002430.915833, 208293....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_iat.avg</td>\n",
       "      <td>[0.0, 1735224.637118, 3002430.915833, 34715.65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_iat.std</td>\n",
       "      <td>[0.0, 642472.5112739999, 84675.319676, 84982.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>float64</td>\n",
       "      <td>payload_bytes_per_second</td>\n",
       "      <td>[0.0, 26.457146, 24.979759, 1949.1688, 1932.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_subflow_pkts</td>\n",
       "      <td>[1.0, 1.133333, 7.0, 10.0, 13.0, 13.75, 1.0086...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_subflow_pkts</td>\n",
       "      <td>[0.0, 4.0, 5.0, 1.0, 1.5, 2.0, 26.0, 3.0, 2.5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_subflow_bytes</td>\n",
       "      <td>[45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_subflow_bytes</td>\n",
       "      <td>[0.0, 850.0, 1124.0, 283.333333, 2168.0, 711.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_bulk_bytes</td>\n",
       "      <td>[0.0, 406.0, 405.0, 586.0, 569.0, 759.0, 763.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_bulk_bytes</td>\n",
       "      <td>[0.0, 836.0, 20.0, 24.0, 28.0, 32.0, 36.0, 40....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_bulk_packets</td>\n",
       "      <td>[0.0, 7.0, 10.0, 13.0, 17.666667, 292.0, 281.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_bulk_packets</td>\n",
       "      <td>[0.0, 8.0, 5.0, 6.0, 7.0, 9.0, 10.0, 11.0, 17....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_bulk_rate</td>\n",
       "      <td>[0.0, 1949.1688, 1932.186233, 2818.109541, 274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_bulk_rate</td>\n",
       "      <td>[0.0, 46924.251347000005, 51.213504, 51.780188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>float64</td>\n",
       "      <td>active.min</td>\n",
       "      <td>[0.0, 57262413.024902, 3002430.915833, 208293....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>float64</td>\n",
       "      <td>active.max</td>\n",
       "      <td>[0.0, 57262413.024902, 3002430.915833, 208293....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>float64</td>\n",
       "      <td>active.tot</td>\n",
       "      <td>[0.0, 57262413.024902, 3002430.915833, 208293....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>float64</td>\n",
       "      <td>active.avg</td>\n",
       "      <td>[0.0, 57262413.024902, 3002430.915833, 208293....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>float64</td>\n",
       "      <td>active.std</td>\n",
       "      <td>[0.0, 181677.269011, 29231.199666000004, 41902...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>float64</td>\n",
       "      <td>idle.min</td>\n",
       "      <td>[0.0, 8001144.170761, 5795279.026031, 5792163....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>float64</td>\n",
       "      <td>idle.max</td>\n",
       "      <td>[0.0, 8001144.170761, 5795279.026031, 5792163....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>float64</td>\n",
       "      <td>idle.tot</td>\n",
       "      <td>[0.0, 8001144.170761, 5795279.026031, 5792163....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>float64</td>\n",
       "      <td>idle.avg</td>\n",
       "      <td>[0.0, 8001144.170761, 5795279.026031, 5792163....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>float64</td>\n",
       "      <td>idle.std</td>\n",
       "      <td>[0.0, 10012.734441, 4270739.749407, 15102915.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_init_window_size</td>\n",
       "      <td>[0, 1152, 64240, 301, 4584, 501, 1024, 256, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_init_window_size</td>\n",
       "      <td>[0, 65160, 507, 508, 501, 506, 64240, 509, 502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_last_window_size</td>\n",
       "      <td>[0, 302, 501, 1152, 4584, 301, 497, 500, 502, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_last_window_size</td>\n",
       "      <td>[0, 507, 508, 501, 506, 510, 65160, 64240, 509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>object</td>\n",
       "      <td>traffic</td>\n",
       "      <td>[arpspoofing, slowread, rudeadyet, netscan, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>int64</td>\n",
       "      <td>label</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data Type               Column Name  \\\n",
       "0      object                 id.orig_h   \n",
       "1       int64                 id.orig_p   \n",
       "2      object                 id.resp_h   \n",
       "3       int64                 id.resp_p   \n",
       "4      object                     proto   \n",
       "5      object                   service   \n",
       "6      object                  duration   \n",
       "7      object                orig_bytes   \n",
       "8      object                resp_bytes   \n",
       "9      object                conn_state   \n",
       "10     object                local_orig   \n",
       "11     object                local_resp   \n",
       "12      int64              missed_bytes   \n",
       "13     object                   history   \n",
       "14      int64                 orig_pkts   \n",
       "15      int64             orig_ip_bytes   \n",
       "16      int64                 resp_pkts   \n",
       "17      int64             resp_ip_bytes   \n",
       "18     object            tunnel_parents   \n",
       "19    float64             flow_duration   \n",
       "20      int64              fwd_pkts_tot   \n",
       "21      int64              bwd_pkts_tot   \n",
       "22      int64         fwd_data_pkts_tot   \n",
       "23      int64         bwd_data_pkts_tot   \n",
       "24    float64          fwd_pkts_per_sec   \n",
       "25    float64          bwd_pkts_per_sec   \n",
       "26    float64         flow_pkts_per_sec   \n",
       "27    float64             down_up_ratio   \n",
       "28      int64       fwd_header_size_tot   \n",
       "29      int64       fwd_header_size_min   \n",
       "30      int64       fwd_header_size_max   \n",
       "31      int64       bwd_header_size_tot   \n",
       "32      int64       bwd_header_size_min   \n",
       "33      int64       bwd_header_size_max   \n",
       "34      int64       flow_FIN_flag_count   \n",
       "35      int64       flow_SYN_flag_count   \n",
       "36      int64       flow_RST_flag_count   \n",
       "37      int64        fwd_PSH_flag_count   \n",
       "38      int64        bwd_PSH_flag_count   \n",
       "39      int64       flow_ACK_flag_count   \n",
       "40      int64        fwd_URG_flag_count   \n",
       "41      int64        bwd_URG_flag_count   \n",
       "42      int64       flow_CWR_flag_count   \n",
       "43      int64       flow_ECE_flag_count   \n",
       "44    float64      fwd_pkts_payload.min   \n",
       "45    float64      fwd_pkts_payload.max   \n",
       "46    float64      fwd_pkts_payload.tot   \n",
       "47    float64      fwd_pkts_payload.avg   \n",
       "48    float64      fwd_pkts_payload.std   \n",
       "49    float64      bwd_pkts_payload.min   \n",
       "50    float64      bwd_pkts_payload.max   \n",
       "51    float64      bwd_pkts_payload.tot   \n",
       "52    float64      bwd_pkts_payload.avg   \n",
       "53    float64      bwd_pkts_payload.std   \n",
       "54    float64     flow_pkts_payload.min   \n",
       "55    float64     flow_pkts_payload.max   \n",
       "56    float64     flow_pkts_payload.tot   \n",
       "57    float64     flow_pkts_payload.avg   \n",
       "58    float64     flow_pkts_payload.std   \n",
       "59    float64               fwd_iat.min   \n",
       "60    float64               fwd_iat.max   \n",
       "61    float64               fwd_iat.tot   \n",
       "62    float64               fwd_iat.avg   \n",
       "63    float64               fwd_iat.std   \n",
       "64    float64               bwd_iat.min   \n",
       "65    float64               bwd_iat.max   \n",
       "66    float64               bwd_iat.tot   \n",
       "67    float64               bwd_iat.avg   \n",
       "68    float64               bwd_iat.std   \n",
       "69    float64              flow_iat.min   \n",
       "70    float64              flow_iat.max   \n",
       "71    float64              flow_iat.tot   \n",
       "72    float64              flow_iat.avg   \n",
       "73    float64              flow_iat.std   \n",
       "74    float64  payload_bytes_per_second   \n",
       "75    float64          fwd_subflow_pkts   \n",
       "76    float64          bwd_subflow_pkts   \n",
       "77    float64         fwd_subflow_bytes   \n",
       "78    float64         bwd_subflow_bytes   \n",
       "79    float64            fwd_bulk_bytes   \n",
       "80    float64            bwd_bulk_bytes   \n",
       "81    float64          fwd_bulk_packets   \n",
       "82    float64          bwd_bulk_packets   \n",
       "83    float64             fwd_bulk_rate   \n",
       "84    float64             bwd_bulk_rate   \n",
       "85    float64                active.min   \n",
       "86    float64                active.max   \n",
       "87    float64                active.tot   \n",
       "88    float64                active.avg   \n",
       "89    float64                active.std   \n",
       "90    float64                  idle.min   \n",
       "91    float64                  idle.max   \n",
       "92    float64                  idle.tot   \n",
       "93    float64                  idle.avg   \n",
       "94    float64                  idle.std   \n",
       "95      int64      fwd_init_window_size   \n",
       "96      int64      bwd_init_window_size   \n",
       "97      int64      fwd_last_window_size   \n",
       "98      int64      bwd_last_window_size   \n",
       "99     object                   traffic   \n",
       "100     int64                     label   \n",
       "\n",
       "                                         Unique Values  \n",
       "0    [10.10.10.252, ::1, 10.10.10.1, 10.10.10.249, ...  \n",
       "1    [33540, 50435, 47976, 37995, 38680, 53906, 520...  \n",
       "2    [224.0.0.251, 10.10.10.0, 10.10.10.249, 10.10....  \n",
       "3    [5353, 137, 57621, 80, 22, 256, 143, 23, 8080,...  \n",
       "4                                     [udp, tcp, icmp]  \n",
       "5                           [dns, -, http, mqtt, dhcp]  \n",
       "6    [-, 57.262413, 3.002431, 0.208294, 0.209607, 0...  \n",
       "7    [-, 1515, 75, 406, 405, 586, 569, 759, 763, 58...  \n",
       "8    [-, 0, 851, 0, 712, 310, 1111456671, 128716506...  \n",
       "9    [S0, SH, RSTR, OTH, RSTRH, S2, RSTOS0, REJ, SH...  \n",
       "10                                              [T, F]  \n",
       "11                                              [F, T]  \n",
       "12                                         [0, 712, 1]  \n",
       "13   [D, ScAD, ScADF, ^cAFr, ScADdFr, DcAc, ^c, ^cA...  \n",
       "14   [1, 34, 2, 7, 10, 13, 55, 5, 472, 117, 6, 4, 3...  \n",
       "15   [73, 74, 57, 78, 67, 71, 68, 75, 2467, 131, 60...  \n",
       "16                                [0, 1, 2, 3, 240, 4]  \n",
       "17   [0, 40, 80, 668, 60, 763, 361, 52, 120, 39120,...  \n",
       "18                                                 [-]  \n",
       "19   [0.0, 57.262413, 3.002431, 0.208294, 0.2096070...  \n",
       "20   [1, 34, 2, 7, 10, 13, 55, 5, 472, 117, 6, 4, 3...  \n",
       "21   [0, 4, 5, 2, 3, 6, 26, 1, 7, 8, 240, 10614, 20...  \n",
       "22   [1, 34, 2, 7, 10, 13, 55, 5, 472, 117, 0, 74, ...  \n",
       "23   [0, 2, 1, 3, 26, 4, 240, 10614, 16, 19, 18, 6,...  \n",
       "24   [0.0, 0.593758, 0.666127, 33.606359000000005, ...  \n",
       "25   [0.0, 60.843008, 61.064015000000005, 61.214630...  \n",
       "26   [0.0, 0.593758, 0.666127, 33.606359000000005, ...  \n",
       "27   [0.0, 0.8, 0.666667, 1.0, 1.25, 0.857143, 0.74...  \n",
       "28   [8, 272, 16, 56, 80, 104, 440, 40, 3776, 936, ...  \n",
       "29                              [8, 32, 0, 20, 24, 40]  \n",
       "30                          [8, 40, 44, 32, 0, 24, 36]  \n",
       "31   [0, 136, 168, 52, 72, 188, 832, 32, 104, 64, 9...  \n",
       "32                          [0, 32, 20, 40, 24, 36, 8]  \n",
       "33                  [0, 40, 32, 44, 20, 24, 36, 8, 52]  \n",
       "34                                     [0, 2, 3, 1, 4]  \n",
       "35                                     [0, 2, 1, 4, 3]  \n",
       "36                                        [0, 1, 2, 3]  \n",
       "37   [0, 1, 10, 2, 3, 292, 281, 293, 287, 288, 283,...  \n",
       "38   [0, 1, 2, 26, 3, 4, 16, 19, 18, 6, 14, 9, 7, 2...  \n",
       "39   [0, 8, 9, 7, 3, 4, 11, 61, 1, 2, 6, 5, 10, 12,...  \n",
       "40                                        [0, 1, 3, 2]  \n",
       "41                                                 [0]  \n",
       "42                                              [0, 2]  \n",
       "43                                              [0, 1]  \n",
       "44   [45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....  \n",
       "45   [45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....  \n",
       "46   [45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....  \n",
       "47   [45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....  \n",
       "48   [0.0, 1.439511, 12.020814999999999, 5.291503, ...  \n",
       "49   [0.0, 36.0, 120.0, 300.0, 94.0, 477.0, 34.0, 2...  \n",
       "50   [0.0, 576.0, 850.0, 324.0, 711.0, 309.0, 40.0,...  \n",
       "51   [0.0, 850.0, 1124.0, 2168.0, 711.0, 309.0, 142...  \n",
       "52   [0.0, 212.5, 224.8, 141.666667, 83.384615, 237...  \n",
       "53   [0.0, 274.606992, 425.0, 239.401754, 239.34716...  \n",
       "54   [45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....  \n",
       "55   [45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....  \n",
       "56   [45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....  \n",
       "57   [45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....  \n",
       "58   [0.0, 1.439511, 12.020814999999999, 5.291503, ...  \n",
       "59   [0.0, 38684.129714999995, 3002430.915833, 5.00...  \n",
       "60   [0.0, 2000760.07843, 3002430.915833, 207557.91...  \n",
       "61   [0.0, 57262413.024902, 3002430.915833, 208293....  \n",
       "62   [0.0, 1735224.637118, 3002430.915833, 34715.65...  \n",
       "63   [0.0, 642472.5112739999, 84675.319676, 84982.5...  \n",
       "64   [0.0, 664.949417, 368.118286, 550.031662, 1080...  \n",
       "65   [0.0, 20202.875137, 20545.005798, 20215.034485...  \n",
       "66   [0.0, 21582.841872999998, 21459.102631, 21322....  \n",
       "67   [0.0, 7194.280623999999, 7153.03421, 7107.3373...  \n",
       "68   [0.0, 11265.80113, 11598.128549, 11351.5992599...  \n",
       "69   [0.0, 38684.129714999995, 3002430.915833, 5.00...  \n",
       "70   [0.0, 2000760.07843, 3002430.915833, 207557.91...  \n",
       "71   [0.0, 57262413.024902, 3002430.915833, 208293....  \n",
       "72   [0.0, 1735224.637118, 3002430.915833, 34715.65...  \n",
       "73   [0.0, 642472.5112739999, 84675.319676, 84982.5...  \n",
       "74   [0.0, 26.457146, 24.979759, 1949.1688, 1932.18...  \n",
       "75   [1.0, 1.133333, 7.0, 10.0, 13.0, 13.75, 1.0086...  \n",
       "76   [0.0, 4.0, 5.0, 1.0, 1.5, 2.0, 26.0, 3.0, 2.5,...  \n",
       "77   [45.0, 46.0, 29.0, 50.0, 39.0, 43.0, 40.0, 47....  \n",
       "78   [0.0, 850.0, 1124.0, 283.333333, 2168.0, 711.0...  \n",
       "79   [0.0, 406.0, 405.0, 586.0, 569.0, 759.0, 763.0...  \n",
       "80   [0.0, 836.0, 20.0, 24.0, 28.0, 32.0, 36.0, 40....  \n",
       "81   [0.0, 7.0, 10.0, 13.0, 17.666667, 292.0, 281.0...  \n",
       "82   [0.0, 8.0, 5.0, 6.0, 7.0, 9.0, 10.0, 11.0, 17....  \n",
       "83   [0.0, 1949.1688, 1932.186233, 2818.109541, 274...  \n",
       "84   [0.0, 46924.251347000005, 51.213504, 51.780188...  \n",
       "85   [0.0, 57262413.024902, 3002430.915833, 208293....  \n",
       "86   [0.0, 57262413.024902, 3002430.915833, 208293....  \n",
       "87   [0.0, 57262413.024902, 3002430.915833, 208293....  \n",
       "88   [0.0, 57262413.024902, 3002430.915833, 208293....  \n",
       "89   [0.0, 181677.269011, 29231.199666000004, 41902...  \n",
       "90   [0.0, 8001144.170761, 5795279.026031, 5792163....  \n",
       "91   [0.0, 8001144.170761, 5795279.026031, 5792163....  \n",
       "92   [0.0, 8001144.170761, 5795279.026031, 5792163....  \n",
       "93   [0.0, 8001144.170761, 5795279.026031, 5792163....  \n",
       "94   [0.0, 10012.734441, 4270739.749407, 15102915.5...  \n",
       "95   [0, 1152, 64240, 301, 4584, 501, 1024, 256, 1,...  \n",
       "96   [0, 65160, 507, 508, 501, 506, 64240, 509, 502...  \n",
       "97   [0, 302, 501, 1152, 4584, 301, 497, 500, 502, ...  \n",
       "98   [0, 507, 508, 501, 506, 510, 65160, 64240, 509...  \n",
       "99   [arpspoofing, slowread, rudeadyet, netscan, no...  \n",
       "100                                             [1, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_information_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgb20-msN_XI"
   },
   "source": [
    "--------------------------------------------\n",
    "\n",
    "## Pre-processing and Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2L5yxSG6fxk"
   },
   "source": [
    "Split History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "byGEDcyWZtM7"
   },
   "outputs": [],
   "source": [
    "def count_letters(string, is_upper):\n",
    "    count = 0\n",
    "    \n",
    "    # Iterate through each character in the string\n",
    "    for c in string:\n",
    "        if is_upper and c.isupper():  # Check if the character is uppercase\n",
    "            count += 1\n",
    "        elif not is_upper and c.islower():  # Check if the character is lowercase\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IGQEQC_GbWZD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPLIT HISTORY] history_originator\n",
      "[SPLIT HISTORY] history_responder\n"
     ]
    }
   ],
   "source": [
    "print('[SPLIT HISTORY] history_originator')\n",
    "df['history_originator'] = df['history'].apply(lambda x: count_letters(x, True))\n",
    "\n",
    "print('[SPLIT HISTORY] history_responder')\n",
    "df['history_responder'] = df['history'].apply(lambda x: count_letters(x, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decimal Scale Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DECIMAL SCALE NORMALIZATION] flow_duration\n",
      "[DECIMAL SCALE NORMALIZATION] duration\n",
      "[DECIMAL SCALE NORMALIZATION] down_up_ratio\n"
     ]
    }
   ],
   "source": [
    "# Multiply by 1000 for a bigger scale\n",
    "print('[DECIMAL SCALE NORMALIZATION] flow_duration')\n",
    "df['flow_duration'] *= 1000\n",
    "\n",
    "# Multiply by 100 for a bigger scale\n",
    "print('[DECIMAL SCALE NORMALIZATION] duration')\n",
    "df['duration'] *= 100\n",
    "\n",
    "# Multiply by 10 for a bigger scale\n",
    "print('[DECIMAL SCALE NORMALIZATION] down_up_ratio')\n",
    "df['down_up_ratio'] *= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA NORMALIZATION] bwd_PSH_flag_count\n",
      "[DATA NORMALIZATION] bwd_data_pkts_tot\n"
     ]
    }
   ],
   "source": [
    "# Update values in 'bwd_PSH_flag_count' column if they are higher than 4\n",
    "print('[DATA NORMALIZATION] bwd_PSH_flag_count')\n",
    "df.loc[df['bwd_PSH_flag_count'] > 4, 'bwd_PSH_flag_count'] = 5\n",
    "\n",
    "# Update values in 'bwd_data_pkts_tot' column if they are higher than 3\n",
    "print('[DATA NORMALIZATION] bwd_data_pkts_tot')\n",
    "df.loc[df['bwd_data_pkts_tot'] > 3, 'bwd_data_pkts_tot'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSbkiI6JD6vO"
   },
   "source": [
    "Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df,columns,n_std):\n",
    "    for col in columns:\n",
    "        print(f'[REMOVED OUTLIERS] {col}')\n",
    "        \n",
    "        mean = df[col].mean()\n",
    "        sd = df[col].std()\n",
    "        \n",
    "        df = df[(df[col] <= mean+(n_std*sd))]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7G5NkFuBD8lM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REMOVED OUTLIERS] resp_ip_bytes\n",
      "[REMOVED OUTLIERS] orig_pkts\n",
      "[REMOVED OUTLIERS] flow_duration\n",
      "[REMOVED OUTLIERS] bwd_pkts_tot\n",
      "[REMOVED OUTLIERS] bwd_pkts_payload.avg\n",
      "[REMOVED OUTLIERS] bwd_header_size_tot\n",
      "[REMOVED OUTLIERS] resp_pkts\n"
     ]
    }
   ],
   "source": [
    "outliers = [\n",
    "    'resp_ip_bytes',\n",
    "    'orig_pkts',\n",
    "    'flow_duration',\n",
    "    'bwd_pkts_tot',\n",
    "    'bwd_pkts_payload.avg',\n",
    "    'bwd_header_size_tot',\n",
    "    'resp_pkts',\n",
    "    'duration',\n",
    "]\n",
    "\n",
    "df = remove_outliers(df, outliers, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6MG8V_sC7y3"
   },
   "source": [
    "One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "psGbkLKcFqA_"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(df, columns):\n",
    "    for col in columns:\n",
    "        print(f'[ONE HOT ENCODING] {col}')\n",
    "        df = pd.get_dummies(df, columns=[col], prefix=col)  # Perform one-hot encoding on the column\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoAIe3cv9mE-",
    "outputId": "55a1eb68-aac9-4987-87f3-1e3dbbca521e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONE HOT ENCODING] proto\n",
      "[ONE HOT ENCODING] local_resp\n",
      "[ONE HOT ENCODING] local_orig\n",
      "[ONE HOT ENCODING] fwd_header_size_min\n",
      "[ONE HOT ENCODING] fwd_header_size_max\n",
      "[ONE HOT ENCODING] flow_SYN_flag_count\n",
      "[ONE HOT ENCODING] flow_RST_flag_count\n",
      "[ONE HOT ENCODING] flow_FIN_flag_count\n",
      "[ONE HOT ENCODING] conn_state\n",
      "[ONE HOT ENCODING] bwd_PSH_flag_count\n",
      "[ONE HOT ENCODING] bwd_header_size_min\n",
      "[ONE HOT ENCODING] bwd_header_size_max\n",
      "[ONE HOT ENCODING] resp_pkts\n"
     ]
    }
   ],
   "source": [
    "cols_to_encode = [\n",
    "    'proto',\n",
    "    'local_resp',\n",
    "    'local_orig',\n",
    "    'fwd_header_size_min',\n",
    "    'fwd_header_size_max',\n",
    "    'flow_SYN_flag_count',\n",
    "    'flow_RST_flag_count',\n",
    "    'flow_FIN_flag_count',\n",
    "    'conn_state',\n",
    "    'bwd_PSH_flag_count',\n",
    "    'bwd_header_size_min',\n",
    "    'bwd_header_size_max',\n",
    "    'resp_pkts',\n",
    "]\n",
    "\n",
    "df = one_hot_encoding(df,cols_to_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsIbHSu0N_XK"
   },
   "source": [
    "Normalize, Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "s68skGdoN_XK"
   },
   "outputs": [],
   "source": [
    "def zscore_normalization(df, cols):\n",
    "    # Standardize the selected columns\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"[WARNING] {col} not found in DataFrame.\")\n",
    "            continue\n",
    "        print(f\"[Z-SCORE] {col}\")\n",
    "        df[col] = zscore(df[col])\n",
    "    \n",
    "    print(\"[DONE] Z-score Normalization\")\n",
    "    print(\"[INFO] Current Fields in the DataFrame:\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "nQdNGsJ-N_XK",
    "outputId": "3721d8a8-a9a0-491f-ddd1-da08e37c1e89",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Z-SCORE] resp_ip_bytes\n",
      "[Z-SCORE] payload_bytes_per_second\n",
      "[Z-SCORE] orig_pkts\n",
      "[Z-SCORE] orig_ip_bytes\n",
      "[Z-SCORE] fwd_subflow_pkts\n",
      "[Z-SCORE] fwd_subflow_bytes\n",
      "[Z-SCORE] fwd_PSH_flag_count\n",
      "[Z-SCORE] fwd_pkts_tot\n",
      "[Z-SCORE] fwd_pkts_per_sec\n",
      "[Z-SCORE] fwd_pkts_payload.tot\n",
      "[Z-SCORE] fwd_pkts_payload.std\n",
      "[Z-SCORE] fwd_pkts_payload.min\n",
      "[Z-SCORE] fwd_pkts_payload.max\n",
      "[Z-SCORE] fwd_pkts_payload.avg\n",
      "[Z-SCORE] fwd_last_window_size\n",
      "[Z-SCORE] fwd_init_window_size\n",
      "[Z-SCORE] fwd_iat.tot\n",
      "[Z-SCORE] fwd_iat.std\n",
      "[Z-SCORE] fwd_iat.min\n",
      "[Z-SCORE] fwd_iat.max\n",
      "[Z-SCORE] fwd_iat.avg\n",
      "[Z-SCORE] fwd_header_size_tot\n",
      "[Z-SCORE] fwd_data_pkts_tot\n",
      "[Z-SCORE] fwd_bulk_bytes\n",
      "[Z-SCORE] flow_pkts_per_sec\n",
      "[Z-SCORE] flow_pkts_payload.tot\n",
      "[Z-SCORE] flow_pkts_payload.std\n",
      "[Z-SCORE] flow_pkts_payload.min\n",
      "[Z-SCORE] flow_pkts_payload.max\n",
      "[Z-SCORE] flow_pkts_payload.avg\n",
      "[Z-SCORE] flow_iat.tot\n",
      "[Z-SCORE] flow_iat.std\n",
      "[Z-SCORE] flow_iat.min\n",
      "[Z-SCORE] flow_iat.max\n",
      "[Z-SCORE] flow_iat.avg\n",
      "[Z-SCORE] flow_duration\n",
      "[Z-SCORE] flow_ACK_flag_count\n",
      "[Z-SCORE] down_up_ratio\n",
      "[Z-SCORE] bwd_subflow_pkts\n",
      "[Z-SCORE] bwd_subflow_bytes\n",
      "[Z-SCORE] bwd_pkts_tot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:2419: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Z-SCORE] bwd_pkts_per_sec\n",
      "[Z-SCORE] bwd_pkts_payload.tot\n",
      "[Z-SCORE] bwd_pkts_payload.std\n",
      "[Z-SCORE] bwd_pkts_payload.max\n",
      "[Z-SCORE] bwd_pkts_payload.avg\n",
      "[Z-SCORE] bwd_last_window_size\n",
      "[Z-SCORE] bwd_init_window_size\n",
      "[Z-SCORE] bwd_iat.tot\n",
      "[Z-SCORE] bwd_iat.min\n",
      "[Z-SCORE] bwd_iat.max\n",
      "[Z-SCORE] bwd_iat.avg\n",
      "[Z-SCORE] bwd_header_size_tot\n",
      "[Z-SCORE] active.tot\n",
      "[Z-SCORE] active.min\n",
      "[Z-SCORE] active.max\n",
      "[Z-SCORE] active.avg\n",
      "[DONE] Z-score Normalization\n",
      "[INFO] Current Fields in the DataFrame:\n"
     ]
    }
   ],
   "source": [
    "cols_to_zscore = [\n",
    "    'resp_ip_bytes',\n",
    "    'payload_bytes_per_second',\n",
    "    'orig_pkts',\n",
    "    'orig_ip_bytes',\n",
    "    'fwd_subflow_pkts',\n",
    "    'fwd_subflow_bytes',\n",
    "    'fwd_PSH_flag_count',\n",
    "    'fwd_pkts_tot',\n",
    "    'fwd_pkts_per_sec',\n",
    "    'fwd_pkts_payload.tot',\n",
    "    'fwd_pkts_payload.std',\n",
    "    'fwd_pkts_payload.min',\n",
    "    'fwd_pkts_payload.max',\n",
    "    'fwd_pkts_payload.avg',\n",
    "    'fwd_last_window_size',\n",
    "    'fwd_init_window_size',\n",
    "    'fwd_iat.tot',\n",
    "    'fwd_iat.std',\n",
    "    'fwd_iat.min',\n",
    "    'fwd_iat.max', \n",
    "    'fwd_iat.avg',\n",
    "    'fwd_header_size_tot',\n",
    "    'fwd_data_pkts_tot',\n",
    "    'fwd_bulk_bytes',\n",
    "    'flow_pkts_per_sec',\n",
    "    'flow_pkts_payload.tot',\n",
    "    'flow_pkts_payload.std',\n",
    "    'flow_pkts_payload.min',\n",
    "    'flow_pkts_payload.max',\n",
    "    'flow_pkts_payload.avg',\n",
    "    'flow_iat.tot',\n",
    "    'flow_iat.std',\n",
    "    'flow_iat.min',\n",
    "    'flow_iat.max',\n",
    "    'flow_iat.avg',\n",
    "    'flow_duration',\n",
    "    'flow_ACK_flag_count',\n",
    "    'down_up_ratio',\n",
    "    'bwd_subflow_pkts',\n",
    "    'bwd_subflow_bytes',\n",
    "    'bwd_pkts_tot',\n",
    "    'bwd_pkts_per_sec',\n",
    "    'bwd_pkts_payload.tot',\n",
    "    'bwd_pkts_payload.std',\n",
    "    'bwd_pkts_payload.max',\n",
    "    'bwd_pkts_payload.avg',\n",
    "    'bwd_last_window_size',\n",
    "    'bwd_init_window_size',\n",
    "    'bwd_iat.tot',\n",
    "    'bwd_iat.min',\n",
    "    'bwd_iat.max',\n",
    "    'bwd_iat.avg',\n",
    "    'bwd_header_size_tot',\n",
    "    'active.tot',\n",
    "    'active.min',\n",
    "    'active.max',\n",
    "    'active.avg',  \n",
    "]\n",
    "\n",
    "df = zscore_normalization(df, cols_to_zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paLhEkkLN_XK"
   },
   "source": [
    "Delete Insignificant Columns from the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "gM8kKWVhN_XK"
   },
   "outputs": [],
   "source": [
    "def delete_columns(df, cols):\n",
    "    for col in cols:\n",
    "        df.drop(col, axis = 1, inplace = True)\n",
    "        print(f'[REMOVED] {col}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LC6qBPhN_XK",
    "outputId": "ae158dcd-20b4-4f09-9bf6-63e4ba623aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REMOVED] tunnel_parents\n",
      "[REMOVED] service\n",
      "[REMOVED] missed_bytes\n",
      "[REMOVED] idle.tot\n",
      "[REMOVED] idle.std\n",
      "[REMOVED] idle.min\n",
      "[REMOVED] idle.max\n",
      "[REMOVED] idle.avg\n",
      "[REMOVED] fwd_URG_flag_count\n",
      "[REMOVED] fwd_bulk_rate\n",
      "[REMOVED] fwd_bulk_packets\n",
      "[REMOVED] flow_ECE_flag_count\n",
      "[REMOVED] flow_CWR_flag_count\n",
      "[REMOVED] bwd_URG_flag_count\n",
      "[REMOVED] bwd_pkts_payload.min\n",
      "[REMOVED] bwd_iat.std\n",
      "[REMOVED] bwd_bulk_rate\n",
      "[REMOVED] bwd_bulk_packets\n",
      "[REMOVED] bwd_bulk_bytes\n",
      "[REMOVED] active.std\n",
      "[REMOVED] id.orig_h\n",
      "[REMOVED] id.orig_p\n",
      "[REMOVED] id.resp_h\n",
      "[REMOVED] id.resp_p\n",
      "[REMOVED] history\n",
      "[REMOVED] traffic\n",
      "[REMOVED] duration\n",
      "[REMOVED] orig_bytes\n",
      "[REMOVED] resp_bytes\n"
     ]
    }
   ],
   "source": [
    "cols_to_del = [\n",
    "    'tunnel_parents',\n",
    "    'service',\n",
    "    'missed_bytes',\n",
    "    'idle.tot',\n",
    "    'idle.std',\n",
    "    'idle.min',\n",
    "    'idle.max',\n",
    "    'idle.avg',\n",
    "    'fwd_URG_flag_count',\n",
    "    'fwd_bulk_rate',\n",
    "    'fwd_bulk_packets',\n",
    "    'flow_ECE_flag_count',\n",
    "    'flow_CWR_flag_count',\n",
    "    'bwd_URG_flag_count',\n",
    "    'bwd_pkts_payload.min',\n",
    "    'bwd_iat.std',\n",
    "    'bwd_bulk_rate',\n",
    "    'bwd_bulk_packets',\n",
    "    'bwd_bulk_bytes',\n",
    "    'active.std',\n",
    "    'id.orig_h',\n",
    "    'id.orig_p',\n",
    "    'id.resp_h',\n",
    "    'id.resp_p',\n",
    "    'history',\n",
    "    'traffic',\n",
    "]\n",
    "\n",
    "df = delete_columns(df,cols_to_del)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcHY3Kk_N_XN"
   },
   "source": [
    "---------------------------------------\n",
    "\n",
    "## Save Train Data and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "g7ExpPs6N_XN"
   },
   "outputs": [],
   "source": [
    "x_columns = df.columns.drop('is_attack')\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df[\"is_attack\"].values)\n",
    "\n",
    "x = df[x_columns].values\n",
    "y = df[\"is_attack\"].values\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "x_train_train, x_test_train, y_train_train, y_test_train = train_test_split(x_train, y_train, test_size=0.25, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1009603, 105), (1009603,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3028806, 105), (3028806,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "kmWyRAR0N_XN",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3028806 samples, validate on 1009603 samples\n",
      "Epoch 1/100\n",
      "3028806/3028806 [==============================] - 14s 5us/sample - loss: 0.0142 - accuracy: 0.9997 - val_loss: 9.5049e-04 - val_accuracy: 0.9999\n",
      "Epoch 2/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 0.0011 - accuracy: 0.9999 - val_loss: 9.7495e-04 - val_accuracy: 0.9999\n",
      "Epoch 3/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 0.0011 - accuracy: 0.9999 - val_loss: 9.6065e-04 - val_accuracy: 0.9999\n",
      "Epoch 4/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 9.5261e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 9.5346e-04 - val_accuracy: 0.9999\n",
      "Epoch 6/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 9.3956e-04 - val_accuracy: 0.9999\n",
      "Epoch 7/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 9.4581e-04 - val_accuracy: 0.9999\n",
      "Epoch 8/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.9866e-04 - accuracy: 0.9999 - val_loss: 9.3055e-04 - val_accuracy: 0.9999\n",
      "Epoch 9/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.8978e-04 - accuracy: 0.9999 - val_loss: 9.2929e-04 - val_accuracy: 0.9999\n",
      "Epoch 10/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.9538e-04 - accuracy: 0.9999 - val_loss: 9.2484e-04 - val_accuracy: 0.9999\n",
      "Epoch 11/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.8339e-04 - accuracy: 0.9999 - val_loss: 9.3084e-04 - val_accuracy: 0.9999\n",
      "Epoch 12/100\n",
      "3027456/3028806 [============================>.] - ETA: 0s - loss: 9.8071e-04 - accuracy: 0.9999\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.8032e-04 - accuracy: 0.9999 - val_loss: 9.2504e-04 - val_accuracy: 0.9999\n",
      "Epoch 13/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.7294e-04 - accuracy: 0.9999 - val_loss: 9.2983e-04 - val_accuracy: 0.9999\n",
      "Epoch 14/100\n",
      "3028806/3028806 [==============================] - 14s 5us/sample - loss: 9.6968e-04 - accuracy: 0.9999 - val_loss: 9.2511e-04 - val_accuracy: 0.9999\n",
      "Epoch 15/100\n",
      "3028806/3028806 [==============================] - 14s 5us/sample - loss: 9.6104e-04 - accuracy: 0.9999 - val_loss: 9.3128e-04 - val_accuracy: 0.9999\n",
      "Epoch 16/100\n",
      "3028806/3028806 [==============================] - 14s 5us/sample - loss: 9.7134e-04 - accuracy: 0.9999 - val_loss: 9.3631e-04 - val_accuracy: 0.9999\n",
      "Epoch 17/100\n",
      "3028806/3028806 [==============================] - 14s 4us/sample - loss: 9.6751e-04 - accuracy: 0.9999 - val_loss: 9.2075e-04 - val_accuracy: 0.9999\n",
      "Epoch 18/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.5748e-04 - accuracy: 0.9999 - val_loss: 9.2477e-04 - val_accuracy: 0.9999\n",
      "Epoch 19/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.6324e-04 - accuracy: 0.9999 - val_loss: 9.2084e-04 - val_accuracy: 0.9999\n",
      "Epoch 20/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.6438e-04 - accuracy: 0.9999 - val_loss: 9.2561e-04 - val_accuracy: 0.9999\n",
      "Epoch 21/100\n",
      "3028806/3028806 [==============================] - 15s 5us/sample - loss: 9.5102e-04 - accuracy: 0.9999 - val_loss: 9.2121e-04 - val_accuracy: 0.9999\n",
      "Epoch 22/100\n",
      "3028806/3028806 [==============================] - 15s 5us/sample - loss: 9.5955e-04 - accuracy: 0.9999 - val_loss: 9.2069e-04 - val_accuracy: 0.9999\n",
      "Epoch 23/100\n",
      "3028806/3028806 [==============================] - 15s 5us/sample - loss: 9.5500e-04 - accuracy: 0.9999 - val_loss: 9.2311e-04 - val_accuracy: 0.9999\n",
      "Epoch 24/100\n",
      "3028806/3028806 [==============================] - 14s 5us/sample - loss: 9.6311e-04 - accuracy: 0.9999 - val_loss: 9.2351e-04 - val_accuracy: 0.9999\n",
      "Epoch 25/100\n",
      "3025920/3028806 [============================>.] - ETA: 0s - loss: 9.4907e-04 - accuracy: 0.9999\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4827e-04 - accuracy: 0.9999 - val_loss: 9.2094e-04 - val_accuracy: 0.9999\n",
      "Epoch 26/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.5218e-04 - accuracy: 0.9999 - val_loss: 9.2249e-04 - val_accuracy: 0.9999\n",
      "Epoch 27/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.5405e-04 - accuracy: 0.9999 - val_loss: 9.2344e-04 - val_accuracy: 0.9999\n",
      "Epoch 28/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.5548e-04 - accuracy: 0.9999 - val_loss: 9.2052e-04 - val_accuracy: 0.9999\n",
      "Epoch 29/100\n",
      "3028806/3028806 [==============================] - 14s 4us/sample - loss: 9.4079e-04 - accuracy: 0.9999 - val_loss: 9.2099e-04 - val_accuracy: 0.9999\n",
      "Epoch 30/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4640e-04 - accuracy: 0.9999 - val_loss: 9.2173e-04 - val_accuracy: 0.9999\n",
      "Epoch 31/100\n",
      "3028806/3028806 [==============================] - 14s 5us/sample - loss: 9.4491e-04 - accuracy: 0.9999 - val_loss: 9.2182e-04 - val_accuracy: 0.9999\n",
      "Epoch 32/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4747e-04 - accuracy: 0.9999 - val_loss: 9.2089e-04 - val_accuracy: 0.9999\n",
      "Epoch 33/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4085e-04 - accuracy: 0.9999 - val_loss: 9.2104e-04 - val_accuracy: 0.9999\n",
      "Epoch 34/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4888e-04 - accuracy: 0.9999 - val_loss: 9.2125e-04 - val_accuracy: 0.9999\n",
      "Epoch 35/100\n",
      "3027968/3028806 [============================>.] - ETA: 0s - loss: 9.4940e-04 - accuracy: 0.9999\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4917e-04 - accuracy: 0.9999 - val_loss: 9.2066e-04 - val_accuracy: 0.9999\n",
      "Epoch 36/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4664e-04 - accuracy: 0.9999 - val_loss: 9.2096e-04 - val_accuracy: 0.9999\n",
      "Epoch 37/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4093e-04 - accuracy: 0.9999 - val_loss: 9.2199e-04 - val_accuracy: 0.9999\n",
      "Epoch 38/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4495e-04 - accuracy: 0.9999 - val_loss: 9.2080e-04 - val_accuracy: 0.9999\n",
      "Epoch 39/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4754e-04 - accuracy: 0.9999 - val_loss: 9.2217e-04 - val_accuracy: 0.9999\n",
      "Epoch 40/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4444e-04 - accuracy: 0.9999 - val_loss: 9.2143e-04 - val_accuracy: 0.9999\n",
      "Epoch 41/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4886e-04 - accuracy: 0.9999 - val_loss: 9.2098e-04 - val_accuracy: 0.9999\n",
      "Epoch 42/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4962e-04 - accuracy: 0.9999 - val_loss: 9.2195e-04 - val_accuracy: 0.9999\n",
      "Epoch 43/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.5155e-04 - accuracy: 0.9999 - val_loss: 9.2082e-04 - val_accuracy: 0.9999\n",
      "Epoch 44/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.3718e-04 - accuracy: 0.9999 - val_loss: 9.2092e-04 - val_accuracy: 0.9999\n",
      "Epoch 45/100\n",
      "3021312/3028806 [============================>.] - ETA: 0s - loss: 9.4201e-04 - accuracy: 0.9999\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.3992e-04 - accuracy: 0.9999 - val_loss: 9.2102e-04 - val_accuracy: 0.9999\n",
      "Epoch 46/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4143e-04 - accuracy: 0.9999 - val_loss: 9.2100e-04 - val_accuracy: 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3635e-04 - accuracy: 0.9999 - val_loss: 9.2109e-04 - val_accuracy: 0.9999\n",
      "Epoch 48/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4038e-04 - accuracy: 0.9999 - val_loss: 9.2114e-04 - val_accuracy: 0.9999\n",
      "Epoch 49/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4076e-04 - accuracy: 0.9999 - val_loss: 9.2080e-04 - val_accuracy: 0.9999\n",
      "Epoch 50/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4548e-04 - accuracy: 0.9999 - val_loss: 9.2103e-04 - val_accuracy: 0.9999\n",
      "Epoch 51/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3649e-04 - accuracy: 0.9999 - val_loss: 9.2111e-04 - val_accuracy: 0.9999\n",
      "Epoch 52/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3718e-04 - accuracy: 0.9999 - val_loss: 9.2129e-04 - val_accuracy: 0.9999\n",
      "Epoch 53/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4045e-04 - accuracy: 0.9999 - val_loss: 9.2098e-04 - val_accuracy: 0.9999\n",
      "Epoch 54/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4161e-04 - accuracy: 0.9999 - val_loss: 9.2117e-04 - val_accuracy: 0.9999\n",
      "Epoch 55/100\n",
      "3025408/3028806 [============================>.] - ETA: 0s - loss: 9.4213e-04 - accuracy: 0.9999\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4430e-04 - accuracy: 0.9999 - val_loss: 9.2091e-04 - val_accuracy: 0.9999\n",
      "Epoch 56/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3765e-04 - accuracy: 0.9999 - val_loss: 9.2101e-04 - val_accuracy: 0.9999\n",
      "Epoch 57/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4310e-04 - accuracy: 0.9999 - val_loss: 9.2103e-04 - val_accuracy: 0.9999\n",
      "Epoch 58/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3906e-04 - accuracy: 0.9999 - val_loss: 9.2102e-04 - val_accuracy: 0.9999\n",
      "Epoch 59/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3938e-04 - accuracy: 0.9999 - val_loss: 9.2100e-04 - val_accuracy: 0.9999\n",
      "Epoch 60/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3903e-04 - accuracy: 0.9999 - val_loss: 9.2095e-04 - val_accuracy: 0.9999\n",
      "Epoch 61/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4417e-04 - accuracy: 0.9999 - val_loss: 9.2083e-04 - val_accuracy: 0.9999\n",
      "Epoch 62/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4069e-04 - accuracy: 0.9999 - val_loss: 9.2081e-04 - val_accuracy: 0.9999\n",
      "Epoch 63/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4498e-04 - accuracy: 0.9999 - val_loss: 9.2080e-04 - val_accuracy: 0.9999\n",
      "Epoch 64/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4064e-04 - accuracy: 0.9999 - val_loss: 9.2077e-04 - val_accuracy: 0.9999\n",
      "Epoch 65/100\n",
      "3022336/3028806 [============================>.] - ETA: 0s - loss: 9.4064e-04 - accuracy: 0.9999\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4196e-04 - accuracy: 0.9999 - val_loss: 9.2078e-04 - val_accuracy: 0.9999\n",
      "Epoch 66/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3461e-04 - accuracy: 0.9999 - val_loss: 9.2085e-04 - val_accuracy: 0.9999\n",
      "Epoch 67/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4069e-04 - accuracy: 0.9999 - val_loss: 9.2087e-04 - val_accuracy: 0.9999\n",
      "Epoch 68/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4187e-04 - accuracy: 0.9999 - val_loss: 9.2087e-04 - val_accuracy: 0.9999\n",
      "Epoch 69/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4056e-04 - accuracy: 0.9999 - val_loss: 9.2087e-04 - val_accuracy: 0.9999\n",
      "Epoch 70/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.3883e-04 - accuracy: 0.9999 - val_loss: 9.2089e-04 - val_accuracy: 0.9999\n",
      "Epoch 71/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.3811e-04 - accuracy: 0.9999 - val_loss: 9.2089e-04 - val_accuracy: 0.9999\n",
      "Epoch 72/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4186e-04 - accuracy: 0.9999 - val_loss: 9.2086e-04 - val_accuracy: 0.9999\n",
      "Epoch 73/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.3931e-04 - accuracy: 0.9999 - val_loss: 9.2089e-04 - val_accuracy: 0.9999\n",
      "Epoch 74/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4284e-04 - accuracy: 0.9999 - val_loss: 9.2086e-04 - val_accuracy: 0.9999\n",
      "Epoch 75/100\n",
      "3022848/3028806 [============================>.] - ETA: 0s - loss: 9.4309e-04 - accuracy: 0.9999\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4143e-04 - accuracy: 0.9999 - val_loss: 9.2085e-04 - val_accuracy: 0.9999\n",
      "Epoch 76/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4631e-04 - accuracy: 0.9999 - val_loss: 9.2082e-04 - val_accuracy: 0.9999\n",
      "Epoch 77/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.3968e-04 - accuracy: 0.9999 - val_loss: 9.2082e-04 - val_accuracy: 0.9999\n",
      "Epoch 78/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.3872e-04 - accuracy: 0.9999 - val_loss: 9.2083e-04 - val_accuracy: 0.9999\n",
      "Epoch 79/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4248e-04 - accuracy: 0.9999 - val_loss: 9.2082e-04 - val_accuracy: 0.9999\n",
      "Epoch 80/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4414e-04 - accuracy: 0.9999 - val_loss: 9.2081e-04 - val_accuracy: 0.9999\n",
      "Epoch 81/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.3757e-04 - accuracy: 0.9999 - val_loss: 9.2082e-04 - val_accuracy: 0.9999\n",
      "Epoch 82/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4319e-04 - accuracy: 0.9999 - val_loss: 9.2081e-04 - val_accuracy: 0.9999\n",
      "Epoch 83/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.3717e-04 - accuracy: 0.9999 - val_loss: 9.2085e-04 - val_accuracy: 0.9999\n",
      "Epoch 84/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4066e-04 - accuracy: 0.9999 - val_loss: 9.2083e-04 - val_accuracy: 0.9999\n",
      "Epoch 85/100\n",
      "3019776/3028806 [============================>.] - ETA: 0s - loss: 9.4120e-04 - accuracy: 0.9999\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4233e-04 - accuracy: 0.9999 - val_loss: 9.2083e-04 - val_accuracy: 0.9999\n",
      "Epoch 86/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4000e-04 - accuracy: 0.9999 - val_loss: 9.2082e-04 - val_accuracy: 0.9999\n",
      "Epoch 87/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.3755e-04 - accuracy: 0.9999 - val_loss: 9.2084e-04 - val_accuracy: 0.9999\n",
      "Epoch 88/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.4130e-04 - accuracy: 0.9999 - val_loss: 9.2083e-04 - val_accuracy: 0.9999\n",
      "Epoch 89/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3924e-04 - accuracy: 0.9999 - val_loss: 9.2083e-04 - val_accuracy: 0.9999\n",
      "Epoch 90/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4022e-04 - accuracy: 0.9999 - val_loss: 9.2083e-04 - val_accuracy: 0.9999\n",
      "Epoch 91/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3807e-04 - accuracy: 0.9999 - val_loss: 9.2084e-04 - val_accuracy: 0.9999\n",
      "Epoch 92/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3582e-04 - accuracy: 0.9999 - val_loss: 9.2085e-04 - val_accuracy: 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "3028806/3028806 [==============================] - 13s 4us/sample - loss: 9.3956e-04 - accuracy: 0.9999 - val_loss: 9.2085e-04 - val_accuracy: 0.9999\n",
      "Epoch 94/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3954e-04 - accuracy: 0.9999 - val_loss: 9.2085e-04 - val_accuracy: 0.9999\n",
      "Epoch 95/100\n",
      "3015680/3028806 [============================>.] - ETA: 0s - loss: 9.4518e-04 - accuracy: 0.9999\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4151e-04 - accuracy: 0.9999 - val_loss: 9.2085e-04 - val_accuracy: 0.9999\n",
      "Epoch 96/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4182e-04 - accuracy: 0.9999 - val_loss: 9.2085e-04 - val_accuracy: 0.9999\n",
      "Epoch 97/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3652e-04 - accuracy: 0.9999 - val_loss: 9.2085e-04 - val_accuracy: 0.9999\n",
      "Epoch 98/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3898e-04 - accuracy: 0.9999 - val_loss: 9.2085e-04 - val_accuracy: 0.9999\n",
      "Epoch 99/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.3460e-04 - accuracy: 0.9999 - val_loss: 9.2086e-04 - val_accuracy: 0.9999\n",
      "Epoch 100/100\n",
      "3028806/3028806 [==============================] - 12s 4us/sample - loss: 9.4141e-04 - accuracy: 0.9999 - val_loss: 9.2086e-04 - val_accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# Define early stopping\n",
    "monitor = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor=0.5,mode=\"min\",patience=10,verbose=1,min_lr=1e-7)\n",
    "checkpoint = ModelCheckpoint('Best_Model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=512, callbacks=[monitor, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009603/1009603 [==============================] - 21s 21us/sample - loss: 9.2052e-04 - accuracy: 0.9999\n",
      "\n",
      "Test loss: 0.0009205229476393316\n",
      "Test accuracy: 0.99991083\n"
     ]
    }
   ],
   "source": [
    "# Load the best saved model\n",
    "best_model = load_model('Best_Model.h5')\n",
    "\n",
    "# Evaluate the best saved model\n",
    "score = best_model.evaluate(x_test, y_test)\n",
    "print('')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               27136     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 72,321\n",
      "Trainable params: 71,361\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJsAAAOjCAYAAAAceQVTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdf9ClZ33f98/3vo+EZJCQK22QkSgrg2pYmUHGW2psWjKGgoiTiKbChpoayxD9kRD8I3QqNzYQbE/Q1C52QLarBGFMY4QDYaqkEGwXMgPjBliwMCBQWQsoC2JYlt8EWTzPc/WP55xlWa2kR9JztNclvV4zz8w597nP0XW0/73nur6nWmsBAAAAgN0wnewFAAAAAHD/ITYBAAAAsGvEJgAAAAB2jdgEAAAAwK4RmwAAAADYNWITAAAAALtGbAIAWLOq2ltVraoWO7j3Z6vqPffFugAA1kFsAgA4RlV9qqpuq6pzjrv+F8tgtPfkrOzuRSsAgJNFbAIAuL1PJnnu6klVPS7J95y85QAAjENsAgC4vTck+Zljnj8/yR8ee0NVPbSq/rCqDlfVp6vqV6pqWr42V9VvVtUXq+rmJD9xgve+tqpuqarPVtWvV9V8bxZcVQ+qqt+uqs8t/367qh60fO2cqvp3VfWVqvpSVb37mLX+z8s1fL2qbqqqp96bdQAAiE0AALf3H5OcWVWPXUag5yT5P46759VJHprk+5M8Jdtx6vLla38/yd9O8kNJ9ie57Lj3/kGSjSSPXt7z9CQvvJdr/idJfiTJxUken+SJSX5l+do/TnIoyZ4kD0vyvyRpVfUDSV6U5L9srZ2R5BlJPnUv1wEAPMCJTQAAJ7ba3fTfJvlYks+uXjgmQP1ya+3rrbVPJfmtJP/j8pafTPLbrbXPtNa+lOSfHfPehyX5W0l+obX2zdbaF5K8avl598ZPJ3lFa+0LrbXDSf7pMev5dpLvS/LI1tq3W2vvbq21JJtJHpRkX1Wd0lr7VGvtr+7lOgCABzixCQDgxN6Q5H9I8rM57ghdknOSnJLk08dc+3SS85aPH57kM8e9tvLI5XtvWR5r+0qS/z3J37iX6334Cdbz8OXj/zXJwSR/UlU3V9WVSdJaO5jkF5K8PMkXquq6qnp4AADuBbEJAOAEWmufzvag8L+V5N8c9/IXs71b6JHHXPvP853dT7ckecRxr618JslfJzmntXbW8u/M1tpF93LJnzvBej63/C5fb63949ba9yf5u0l+aTWbqbX2R621Jy/f25JcdS/XAQA8wIlNAAB37AVJfry19s1jL7bWNpP8cZLfqKozquqRSX4p35nr9MdJXlxV51fV9ya58pj33pLkT5L8VlWdWVVTVT2qqp5yN9b1oKo67Zi/Kckbk/xKVe2pqnOSvHS1nqr621X16KqqJF/N9vG5rar6gar68eUg8VuTfCvJ1t38fwQA8F3EJgCAO9Ba+6vW2oE7ePkfJflmkpuTvCfJHyW5dvnav0jyjiQfSvLB3H5n1M8kOTXJjUm+nOTN2Z6ptFPfyHYYWv39eJJfT3IgyV8m+fDyv/vry/svTPJny/f9P0l+t7X2rmzPa3pltndqfT7bR/l++W6sAwDgdmp7NiQAAAAA3Ht2NgEAAACwa8QmAAAAAHaN2AQAAADArhGbAAAAANg1YhMAAAAAu2ZxshdwXzjnnHPa3r17T/YyAAAAAO43PvCBD3yxtbbn+OsPiNi0d+/eHDhw4GQvAwAAAOB+o6o+faLrjtEBAAAAsGvEJgAAAAB2jdgEAAAAwK55QMxsAgAAANgN3/72t3Po0KHceuutJ3sp95nTTjst559/fk455ZQd3S82AQAAAOzQoUOHcsYZZ2Tv3r2pqpO9nLVrreXIkSM5dOhQLrjggh29xzE6AAAAgB269dZbc/bZZz8gQlOSVFXOPvvsu7WTS2wCAAAAuBseKKFp5e5+X7EJAAAAYBBHjhzJxRdfnIsvvjjnnntuzjvvvKPPb7vtth19xuWXX56bbrppbWs0swkAAABgEGeffXZuuOGGJMnLX/7yPOQhD8lLXvKS77qntZbWWqbpxHuMXve61611jXY2AQAAAAzu4MGD2bdvX376p386F110UW655ZZcccUV2b9/fy666KK84hWvOHrvk5/85Nxwww3Z2NjIWWedlSuvvDKPf/zj86QnPSlf+MIX7vVaxCYAAACA+4GPf/zj+cVf/MXceOONOe+88/LKV74yBw4cyIc+9KH86Z/+aW688cbbveerX/1qnvKUp+RDH/pQnvSkJ+Xaa6+91+twjA4AAADgHvin//ajufFzX9vVz9z38DPzsr9z0T1676Me9ajs37//6PM3vvGNee1rX5uNjY187nOfy4033ph9+/Z913tOP/30PPOZz0yS/PAP/3De/e533/PFL4lNAAAAAPcDD37wg48+/sQnPpHf+Z3fyfve976cddZZed7znpdbb731du859dRTjz6e5zkbGxv3eh1iEwAAAMA9cE93IN0Xvva1r+WMM87ImWeemVtuuSXveMc7cskll9wn/22xCQAAAOB+5glPeEL27duXxzzmMXnkIx+ZH/uxH7vP/tvVWrvP/mMny/79+9uBAwdO9jIAAACAwX3sYx/LYx/72JO9jPvcib53VX2gtbb/+Hv9Gh0AAAAAu0ZsAgAAAGDXiE0AAAAA7BqxCQAAAIBdIzYBAAAAsGvEJgAAAAB2jdgEAAAAMIgjR47k4osvzsUXX5xzzz0355133tHnt912244/59prr83nP//5taxxsZZPBQAAAGDXnX322bnhhhuSJC9/+cvzkIc8JC95yUvu9udce+21ecITnpBzzz13t5coNgEAAADcH7z+9a/P1Vdfndtuuy0/+qM/mte85jXZ2trK5ZdfnhtuuCGttVxxxRV52MMelhtuuCE/9VM/ldNPPz3ve9/7cuqpp+7aOsQmAAAAgMF95CMfyVvf+tb8+Z//eRaLRa644opcd911edSjHpUvfvGL+fCHP5wk+cpXvpKzzjorr371q/Oa17wmF1988a6vRWwCAAAAuCfefmXy+Q/v7mee+7jkma+822/7sz/7s7z//e/P/v37kyTf+ta38ohHPCLPeMYzctNNN+XFL35xfuInfiJPf/rTd3e9JyA2AQAAAAyutZaf+7mfy6/92q/d7rW//Mu/zNvf/vZcffXVectb3pJrrrlmrWsRmwAAAADuiXuwA2ldnva0p+Wyyy7Lz//8z+ecc87JkSNH8s1vfjOnn356TjvttDz72c/OhRdemBe+8IVJkjPOOCNf//rX17IWsQkAAABgcI973OPyspe9LE972tOytbWVU045Jb//+7+feZ7zghe8IK21VFWuuuqqJMnll1+eF77whWsZEF6ttV37sF7t37+/HThw4GQvAwAAABjcxz72sTz2sY892cu4z53oe1fVB1pr+4+/d7rPVgUAAADA/Z7YBAAAAMCuEZsAAAAA2DViEwAAAMDd8ECYf32su/t9xSYAAACAHTrttNNy5MiRB0xwaq3lyJEjOe2003b8nsUa18Mu+tqt385nv/ytXHDOg3PaKfPJXg4AAAA8IJ1//vk5dOhQDh8+fLKXcp857bTTcv755+/4frFpEO/5xBfzD/7VB/Pvf+G/zmPOPfNkLwcAAAAekE455ZRccMEFJ3sZXXOMbhDzVEmSza0HxjY9AAAAYExi0yDmEpsAAACA/olNg7CzCQAAABiB2DQIsQkAAAAYgdg0CLEJAAAAGIHYNIijsamJTQAAAEC/1hqbquqSqrqpqg5W1ZUneP1BVfWm5evvraq9y+tnV9W7quobVfWaO/js66vqI+tcf0/sbAIAAABGsLbYVFVzkquTPDPJviTPrap9x932giRfbq09Osmrkly1vH5rkl9N8pI7+Oy/l+Qb61h3rya/RgcAAAAMYJ07m56Y5GBr7ebW2m1Jrkty6XH3XJrk9cvHb07y1Kqq1to3W2vvyXZ0+i5V9ZAkv5Tk19e39P4sljubthyjAwAAADq2zth0XpLPHPP80PLaCe9prW0k+WqSs+/ic38tyW8l+U+7s8wxrI7RbWyKTQAAAEC/hhoQXlUXJ3lUa+2tO7j3iqo6UFUHDh8+fB+sbr1Wx+jsbAIAAAB6ts7Y9Nkkjzjm+fnLaye8p6oWSR6a5MidfOaTkuyvqk8leU+S/6Kq/sOJbmytXdNa299a279nz5579AV6sphXM5tO8kIAAAAA7sQ6Y9P7k1xYVRdU1alJnpPk+uPuuT7J85ePL0vyztbueOtOa+33WmsPb63tTfLkJP9va+1v7vrKO7Ta2bSxpTYBAAAA/Vqs64NbaxtV9aIk70gyJ7m2tfbRqnpFkgOtteuTvDbJG6rqYJIvZTtIJUmWu5fOTHJqVT0rydNbazeua729mw0IBwAAAAawttiUJK21tyV523HXXnrM41uTPPsO3rv3Lj77U0l+8F4vchCrX6NzjA4AAADo2VADwh/IpqOxSW0CAAAA+iU2DWIuO5sAAACA/olNg1jNbNo0swkAAADomNg0iKOxydYmAAAAoGNi0yCOHqOzsQkAAADomNg0iHk2IBwAAADon9g0CAPCAQAAgBGITYNYzWzaMiAcAAAA6JjYNIhVbNowtAkAAADomNg0iGVryqadTQAAAEDHxKZBVFXmqbK1JTYBAAAA/RKbBjJXZUNsAgAAADomNg1kmgwIBwAAAPomNg1kMU3ZtLMJAAAA6JjYNJCpIjYBAAAAXRObBjJPJTYBAAAAXRObBjJPUzbNbAIAAAA6JjYNZJ6SzU2xCQAAAOiX2DSQucrOJgAAAKBrYtNA5rmyZWYTAAAA0DGxaSBzVTbEJgAAAKBjYtNA5skxOgAAAKBvYtNA5qkMCAcAAAC6JjYNZDIgHAAAAOic2DSQhQHhAAAAQOfEpoEYEA4AAAD0TmwayDRVthyjAwAAADomNg1kMVU27WwCAAAAOiY2DWRyjA4AAADonNg0kHkyIBwAAADom9g0kHmqbJrZBAAAAHRMbBrIbGYTAAAA0DmxaSBziU0AAABA38SmgdjZBAAAAPRObBqI2AQAAAD0TmwayGRAOAAAANA5sWkgCzubAAAAgM6JTQMxIBwAAADondg0kHmqbIlNAAAAQMfEpoHMU2VDbAIAAAA6JjYNZJoqWwaEAwAAAB0TmwZiQDgAAADQO7FpIFM5RgcAAAD0TWwaiAHhAAAAQO/EpoEspsqmmU0AAABAx8SmgUxmNgEAAACdE5sGMpfYBAAAAPRNbBrIPFW2WtIcpQMAAAA6JTYNZJ4qSexuAgAAALolNg3kaGyyswkAAADolNg0kFVs2to6yQsBAAAAuANi00Dm2o5NG2oTAAAA0CmxaSCTnU0AAABA58SmgSwmO5sAAACAvolNA5kMCAcAAAA6JzYNZOEYHQAAANA5sWkgBoQDAAAAvRObBmJAOAAAANA7sWkgCzObAAAAgM6JTQM5OiDc1iYAAACgU2LTQFYzmza1JgAAAKBTYtNA5qM7mxyjAwAAAPokNg1EbAIAAAB6JzYNZF7+axkQDgAAAPRKbBrIPG3/c9nZBAAAAPRKbBrIdwaEi00AAABAn8SmgUyrY3RiEwAAANApsWkgi2Vt2jKzCQAAAOiU2DSQ1YDwDTubAAAAgE6JTQNZDQjfEpsAAACATolNA1kNCLezCQAAAOiV2DQQA8IBAACA3olNAzEgHAAAAOid2DQQA8IBAACA3olNA5mWM5sMCAcAAAB6JTYNZHWMzswmAAAAoFdi00AMCAcAAAB6JzYNZJ62j9FtGhAOAAAAdEpsGsjR2GRnEwAAANApsWkgc4lNAAAAQN/EpoHY2QQAAAD0TmwayCo2bZnZBAAAAHRKbBrIKjZt2NkEAAAAdEpsGshkZhMAAADQObFpIIvVMTqxCQAAAOiU2DQQx+gAAACA3olNA6mqTGVAOAAAANAvsWkw81R2NgEAAADdEpsGM1WZ2QQAAAB0S2wazGIqv0YHAAAAdEtsGszkGB0AAADQMbFpMPNUBoQDAAAA3RKbBuMYHQAAANAzsWkwU4lNAAAAQL/EpsHMdjYBAAAAHRObBjNPlU0zmwAAAIBOiU2DsbMJAAAA6JnYNJjZzCYAAACgY2LTYOapsuUYHQAAANApsWkw81TZ2BSbAAAAgD6JTYOZys4mAAAAoF9i02AWs5lNAAAAQL/EpsFMVdkQmwAAAIBOiU2DWRgQDgAAAHRMbBrMZEA4AAAA0DGxaTCzAeEAAABAx8SmwRgQDgAAAPRMbBrMVGITAAAA0C+xaTDzVNl0jA4AAADolNg0mHmqbG6d7FUAAAAAnNhaY1NVXVJVN1XVwaq68gSvP6iq3rR8/b1VtXd5/eyqeldVfaOqXnPM/d9TVf9XVX28qj5aVa9c5/p7NFdlc0ttAgAAAPq0tthUVXOSq5M8M8m+JM+tqn3H3faCJF9urT06yauSXLW8fmuSX03ykhN89G+21h6T5IeS/FhVPXMd6+/V9s4mx+gAAACAPq1zZ9MTkxxsrd3cWrstyXVJLj3unkuTvH75+M1JnlpV1Vr7ZmvtPdmOTke11v5Ta+1dy8e3JflgkvPX+B26M08VrQkAAADo1Tpj03lJPnPM80PLaye8p7W2keSrSc7eyYdX1VlJ/k6S//ter3Qg81TZcIwOAAAA6NSQA8KrapHkjUn+eWvt5ju454qqOlBVBw4fPnzfLnCNpqpoTQAAAECv1hmbPpvkEcc8P3957YT3LAPSQ5Mc2cFnX5PkE621376jG1pr17TW9rfW9u/Zs+duLbxnCzObAAAAgI6tMza9P8mFVXVBVZ2a5DlJrj/unuuTPH/5+LIk72yt3WlJqapfz3aU+oVdXu8QpqmyITYBAAAAnVqs64NbaxtV9aIk70gyJ7m2tfbRqnpFkgOtteuTvDbJG6rqYJIvZTtIJUmq6lNJzkxyalU9K8nTk3wtyT9J8vEkH6yqJHlNa+1frut79GYxVbbuvMcBAAAAnDRri01J0lp7W5K3HXftpcc8vjXJs+/gvXvv4GNrt9Y3onmqbGwa2gQAAAD0acgB4Q9kU1WcogMAAAB6JTYNZjEbEA4AAAD0S2wazFRiEwAAANAvsWkw85RsGhAOAAAAdEpsGsw8TdncammCEwAAANAhsWkwc23/GJ+TdAAAAECPxKbBzMt/MXObAAAAgB6JTYOZp+1/si3H6AAAAIAOiU2DWe1s2rCzCQAAAOiQ2DSYaTmzyTE6AAAAoEdi02AW03JAuNgEAAAAdEhsGsy8jE2O0QEAAAA9EpsGM612NhkQDgAAAHRIbBrM6hidmU0AAABAj8SmwRgQDgAAAPRMbBrMYhabAAAAgH6JTYNZ7WwyIBwAAADokdg0mNmAcAAAAKBjYtNgDAgHAAAAeiY2DcaAcAAAAKBnYtNgZjubAAAAgI6JTYM5GpvMbAIAAAA6JDYNxs4mAAAAoGdi02BmM5sAAACAjolNg1ntbNoSmwAAAIAOiU2DWcWmDbEJAAAA6JDYNJjJgHAAAACgY2LTYBaO0QEAAAAdE5sGM5VjdAAAAEC/xKbBGBAOAAAA9ExsGszCzCYAAACgY2LTYI4OCLezCQAAAOiQ2DSYhdgEAAAAdExsGowB4QAAAEDPxKbBGBAOAAAA9ExsGowB4QAAAEDPxKbBGBAOAAAA9ExsGsxcYhMAAADQL7FpMPMsNgEAAAD9EpsGY2cTAAAA0DOxaTCzAeEAAABAx8Smwaxi05adTQAAAECHxKbBrI7RbYhNAAAAQIfEpsFMdjYBAAAAHRObBrSYyswmAAAAoEti04CmqRyjAwAAALokNg1oMZVjdAAAAECXxKYBzVXZ3DrZqwAAAAC4PbFpQNNU2dxSmwAAAID+iE0DMiAcAAAA6JXYNKDtnU1iEwAAANAfsWlA2zObxCYAAACgP2LTgObJgHAAAACgT2LTgGYDwgEAAIBOiU0DmqfKplN0AAAAQIfEpgHNU2XLzCYAAACgQ2LTgOaqbDhGBwAAAHRIbBrQZEA4AAAA0CmxaUCLqbLVHKMDAAAA+iM2DWiaKhtmNgEAAAAdEpsGNFcMCAcAAAC6JDYNaDFN2RSbAAAAgA6JTQOapohNAAAAQJfEpgEtpimbBoQDAAAAHRKbBjRNZWcTAAAA0CWxaUBzOUYHAAAA9ElsGtBsQDgAAADQKbFpQLMB4QAAAECnxKYBzVMZEA4AAAB0SWwa0DxN2bKzCQAAAOiQ2DSguZINsQkAAADokNg0oGkqM5sAAACALolNA1pMlS0zmwAAAIAOiU0DmqdyjA4AAADoktg0oKnKgHAAAACgS2LTgBZTZdMxOgAAAKBDYtOApqmyuSk2AQAAAP0RmwY0l51NAAAAQJ/EpgHNc2XTzCYAAACgQ2LTgOYSmwAAAIA+iU0DMiAcAAAA6JXYNKBpqrSWbNndBAAAAHRGbBrQXJUkdjcBAAAA3RGbBjTPy9hkZxMAAADQGbFpQEd3NolNAAAAQGfEpgHNk2N0AAAAQJ/EpgGtYpMB4QAAAEBvxKYBrWLThtgEAAAAdEZsGtBUdjYBAAAAfRKbBrQwswkAAADolNg0oGl1jG5TbAIAAAD6IjYNaF4do7OzCQAAAOiM2DSgxbw8RmdmEwAAANAZsWlAqwHhYhMAAADQG7FpQAaEAwAAAL0Smwa0GhBuZxMAAADQG7FpQLNjdAAAAECnxKYBzQaEAwAAAJ0SmwZkZxMAAADQK7FpQLOZTQAAAECnxKYBzX6NDgAAAOiU2DQgO5sAAACAXolNA5rMbAIAAAA6JTYNaLHc2bTlGB0AAADQGbFpQKtjdBubYhMAAADQF7FpQKtjdHY2AQAAAL0Rmwa0mFczm07yQgAAAACOIzYNaLWzaWNLbQIAAAD6IjYNaDYgHAAAAOiU2DSg1a/ROUYHAAAA9EZsGtB0NDapTQAAAEBf1hqbquqSqrqpqg5W1ZUneP1BVfWm5evvraq9y+tnV9W7quobVfWa497zw1X14eV7/nnVcoDRA4idTQAAAECv1habqmpOcnWSZybZl+S5VbXvuNtekOTLrbVHJ3lVkquW129N8qtJXnKCj/69JH8/yYXLv0t2f/V9Ww0I3zSzCQAAAOjMOnc2PTHJwdbaza2125Jcl+TS4+65NMnrl4/fnOSpVVWttW+21t6T7eh0VFV9X5IzW2v/sbXWkvxhkmet8Tt0aTUgfNPWJgAAAKAz64xN5yX5zDHPDy2vnfCe1tpGkq8mOfsuPvPQXXzm/d7R2GRjEwAAANCZ++2A8Kq6oqoOVNWBw4cPn+zl7KrZgHAAAACgU+uMTZ9N8ohjnp+/vHbCe6pqkeShSY7cxWeefxefmSRprV3TWtvfWtu/Z8+eu7n0vs1lQDgAAADQp3XGpvcnubCqLqiqU5M8J8n1x91zfZLnLx9fluSdy1lMJ9RauyXJ16rqR5a/QvczSf7P3V9631Y7m7YMCAcAAAA6s1jXB7fWNqrqRUnekWROcm1r7aNV9YokB1pr1yd5bZI3VNXBJF/KdpBKklTVp5KcmeTUqnpWkqe31m5M8g+S/EGS05O8ffn3gLKKTRuGNgEAAACdWVtsSpLW2tuSvO24ay895vGtSZ59B+/dewfXDyT5wd1b5XiWrSmbdjYBAAAAnbnfDgi/P6uqzFNla0tsAgAAAPoiNg1qrsqG2AQAAAB0Rmwa1DQZEA4AAAD0R2wa1GKasmlnEwAAANAZsWlQU0VsAgAAALojNg1qnkpsAgAAALojNg1qnqZsmtkEAAAAdEZsGtQ8JZubYhMAAADQF7FpUAs7mwAAAIAOiU2DmqZky8wmAAAAoDNi06DmqmyITQAAAEBnxKZBzVM5RgcAAAB0R2wa1DyVAeEAAABAd8SmQU1lZxMAAADQH7FpUIu5DAgHAAAAuiM2DcqAcAAAAKBHYtOgpqmy5RgdAAAA0BmxaVCLqbJpZxMAAADQGbFpUJNjdAAAAECHxKZBzZMB4QAAAEB/xKZBzVNl08wmAAAAoDNi06BmM5sAAACADolNgzIgHAAAAOiR2DSoqcQmAAAAoD9i06AcowMAAAB6JDYNyoBwAAAAoEdi06DsbAIAAAB6JDYNajazCQAAAOiQ2DSoeapsiU0AAABAZ8SmQc1TZUNsAgAAADojNg1qmipbBoQDAAAAnRGbBrUwIBwAAADokNg0qKkcowMAAAD6IzYNyoBwAAAAoEdi06AWU2XTzCYAAACgM2LToCYzmwAAAIAOiU2DmktsAgAAAPojNg1qnipbLWmO0gEAAAAdEZsGNU+VJHY3AQAAAF0RmwZ1NDbZ2QQAAAB0RGwa1Co2bW2d5IUAAAAAHENsGtRc27FpQ20CAAAAOiI2DcrOJgAAAKBHYtOgVrHJziYAAACgJ2LToCYDwgEAAIAOiU2DWjhGBwAAAHRIbBqUAeEAAABAj8SmQU12NgEAAAAdEpsGtTCzCQAAAOiQ2DSoowPCbW0CAAAAOiI2DWo1s2lTawIAAAA6IjYNaj66s8kxOgAAAKAfYtOgxCYAAACgR2LToOblv5wB4QAAAEBPxKZBzdP2P52dTQAAAEBPxKZBfWdAuNgEAAAA9ENsGpSZTQAAAECPxKZBrWLTlplNAAAAQEfEpkGtBoRv2NkEAAAAdERsGtRqQPiW2AQAAAB0RGwa1GpAuJ1NAAAAQE/EpkEtNzYZEA4AAAB0RWwa1GJ1jM6AcAAAAKAjYtOgDAgHAAAAeiQ2DWpazmwyIBwAAADoidg0qNUxOjObAAAAgJ6ITYMyIBwAAADokdg0qHnaPka3aUA4AAAA0BGxaVBHY5OdTQAAAEBHxKZBzSU2AQAAAP0RmwZlQDgAAADQI7FpUKsB4VtmNgEAAAAdEZsGtZrZtGFnEwAAANARsWlQBoQDAAAAPRKbBrUaEL4lNgEAAAAdEZsG5RgdAAAA0COxaVBVlakMCAcAAAD6IjYNbJ7KziYAAACgK2LTwKYqM5sAAACArohNA1tM5dfoAAAAgK6ITQObHKMDAAAAOiM2DWyeyoBwAAAAoCti08AcowMAAAB6IzYNbCqxCQAAAOiL2DSw2c4mAAAAoDNi0zAaDzEAACAASURBVMDmqbJpZhMAAADQEbFpYHY2AQAAAL0RmwYmNgEAAAC9EZsGNldlyzE6AAAAoCNi08DmqbKxKTYBAAAA/RCbBjZPdjYBAAAAfRGbBmZmEwAAANAbsWlgU1U2xCYAAACgI2LTwBaO0QEAAACdEZsGNhkQDgAAAHRGbBrYXHY2AQAAAH0Rmwa2mA0IBwAAAPoiNg1sKrEJAAAA6IvYNLB5qmw6RgcAAAB0RGwa2DxVNrdO9ioAAAAAvkNsGthclc0ttQkAAADoh9g0sO2dTY7RAQAAAP0QmwY2TxWtCQAAAOiJ2DSweapsOEYHAAAAdERsGtg8VbQmAAAAoCdi08C2B4Q7RwcAAAD0Q2wa2DRVNsQmAAAAoCNi08AWU2WriU0AAABAP8Smgc1TZWPT0CYAAACgH2LTwKaqOEUHAAAA9GStsamqLqmqm6rqYFVdeYLXH1RVb1q+/t6q2nvMa7+8vH5TVT3jmOu/WFUfraqPVNUbq+q0dX6Hni1mA8IBAACAvqwtNlXVnOTqJM9Msi/Jc6tq33G3vSDJl1trj07yqiRXLd+7L8lzklyU5JIkv1tVc1Wdl+TFSfa31n4wyby87wFp8mt0AAAAQGfWubPpiUkOttZubq3dluS6JJced8+lSV6/fPzmJE+tqlpev6619tettU8mObj8vCRZJDm9qhZJvifJ59b4Hbo2T8mmAeEAAABAR9YZm85L8pljnh9aXjvhPa21jSRfTXL2Hb23tfbZJL+Z5P9LckuSr7bW/mQtqx/APE3Z3GppghMAAADQiaEGhFfV92Z719MFSR6e5MFV9bw7uPeKqjpQVQcOHz58Xy7zPjNXJYkh4QAAAEA31hmbPpvkEcc8P3957YT3LI/FPTTJkTt579OSfLK1dri19u0k/ybJj57oP95au6a1tr+1tn/Pnj278HX6My//9cxtAgAAAHqxztj0/iQXVtUFVXVqtgd5X3/cPdcnef7y8WVJ3tm2z4Rdn+Q5y1+ruyDJhUnel+3jcz9SVd+znO301CQfW+N36No8bf/zbTlGBwAAAHRisa4Pbq1tVNWLkrwj278ad21r7aNV9YokB1pr1yd5bZI3VNXBJF/K8pfllvf9cZIbk2wk+Yettc0k762qNyf54PL6XyS5Zl3foXernU0bdjYBAAAAnVhbbEqS1trbkrztuGsvPebxrUmefQfv/Y0kv3GC6y9L8rLdXemYVjubHKMDAAAAejHUgHC+27w9HzxbYhMAAADQCbFpYPO0XZscowMAAAB6ITYNzIBwAAAAoDdi08BWA8LNbAIAAAB6ITYNbKrtY3RiEwAAANALsWlgi1lsAgAAAPoiNg1stbPJgHAAAACgF2LTwFa/RmdAOAAAANALsWlgi8kxOgAAAKAvYtPADAgHAAAAeiM2DWy2swkAAADojNg0sKOxycwmAAAAoBNi08DsbAIAAAB6s6PYVFWPqqoHLR//zap6cVWdtd6lcVdmM5sAAACAzux0Z9NbkmxW1aOTXJPkEUn+aG2rYkdWO5u2xCYAAACgEzuNTVuttY0k/12SV7fW/qck37e+ZbETq9i0ITYBAAAAndhpbPp2VT03yfOT/LvltVPWsyR2yoBwAAAAoDc7jU2XJ3lSkt9orX2yqi5I8ob1LYudcIwOAAAA6M1iJze11m5M8uIkqarvTXJGa+2qdS6MuzaVY3QAAABAX3b6a3T/oarOrKr/LMkHk/yLqvrf1rs07spitrMJAAAA6MtOj9E9tLX2tSR/L8kfttb+qyRPW9+y2Im5zGwCAAAA+rLT2LSoqu9L8pP5zoBwTrJpNSDcziYAAACgEzuNTa9I8o4kf9Vae39VfX+ST6xvWezEQmwCAAAAOrPTAeH/Osm/Pub5zUn++3Utip0xIBwAAADozU4HhJ9fVW+tqi8s/95SVeeve3HcuXkyIBwAAADoy06P0b0uyfVJHr78+7fLa5xER4/RGRAOAAAAdGKnsWlPa+11rbWN5d8fJNmzxnWxAwaEAwAAAL3ZaWw6UlXPq6p5+fe8JEfWuTDu2lxiEwAAANCXncamn0vyk0k+n+SWJJcl+dk1rYkdmmexCQAAAOjLjmJTa+3TrbW/21rb01r7G621Z8Wv0Z10djYBAAAAvdnpzqYT+aVdWwX3yGxAOAAAANCZexObatdWwT2yik1bdjYBAAAAnbg3sUnhOMlWx+g2xCYAAACgE4s7e7Gqvp4TR6VKcvpaVsSOTVOlys4mAAAAoB93Gptaa2fcVwvhnpmrzGwCAAAAunFvjtHRgWkqx+gAAACAbohNg1tM5RgdAAAA0A2xaXBzVTa3TvYqAAAAALaJTYObpsrmltoEAAAA9EFsGtxiMiAcAAAA6IfYNLjtnU1iEwAAANAHsWlw2zObxCYAAACgD2LT4ObJgHAAAACgH2LT4GYDwgEAAICOiE2Dm6fKplN0AAAAQCfEpsHNU2XLzCYAAACgE2LT4OaqbDhGBwAAAHRCbBqcAeEAAABAT8Smwc1TZas5RgcAAAD0QWwa3DRVNsxsAgAAADohNg1uYUA4AAAA0BGxaXBzVTbFJgAAAKATYtPgpiliEwAAANANsWlwi2nKpgHhAAAAQCfEpsFNk2N0AAAAQD/EpsHN5RgdAAAA0A+xaXDzNIlNAAAAQDfEpsHNBoQDAAAAHRGbBjdPZUA4AAAA0A2xaXDzNGXLziYAAACgE2LT4OZKNsQmAAAAoBNi0+CmqcxsAgAAALohNg1uMVW2zGwCAAAAOiE2DW6eyjE6AAAAoBti0+DmqQwIBwAAALohNg1ursqmY3QAAABAJ8SmwU1TZXNTbAIAAAD6IDYNbjHZ2QQAAAD0Q2wa3DRVNs1sAgAAADohNg1uLrEJAAAA6IfYNDjH6AAAAICeiE2Dm6ZKa8mW3U0AAABAB8Smwc1VSWJ3EwAAANAFsWlw87yMTXY2AQAAAB0QmwZ3dGeT2AQAAAB0QGwa3Dw5RgcAAAD0Q2wa3Co2GRAOAAAA9EBsGtwqNm2ITQAAAEAHxKbBTWVnEwAAANAPsWlwCzObAAAAgI6ITYObVsfoNsUmAAAA4OQTmwa32tm0ZWcTAAAA0AGxaXCrAeGbZjYBAAAAHRCbBrcaEC42AQAAAD0QmwZnQDgAAADQE7FpcJNjdAAAAEBHxKbBzY7RAQAAAB0RmwY3z2ITAAAA0A+xaXB2NgEAAAA9EZsGN5vZBAAAAHREbBrc7NfoAAAAgI6ITYOzswkAAADoidg0uMnMJgAAAKAjYtPgFsudTVuO0QEAAAAdEJsGtzpGt7EpNgEAAAAnn9g0uNnOJgAAAKAjYtPgvjMg/CQvBAAAACBi0/BWA8I3ttQmAAAA4OQTmwZnQDgAAADQE7FpcI7RAQAAAD0RmwY3HY1NahMAAABw8olNg1vY2QQAAAB0RGwa3GpA+KaZTQAAAEAHxKbBHZ3ZZGsTAAAA0AGxaXBHY5ONTQAAAEAHxKbBzQaEAwAAAB0RmwY3lwHhAAAAQD/EpsGtdjZtGRAOAAAAdEBsGtwqNm0Y2gQAAAB0QGwa3LI1ZdPOJgAAAKADa41NVXVJVd1UVQer6soTvP6gqnrT8vX3VtXeY1775eX1m6rqGcdcP6uq3lxVH6+qj1XVk9b5HXpXVZmnytaW2AQAAACcfGuLTVU1J7k6yTOT7Evy3Krad9xtL0jy5dbao5O8KslVy/fuS/KcJBcluSTJ7y4/L0l+J8m/b609Jsnjk3xsXd9hFHNVNsQmAAAAoAPr3Nn0xCQHW2s3t9ZuS3JdkkuPu+fSJK9fPn5zkqdWVS2vX9da++vW2ieTHEzyxKp6aJL/Jslrk6S1dltr7Str/A5DmKcyIBwAAADowjpj03lJPnPM80PLaye8p7W2keSrSc6+k/dekORwktdV1V9U1b+sqgevZ/njmKfKpp1NAAAAQAdGGxC+SPKEJL/XWvuhJN9McrtZUElSVVdU1YGqOnD48OH7co33uakiNgEAAABdWGds+mySRxzz/PzltRPeU1WLJA9NcuRO3nsoyaHW2nuX19+c7fh0O621a1pr+1tr+/fs2XMvv0rfFvMkNgEAAABdWGdsen+SC6vqgqo6NdsDv68/7p7rkzx/+fiyJO9srbXl9ecsf63ugiQXJnlfa+3zST5TVT+wfM9Tk9y4xu8whKkqm2Y2AQAAAB1YrOuDW2sbVfWiJO9IMie5trX20ap6RZIDrbXrsz3o+w1VdTDJl7IdpLK874+zHZI2kvzD1trm8qP/UZJ/tQxYNye5fF3fYRTzlGxuik0AwP/f3t3HyJbm9WH/PudUd9/b987O7Lywhp2FWWAcZ4mBJSNEYiuyIJKXGHkTBcIi28GICMnCCY7sOIv/IIqVtUQUGUKMLWHAITYyYIyTFVrZsQAnWEkWZs3rsmDGy8LusuzOy87u3Lfurqonf5xzqk/3vT1772zfOdVnPh+pdF6quuqpqnPq1PnW8/waAGB69y1sSpJa63uSvOfUuu8azd9K8g1n/O27krzrDut/OclT59vSi23RNHo2AQAAAFvhohUI5w6aJlmr2QQAAABsAWHTDLSlZClsAgAAALaAsGkG2kaBcAAAAGA7CJtmoG2KAuEAAADAVhA2zUBT9GwCAAAAtoOwaQYWbVEgHAAAANgKwqYZUCAcAAAA2BbCphlompK1YXQAAADAFhA2zcCiKVnp2QQAAABsAWHTDDSG0QEAAABbQtg0AwqEAwAAANtC2DQDTSlZqdkEAAAAbAFh0wy0ajYBAAAAW0LYNAMKhAMAAADbQtg0A00RNgEAAADbQdg0A4bRAQAAANtC2DQDbaNAOAAAALAdhE0z0DYlaz2bAAAAgC0gbJqBtpQshU0AAADAFhA2zYCeTQAAAMC2EDbNQNvo2QQAAABsB2HTDDRNyVqBcAAAAGALCJtmYNGUrPRsAgAAALaAsGkGGgXCAQAAgC0hbJqBhQLhAAAAwJYQNs1A25Ss1GwCAAAAtoCwaQYaNZsAAACALSFsmgEFwgEAAIBtIWyagaaUrGtSDaUDAAAAJiZsmoG2KUmidxMAAAAwOWHTDGzCJj2bAAAAgIkJm2ZgCJvW64kbAgAAALzmCZtmoC1d2LSUNgEAAAATEzbNgJ5NAAAAwLYQNs3AEDbp2QQAAABMTdg0A40C4QAAAMCWEDbNwMIwOgAAAGBLCJtmQIFwAAAAYFsIm2ag0bMJAAAA2BLCphlYqNkEAAAAbAlh0wxsCoTr2gQAAABMTNg0A5ueTbImAAAAYGLCphloyhA2GUYHAAAATEvYNANtI2wCAAAAtoOwaQYUCAcAAAC2hbBpBho9mwAAAIAtIWyagVbNJgAAAGBLCJtmQM0mAAAAYFsIm2ZgCJvWajYBAAAAExM2zUDbv4tLPZsAAACAiQmbZqBturdxLWwCAAAAJiZsmoGhQLieTQAAAMDUhE0z0HdsUiAcAAAAmJywaQYWwzA6BcIBAACAiQmbZkCBcAAAAGBbCJtmoOlrNikQDgAAAExN2DQDwzA6NZsAAACAqQmbZkCBcAAAAGBbCJtmYNOzSYFwAAAAYGLCphnQswkAAADYFsKmGWj7AuHCJgAAAGBqwqYZUCAcAAAA2BbCphkYhtGt1WwCAAAAJiZsmoG26YbRLfVsAgAAACYmbJqBIWwyjA4AAACYmrBpBoYC4WthEwAAADAxYdMMGEYHAAAAbAth0wyUUtIUBcIBAACA6QmbZqJtip5NAAAAwOSETTPRlKJmEwAAADA5YdNMLJriv9EBAAAAkxM2zURjGB0AAACwBYRNM7FoigLhAAAAwOSETTPRGkYHAAAAbAFh00w0RdgEAAAATE/YNBMKhAMAAADbQNg0E01TslKzCQAAAJiYsGkm1GwCAAAAtoGwaSaETQAAAMA2EDbNRFtK1obRAQAAABMTNs1E25QsV8ImAAAAYFrCpploGz2bAAAAgOkJm2ZCzSYAAABgGwibZqIpJUthEwAAADAxYdNMLAyjAwAAALaAsGkmGgXCAQAAgC0gbJqJtujZBAAAAExP2DQTi1aBcAAAAGB6wqaZaIqwCQAAAJiesGkmFk3JyjA6AAAAYGLCpplompLVeupWAAAAAK91wqaZaEvJai1tAgAAAKYlbJqJVoFwAAAAYAsIm2aiLSWyJgAAAGBqwqaZaJuSpWF0AAAAwMSETTPRNiWyJgAAAGBqwqaZ6AqEG0cHAAAATEvYNBNNU7IUNgEAAAATEzbNxKIpWVdhEwAAADAtYdNMtI1hdAAAAMD0hE0z0ajZBAAAAGwBYdNMLFphEwAAADA9YdNM6NkEAAAAbANh00y0TbJSIBwAAACYmLBpJtqmyWpdUwVOAAAAwISETTPRlpIkMZIOAAAAmJKwaSYWbRc2qdsEAAAATEnYNBPNpmeTsAkAAACYjrBpJtr+nVzq2QQAAABMSNg0E23TvZWG0QEAAABTEjbNRF+yKWthEwAAADCh+xo2lVLeVkr5rVLKM6WUd97h+r1Syo/317+3lPLE6Lrv7Nf/VinlT576u7aU8kullJ++n+2/SNqmS5sMowMAAACmdN/CplJKm+T7k3xtkrck+aZSyltO3exbk3yy1vrFSb4nyXf3f/uWJO9I8iVJ3pbkb/f3N/iOJB+4X22/iIZhdAqEAwAAAFO6nz2bvjLJM7XWD9ZaD5P8WJK3n7rN25P8SD//k0m+ppRS+vU/Vms9qLX+TpJn+vtLKeXxJH8qyQ/ex7ZfOEOBcDWbAAAAgCndz7DpjUk+PFr+SL/ujreptS6TfCrJI5/hb783yV9Nsj7/Jl9cTemG0QmbAAAAgCldqALhpZSvS/KJWuv77uK231ZKebqU8vSzzz77KrRuWotW2AQAAABM736GTR9N8qbR8uP9ujveppSySPJgkudf5m//WJI/XUr5ULpheV9dSvkHd3rwWusP1FqfqrU+9dhjj332z2bLDT2bFAgHAAAApnQ/w6ZfTPJkKeXNpZTddAW/333qNu9O8s39/Ncn+dlaa+3Xv6P/b3VvTvJkkl+otX5nrfXxWusT/f39bK31z97H53BhDP+NToFwAAAAYEqL+3XHtdZlKeUvJvlnSdokP1xrfX8p5a8nebrW+u4kP5Tk75dSnknyQroAKf3tfiLJbyRZJvn2WuvqfrV1DhaNYXQAAADA9O5b2JQktdb3JHnPqXXfNZq/leQbzvjbdyV518vc979I8i/Oo51zoEA4AAAAsA0uVIFwzqZAOAAAALANhE0zsenZpGYTAAAAMCFh00y0ajYBAAAAW0DYNBPCJgAAAGAbCJtmou2H0a2FTQAAAMCEhE0zMfRsWgqbAAAAgAkJm2ZiM4xOgXAAAABgQsKmmRjCJsPoAAAAgCkJm2aiKYbRAQAAANMTNs3EotWzCQAAAJiesGkmhv9Gp2YTAAAAMCVh00w0Q4FwPZsAAACACQmbZmIhbAIAAAC2gLBpJhQIBwAAALaBsGkm2kaBcAAAAGB6wqaZ2AyjUyAcAAAAmJCwaSYUCAcAAAC2gbBpJhQIBwAAALaBsGkm9GwCAAAAtoGwaSbaImwCAAAApidsmolWgXAAAABgCwibZmIIm9Z6NgEAAAATEjbNxDCMbilsAgAAACYkbJqJpikpRc8mAAAAYFrCphlpS1GzCQAAAJiUsGlGmqYYRgcAAABMStg0I4umGEYHAAAATErYNCNtKVmtp24FAAAA8FombJqRpilZraVNAAAAwHSETTOyaBQIBwAAAKYlbJqRrmeTsAkAAACYjrBpRhbCJgAAAGBiwqYZaRQIBwAAACYmbJqRVoFwAAAAYGLCphnpCoRP3QoAAADgtUzYNCNNU7JWswkAAACYkLBpRtpSsjSMDgAAAJiQsGlGuppNU7cCAAAAeC0TNs1I25Ssq2F0AAAAwHSETTPSNCVLNZsAAACACQmbZmShQDgAAAAwMWHTjLSlZCVsAgAAACYkbJqRpomwCQAAAJiUsGlGFk2TlQLhAAAAwISETTPSNIbRAQAAANMSNs1IWwyjAwAAAKYlbJqRtmmETQAAAMCkhE0z0ioQDgAAAExM2DQjCoQDAAAAUxM2zUjTlKz1bAIAAAAmJGyakbYkS2ETAAAAMCFh04woEA4AAABMTdg0I22TrNVsAgAAACYkbJqRtimG0QEAAACTEjbNSKtAOAAAADAxYdOMtKVkZRgdAAAAMCFh04w0TclqJWwCAAAApiNsmpFFo2cTAAAAMC1h04w0TclKzSYAAABgQsKmGWmLsAkAAACYlrBpRgyjAwAAAKYmbJqRpimpNVnr3QQAAABMRNg0I20pSaJ3EwAAADAZYdOMtG0fNunZBAAAAExE2DQjm55NwiYAAABgIsKmGWkbw+gAAACAaQmbZmQImxQIBwAAAKYibJqRIWxaCpsAAACAiQibZkTPJgAAAGBqwqYZ2RQIV7MJAAAAmIiwaUaaYRjdStgEAAAATEPYNCOLYRidnk0AAADARIRNMzLUbFqp2QQAAABMRNg0I00RNgEAAADTEjbNyDCMToFwAAAAYCrCphlpDKMDAAAAJiZsmpHWMDoAAABgYsKmGWlbYRMAAAAwLWHTjOjZBAAAAExN2DQjCzWbAAAAgIkJm2ak8d/oAAAAgIkJm2ak1bMJAAAAmJiwaUaETQAAAMDUhE0zMhQIXxtGBwAAAExE2DQjQ8+m5UrYBAAAAExD2DQjQ9ikZxMAAAAwFWHTjBzXbJq4IQAAAMBrlrBpRpq+ZtNyLW0CAAAApiFsmpGFYXQAAADAxIRNM2IYHQAAADA1YdOMNJuwSdoEAAAATEPYNCMLPZsAAACAiQmbZmQoEL5SswkAAACYiLBpRjY1m3RtAgAAACYibJqRTdikYxMAAAAwEWHTjLQKhAMAAAATEzbNiALhAAAAwNSETTMyFAhfKxAOAAAATETYNCPDMLqlok0AAADARIRNM9JnTVnp2QQAAABMRNg0I6WUtE3Jei1sAgAAAKYhbJqZtpQshU0AAADARIRNM9M2RYFwAAAAYDLCpplpm5KVnk0AAADARIRNM9OUCJsAAACAyQibZmbRNsImAAAAYDLCpplpSslKzSYAAABgIsKmmWmbZLUSNgEAAADTEDbNzKJp9GwCAAAAJiNsmpmmSdZqNgEAAAATua9hUynlbaWU3yqlPFNKeecdrt8rpfx4f/17SylPjK77zn79b5VS/mS/7k2llJ8rpfxGKeX9pZTvuJ/tv4jaUrIUNgEAAAATuW9hUymlTfL9Sb42yVuSfFMp5S2nbvatST5Za/3iJN+T5Lv7v31Lknck+ZIkb0vyt/v7Wyb5y7XWtyT5qiTffof7fE1rGwXCAQAAgOncz55NX5nkmVrrB2uth0l+LMnbT93m7Ul+pJ//ySRfU0op/fofq7Ue1Fp/J8kzSb6y1vqxWuu/SpJa60tJPpDkjffxOVw4bVMUCAcAAAAmcz/Dpjcm+fBo+SO5PRja3KbWukzyqSSP3M3f9kPu3prkvefY5guvVSAcAAAAmNCFLBBeSrma5B8n+Uu11k+fcZtvK6U8XUp5+tlnn311GzihVoFwAAAAYEL3M2z6aJI3jZYf79fd8TallEWSB5M8/3J/W0rZSRc0/Wit9afOevBa6w/UWp+qtT712GOPfZZP5eJQIBwAAACY0v0Mm34xyZOllDeXUnbTFfx+96nbvDvJN/fzX5/kZ2uttV//jv6/1b05yZNJfqGv5/RDST5Qa/2b97HtF1bblKwNowMAAAAmsrhfd1xrXZZS/mKSf5akTfLDtdb3l1L+epKna63vThcc/f1SyjNJXkgXSKW/3U8k+Y10/4Hu22utq1LKH0/y55L8Winll/uH+mu11vfcr+dx0bRNyUrPJgAAAGAi9y1sSpI+BHrPqXXfNZq/leQbzvjbdyV516l1/zJJOf+WzkdjGB0AAAAwoQtZIJyzLdqiQDgAAAAwGWHTzDSlZKVmEwAAADARYdPMqNkEAAAATEnYNDMLYRMAAAAwIWHTzDRF2AQAAABMR9g0M4bRAQAAAFMSNs1M2ygQDgAAAExH2DQzbVOy1rMJAAAAmIiwaWbapmQpbAIAAAAmImyambbo2QQAAABMR9g0M3o2AQAAAFMSNs1M25SsFQgHAAAAJiJsmpm2KVnp2QQAAABMRNg0M00xjA4AAACYjrBpZhaNAuEAAADAdIRNM9M2JSs1mwAAAICJCJtmplGzCQAAAJiQsGlmFsImAAAAYELCpplpSsm6JtVQOgAAAGACwqaZaZuSJHo3AQAAAJMQNs3MJmzSswkAAACYgLBpZoawab2euCEAAADAa5KwaWba0oVNS2kTAAAAMAFh08zo2QQAAABMSdg0M0PYpGcTAAAAMAVh08woEA4AAABMSdg0M4bRAQAAAFMSNs2MAuEAAADAlIRNM6NnEwAAADAlYdPMqNkEAAAATEnYNDPNEDbp2gQAAABMQNg0M4tN2DRxQwAAAIDXJGHTzDRlCJsMowMAAABefcKmmdnUbBI2AQAAABMQNs3MQoFwAAAAYELCpplp9GwCAAAAJiRsmplWzSYAAABgQsKmmVGzCQAAAJiSsGlmhrBprWYTAAAAMAFh08y0/Tu61LMJAAAAmICwaWbapntL18ImAAAAYALCppkZCoTr2QQAAABMQdg0MwqEAwAAAFMSNs2MAuEAAADAlIRNM6NAOAAAADAlYdPMKBAOAAAATEnYNDNDgXA1mwAAAIApCJtmpu/YJGwCAAAAJiFsmplFnzatFAgHAAAAJrCYugGcr6Fn00u3jvL7L97MjcNlrh2scuNgmeuHq1w/WOb64bKbHqzywKVFnnjkSp54dD9veng/e4t22icAAAAAXGjCppnZa7uw6G+85zfzN97zm/f0t6Ukn/fg5Tzx6H6+4JErefMjV/IFj+zniUev5PMeupz9nTZNU+5HswEALy5mFwAAGURJREFUAICZEDbNzIP7O/meb/yyvHD9KFd221zZW+TKXpsru4tc2Vtkf7fN1b1F9vcW2d9p8+lbR/md567nd5+/kQ89fz0feu56PvT8jbzn1z6WF28cnbjvUpL9ne4+r+4tNvd9PN+tv7TTZn+3zeWdNpf76f7ueL5rxx968FJ2WiM5AQAAYE6ETTP0n7z18bu+7UP7u3nr5+/mrZ//+tuue/HGYT70/I387vPX87FP3cqNg25I3vWDZa4dLruheQer/P6Lt04Mzbt5tLqrx95pS77w0at58g1X84ff8ED+8Buu5sk3PJAveHg/CyEUAAAAXEjCJs700P5uvnx/N1/+pofu6e/W65qD5To3Dpe5ebTKzcNVbhyuNvM3j1a5dmuZ33n+en774y/lVz7yYn76Vz+2+fvdtskXPnZlE0B9zgOXsrMo2Wmb7LRNdhdNdvv5nbZslvcWbdfT6tJC7SkAAACYiLCJc9c0pRsyt3v3gc+Nw2We+cS1/OuPX8tvf/yl/OuPv5T3/e4n8+5f+f1X1IadtnRD+3a7oX1XLw3D/Npc2mlzuFznoL/cOlp186emh8t19vfaPHh5Jw9d3s2D+zt56PJOHtrfyUP7u936/Z08eHkn+7tt2qbJoulCsbYp2WlLP+3WL5ouKLu006QUta8AAACYJ2HTRbc8TF78veSFf5O88MHk+X/TLS/2kiuPJVceTfYf7aab+ceS/YeTZnt6/+zvLvKljz+UL338ZC+qawfLfPrmUQ6X6xyt1jlcrXO0qieXl9301tG6G+J3sNxMh/nrB6t86mb3H/puHq6yt2iyt9N200WThy7vZO+BvezttLm0aLK30/WcunGwyos3D/PijaN8+IUb+fWbR3nxxtFdDxU8y7iOVTftamiNa1st+p5bi6afjubbfrrTNrm8O6qbtXt7Ta1xL6/1uualg2VeunWUl251r+1Lt5Z56eAon77ZrT9Yrje9yIbH2GmbLNqS3X469DB7YG+RBy7t5IFLizxwqQv3XkkR+VprjlY1y/U6tSbrWrOuSTbzNTXdfK3JTtvkwcs7abe0YP16XZNEQX0AAOA1Sdh0UVx/Lvno+7ow6YUPHodLL/5eUtfHt9t9IHn9E8nqIPnQv0xuvnDGHZbk8uuTyw8lu1eS3av99PR8v9zuJqlJ7U6iU2v/uMO6frm03f1eebQLtIaga/fKK3raV/vgZNvcOlrl0zeP8uIofFqtuyBsta45Wq2zHObX635dF5LdPFzmxuEqNzZDDLvlW0er/MGnjzZDDYfwZbnq72/d3d+9Gnp5rVY11w6Xm7fwfiile89eNwqgru4tslzXHBytc7Bc5dbROreWqxycmt5ru0pJHrq8k9df2c3D+7snp1d28vr93TxwaZEbh12dsev99NrBMjcOVrm2qTPWvf5tUzbDM3cXo0vbX/rl5Wqd6/37dv3g1PRwlRsHy9zow8iH93fzyNXdPHp1L49c3csjV3bz6NXdzfwjV/fy4OWdrOtxgHrUv9+n5w+X66xrzWqdrGpNrd32sFrXTTi3Wtes1938ur/Nuna3H4K68fW7i2bTjkeu7ubRK9304Su7ubRzb2H0EBgmSVOStil33YNvaOey31eW/fNYrmtKksu7bS4tXtl/w6y1G9Y7vM83Dleb1yJJuhgzd9z+SkkWTZO2yabnYtuULJqSpp8OvRf3Fvevx2KtdbP/D69PN12npPRh9NCDsnzG177WmsN+mxo+lw6XQ5jfBb41x6/R8HrV/m9r/3qt62j767fL9dDOerwt7u+1x9vZK9i2AF7LVv2x0A9YwEWzfWfx3NmHfj75R3++m997XfLwFyZv/HeTP/oNycNf1C0//IVdsDM+yVgtu8Dp+nPJ9WeTG88l158/nr/16eTwenJ4LbnxQvLih4+XD68l6+X5tH9xOdl/JLnySBdA7T/chVNHN7vL8lZydCM5upUs+3XD/OJS1xvr6uf0vbVG85t1n5NcerDrrVVKUpok/fROl+azK0B+aafNpWadz9k9TK4su8fa2e+eZ/tZ7Fa1dq/5etkFfKd6nw0n4Mt1Fz4dLdddmHI49OY6DlSu3zrMwc3rObx1I4e3rmcvR3lwp+R1O6u8brHO1cUqV9tV9tuj7Der7DfLXGqWWbSLrK48luXlR3N46dEcXXo0R82lHC77x+xPUg+W61wb9ZI6ni7z6dG6564dpm1KLu00ef2V3ewtmlzqe5Vd2mk383uLJou2SVOSpt+Gm1LSlKSMpqUkh8t1PnnjKJ+8fpgXbhzmk9cP8+EXbuRXP/JiPnn9KIer9Z1e3S4M211kf2/UA2x3kT/0up2s6vFzu3FjmYNR77nNyfhynZ1Fkyv9f1Tc73uTfd5Du7my1/2nxSv9+lprnr9+mOevHeT5a4f59Y9+Ks9dO8hLt85pn7oLpRy/ht30eL6UbIaS3snVvUUeubqbR67s5nWXd3K0Wp8ICLu/7cLDg2U39PROgc34sUsfQjWlZH0qQLkbe4tm0/Nv2HYu73TrFk2Tm0d9eHvQ7RPD9BVktK/I7qLpe0a2ubTT1ZEbT3faJstV3YQ6R6t1jpZ11GuzDxiX6xOB0itp/6LpekPuNE3attufjpbHvUOntL/b9qFmH7pe2c3DV3dzZXfRP+/++a/Gwdpo/SgwXY/C1lpPXtf1gizZW7TZ7T9juunp5e54cDh6P068J6P3aLW+c1A5vKLHv8d07/PB6LPjxGfJJuxb59JOu/lhpas7uJOro//0OkwXTTkRBNbNY58MTFfrmuVqnaNhujrelo5Wx9etVse9RofAdxNKj6ZDmDgOg0+HnsN7tdN2Q8Vv30+P/0PtpZ02zebz5/jzZDOkfTkMaV9nuT7uabvbNifrN4563y7aJqWMQ+N66v24fTscviodf2UqJ5aH+pOH4zYt1yfXHXWvyTB0fmhL1yu5bOaH4fTDDwjDez8cZ0732G7KcYg91KYc16wcpk1TTrx3w34wvGebYL3c3qN6f3exWTf0sL600+Rw2fUUv3W0yq3hM/6o+0Fs+LHo1tFqs6+d3nZqTj12RseiZjj+jI9LObncHyPa0XI7+tvhWFKSTajeLQ/31X9XSLrvS6t1Doft/tSPOMt197rX5MSPCe1mvjnxA0NTsvkMX66O96nhB8aj0Q+EL/d8N8fjJjla1dHnxKr73Dg6/ow4WK43x8jdRbPZly7tdN+hhn3t8k6bS7tt9tpm812pGV6Xptu+h9en6V+fo/Xx8aZ7Trf/4LXsX6f15seq2v/gldGPDd31w3e9z7T/77RlU7bi1tHt3yWGz4Kj1br/TOmf76L/ztg/90uL49dhXevmPThanvq8G30eDtvt8Q91xz+WbH6gW3efi23/g1PTDNN+Wygl7al1bb+dtu0Zy6Vk1bdxOLaMt6Xxtjk8drt5rOP9oB09/vBdqvus7o8Fw76YbPbPmu6247YP97M4dd/D5cR1J553dxl+YBzvR8NrvplfdtvK3Vr3P1QN7033/fDkD1tnHYNPfvJ32lKyt9P05xj9ucbOaH7RbUuLppw4pp38YW/d/cjbfxcbRnls6gePpnujY9TRap2bh+vc7D87x/WLb41qGP/bn/u6vPNr/8hdv0YXUan3s5vDlnjqqafq008/PXUzPjs3Xkief6YLlvYfPhko3U/Lwy50Wh2mC29KjkOc0Te1Idypq66tN57vLtef6wOu5/r1/fzNF5Jm0YUzO5eSncuj+f0uYNq53E2Pbnbh2PVPJNf66Y0XcvIj5R6Vthtq2O52lxPzu8fzq8Pj0Gt5MArGbnbP9az7Htq+uNQ9p8Xl7jGatruf1eGp6UH3Wq8OTvZUG7dzsZe0e3379o7bOW7jUd+25c3+PTsnu1f7cO8NydU+3Lv8+u41WB11j7U6PGP+qHve7W7S7hy/tsN8s3M8X9f9a3LrjNepn9b17e9V/xrVZidHZScH6zYHdZFF22R30WZn0WTR9L1Phu04OZ6vq2S96oK+uu5Dv2F5uG51qkdfzp4vpdvGm0X3/JtFUtosS5tby5Kby+TGquTWMmlLTZt12lLTjObbJE3Wacs6TWpKakrW3Zfs1JRaU0o/HV9XmqRtU5o+sGx3Rm3pL+1OakqOVuu+x89Rbh4sc7Mv7H/jsJ8/XOVwucqiSX8pWZTugLsote9NkyxK0vZfaMe9X5LuC1z/6my+zHVfervwt5SS0jQpw3xpUpqSpjRZJ5sv9cvNF9/hS+Rx8Lperzd10XbaZKfpDv7dSWk2J3s7faBZh8+xDJvC8Nl2PK01qXXdf2FbH59QrYeeYuMeZqusVuus16usV/2J2Lrr8bher7NarVPrOqW0KU33HJum7Z53/9ybpuu9VZq2P9GqadNtD02p/bZQ06S/lO6L5aoPHlY1WdfSt3O03L8XTdOk6U+eui+Q/XIp3bTtT+T6bSvjbaquN9tahm1x9H6lf8+69649Xt80OVzW/svV8sQ/ixh6dw5futb9Z9/JE7LjcPTEiWn/lg0nmOlPnobdezhCDicOx5f18fwZ3382jzt8AR9OGpuSpnvQlP5VGKbHnyXH67sv5RmdwGbzhX7R95ZrShf6HPRDwo9Wo15no95mp4935cT82c+jjE7eSym3r+vb3aSODun9NpCTr+nx+9D065rR+9NdhhB5OEFdrlb9fnp8Irhcd/vN+ER+M21H8/39dye3xyci3fTU8jiRLScmo9XD+3PsTq/c+CP89vChbPahYX1TSr+v3d7b7/hktmvz+GRtfCLZnZgenwAm6U/wT578rEbLw2OMw5VxCDN8rA1b6ThIGH44Wt5lkj083yFAG048c/rxNm0ot31NPR2UZnSc6JbXt91mE2CN19e6ed/G2WI99TjJyc+Q0yfpw/Kmt9AdQ7tReNe3Y/j7ZvT+jYOytt9PakrfrlPh8InnXU9sA+Nt7cRyaVJzvB+Nw+RhfxsvZ/R4w6tx4oR8FEAcvw45EWY0zSjwGwK+E9va+POh+0xe1xz3yD/VM398vF6t62Z7avttaryNtU1XsqEtQwhw6j5O/BBx/INMyfHn9nCsOP38Nj9eDs9htL2e3nbreDvInbaLs7aT2h93T96mlPTHk+M2nt4W2/5FHf9trcl6vP2PwqVN20f7X8brhitqTrZ3dH93en6vxOn9oCknPxteTs3JIPT0j8zNqfdr44zP++TsXuF380PeuC3D50iSrHP8neJelORETd/hh4nLn/NFefuf/yv3dF/bqpTyvlrrU7etFzZxIa2WfZj1ieTaJ7ow6tank2E434lLPTW/GoUXR6Ogpw97VkfH17U7dw6OTkwvdW066gOpIfRZ3joOpob169XLh0eLS918047a9jKhy+qwu6/b2nX5uN3jads/xvixFuPLpe5xx8HetY+P5vvX+trHk5uf7IOiM0KkIQxqFn1Qc3R2GDU819L07dp9+depNMd/P34fV4ej97K/9CfHSY7nx+HQxhAOHQdD3fx4uemmyZ0Dq/F8Xfch1Si02syPlusqx73u2pzofXdifTmebgLf5GQvvqEdtXtNhtd9eKzV0Iajk6HmmYbwZTw/fCNrbl934van7uc2dfR+jPbTYf14/m7v88TtytnXnblN3Mvx8GTAcKLn5Pj9OPE6jZ53vdNn1fr4eZ/umdmMto3x/Y7vc3PGVW9/Xp9pPxjPn/kchuXRdnb6uZz4DO4/b+/iq+bmlb/jF9O7+ap61r2evZ2c9W7f1aOd/gy542fKHe7xTtvoHbfv0UOd1bKX296T4xDqZdt6VtvufJ+338epdXe9/0/ls/zOe8fvzPP/Hv3qmWpbOeOz4rO6P4DP4Iu+Ovlz/2TqVpyLs8Imw+i4mNpF8sAbugvn78E3fubbnHlicQHN6bncrXUfCJwOyl5rr8OdDAFKubswgM/eFK/wRXlXL0o7AQDGhE3AKzOnE/A5PZe71TTpOiZzG6EbAAB8VpxpAAAAAHBuhE0AAAAAnBthEwAAAADnRtgEAAAAwLkRNgEAAABwboRNAAAAAJwbYRMAAAAA50bYBAAAAMC5ETYBAAAAcG6ETQAAAACcG2ETAAAAAOdG2AQAAADAuRE2AQAAAHBuhE0AAAAAnBthEwAAAADnRtgEAAAAwLkRNgEAAABwboRNAAAAAJwbYRMAAAAA50bYBAAAAMC5ETYBAAAAcG6ETQAAAACcG2ETAAAAAOdG2AQAAADAuRE2AQAAAHBuhE0AAAAAnBthEwAAAADnRtgEAAAAwLkRNgEAAABwboRNAAAAAJwbYRMAAAAA50bYBAAAAMC5ETYBAAAAcG6ETQAAAACcG2ETAAAAAOdG2AQAAADAuRE2AQAAAHBuSq116jbcd6WUZ5P87tTtOAePJnlu6kbABWKfgXtjn4F7Y5+Be2OfgXtzEfaZL6i1PnZ65WsibJqLUsrTtdanpm4HXBT2Gbg39hm4N/YZuDf2Gbg3F3mfMYwOAAAAgHMjbAIAAADg3AibLpYfmLoBcMHYZ+De2Gfg3thn4N7YZ+DeXNh9Rs0mAAAAAM6Nnk0AAAAAnBth0wVRSnlbKeW3SinPlFLeOXV7YNuUUt5USvm5UspvlFLeX0r5jn79w6WUf15K+e1++vqp2wrbpJTSllJ+qZTy0/3ym0sp7+2PNz9eStmduo2wLUopD5VSfrKU8pullA+UUv49xxk4Wynlv+6/l/16KeUfllIuOc7AsVLKD5dSPlFK+fXRujseV0rn+/p951dLKV8xXcs/M2HTBVBKaZN8f5KvTfKWJN9USnnLtK2CrbNM8pdrrW9J8lVJvr3fT96Z5GdqrU8m+Zl+GTj2HUk+MFr+7iTfU2v94iSfTPKtk7QKttP/nOSf1lr/SJIvS7fvOM7AHZRS3pjkv0ryVK3130nSJnlHHGdg7H9N8rZT6846rnxtkif7y7cl+TuvUhtfEWHTxfCVSZ6ptX6w1nqY5MeSvH3iNsFWqbV+rNb6r/r5l9KdALwx3b7yI/3NfiTJfzxNC2H7lFIeT/Knkvxgv1ySfHWSn+xvYp+BXinlwST/QZIfSpJa62Gt9cU4zsDLWSS5XEpZJNlP8rE4zsBGrfX/TvLCqdVnHVfenuR/q53/L8lDpZTPfXVaeu+ETRfDG5N8eLT8kX4dcAellCeSvDXJe5O8odb6sf6qP0jyhomaBdvoe5P81STrfvmRJC/WWpf9suMNHHtzkmeT/L1+6OkPllKuxHEG7qjW+tEk/1OS30sXMn0qyfviOAOfyVnHlQuVCwibgFkppVxN8o+T/KVa66fH19Xu32/6F5yQpJTydUk+UWt939RtgQtikeQrkvydWutbk1zPqSFzjjNwrK8z8/Z0Qe3nJbmS24cLAS/jIh9XhE0Xw0eTvGm0/Hi/DhgppeykC5p+tNb6U/3qjw/dS/vpJ6ZqH2yZP5bkT5dSPpRuePZXp6tH81A/3CFxvIGxjyT5SK31vf3yT6YLnxxn4M7+wyS/U2t9ttZ6lOSn0h17HGfg5Z11XLlQuYCw6WL4xSRP9v+5YTddYb13T9wm2Cp9rZkfSvKBWuvfHF317iTf3M9/c5L/49VuG2yjWut31lofr7U+ke648rO11j+T5OeSfH1/M/sM9Gqtf5Dkw6WUf6tf9TVJfiOOM3CW30vyVaWU/f572rDPOM7AyzvruPLuJP95/1/pvirJp0bD7bZO6Xplse1KKf9RutoabZIfrrW+a+ImwVYppfzxJD+f5NdyXH/mr6Wr2/QTST4/ye8m+c9qraeL8MFrWinlTyT5K7XWryulfGG6nk4PJ/mlJH+21nowZftgW5RSvjxdQf3dJB9M8i3pfrx1nIE7KKX890m+Md1/Df6lJP9FuhozjjOQpJTyD5P8iSSPJvl4kv8uyf+eOxxX+tD2b6UbjnojybfUWp+eot13Q9gEAAAAwLkxjA4AAACAcyNsAgAAAODcCJsAAAAAODfCJgAAAADOjbAJAAAAgHMjbAIAuA9KKatSyi+PLu88x/t+opTy6+d1fwAA52kxdQMAAGbqZq31y6duBADAq03PJgCAV1Ep5UOllP+xlPJrpZRfKKV8cb/+iVLKz5ZSfrWU8jOllM/v17+hlPJPSim/0l/+/f6u2lLK3y2lvL+U8n+WUi5P9qQAAEaETQAA98flU8PovnF03adqrX80yd9K8r39uv8lyY/UWr80yY8m+b5+/fcl+b9qrV+W5CuSvL9f/2SS76+1fkmSF5P8p/f5+QAA3JVSa526DQAAs1NKuVZrvXqH9R9K8tW11g+WUnaS/EGt9ZFSynNJPrfWetSv/1it9dFSyrNJHq+1Hozu44kk/7zW+mS//N8m2am1/g/3/5kBALw8PZsAAF599Yz5e3Ewml9FLU4AYEsImwAAXn3fOJr+v/38/5PkHf38n0ny8/38zyT5C0lSSmlLKQ++Wo0EAHgl/AIGAHB/XC6l/PJo+Z/WWt/Zz7++lPKr6XonfVO/7r9M8vdKKf9NkmeTfEu//juS/EAp5VvT9WD6C0k+dt9bDwDwCqnZBADwKuprNj1Va31u6rYAANwPhtEBAAAAcG70bAIAAADg3OjZBAAAAMC5ETYBAAAAcG6ETQAAAACcG2ETAAAAAOdG2AQAAADAuRE2AQAAAHBu/n8mgP4wFfR67wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 16))\n",
    "\n",
    "ax.plot(history.history['loss'], label='train')\n",
    "ax.plot(history.history['val_loss'], label='test')\n",
    "ax.set_title('Model Loss')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hVv8L2EN_XN",
    "outputId": "6d8a189e-7051-42a6-dd0d-b626eb55d212"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "zjwPGzH7cXls"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def calculate_metrics(modelName, yTrue, yPred, average='binary'):\n",
    "    \"\"\"\n",
    "    Calculate and print the performance metrics of a classification model.\n",
    "    \n",
    "    Parameters:\n",
    "    modelName (str): The name of the classification model.\n",
    "    yTrue (array-like): The true labels.\n",
    "    yPred (array-like): The predicted labels.\n",
    "    average (str or None, optional): The averaging method to use for multi-class classification. One of \n",
    "        {'micro', 'macro', 'weighted', 'binary'} or None (default: 'binary'). If None, only binary \n",
    "        classification metrics will be computed.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If `average` is not one of {'micro', 'macro', 'weighted', 'binary'} or None.\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Check if average parameter is valid\n",
    "    if average != 'micro' and average != 'macro' and average != 'weighted' and average != 'binary' and average != None:\n",
    "        print(\"Average must be one of this options: {‘micro’, ‘macro’, ‘samples’, ‘weighted’, ‘binary’} or None, default=’binary’\")\n",
    "        return\n",
    "    \n",
    "    # Prints the name of the model and calculate accuracy and precision\n",
    "    print(f\"--- Performance of {modelName} ---\")\n",
    "    acc = accuracy_score(y_true = yTrue, y_pred = yPred)\n",
    "    precision = precision_score(y_true = yTrue, y_pred = yPred, average = average)\n",
    "    print(f'Accuracy : {np.round(acc*100,2)}%\\nPrecision: {np.round(precision*100,2)}%')\n",
    "    \n",
    "    # Calculates and print recall and F1-score\n",
    "    f1 = f1_score(y_true = yTrue, y_pred = yPred, average = average)\n",
    "    recall = recall_score(y_true = yTrue, y_pred = yPred, average = average)\n",
    "    print(f'Recall: {np.round(recall*100,2)}%\\nF1-score: {np.round(f1*100,2)}%')\n",
    "    \n",
    "    #auc_sklearn = roc_auc_score(y_true = yTrue, y_score = yPred, average = average)\n",
    "    #print(f'Roc auc: {np.round(auc_sklearn*100,2)}%')\n",
    "    \n",
    "    # Calculates and prints balanced accuracy and classification report\n",
    "    print(f\"Balanced accuracy: {np.round(balanced_accuracy_score(yTrue, yPred)*100,2)}%\")\n",
    "    print(f\"Classification report:\\n{classification_report(yTrue, yPred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "7opqgASr6fxn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance of Binary - DNN ---\n",
      "Accuracy : 99.99%\n",
      "Precision: 99.99%\n",
      "Recall: 100.0%\n",
      "F1-score: 100.0%\n",
      "Balanced accuracy: 50.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        90\n",
      "           1       1.00      1.00      1.00   1009513\n",
      "\n",
      "    accuracy                           1.00   1009603\n",
      "   macro avg       0.50      0.50      0.50   1009603\n",
      "weighted avg       1.00      1.00      1.00   1009603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/project/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred = np.round(pred).astype(int)\n",
    "calculate_metrics(\"Binary - DNN\", y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ihn2qm186fxn"
   },
   "source": [
    "-------------------------------------\n",
    "\n",
    "**Result Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "7oqLlxmicPrp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f82bdf655f8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "y_pred = np.round(pred).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "cmd = ConfusionMatrixDisplay(cm)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cmd.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_za--boceRr9"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-cd0574415741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Usage of ExtraTreesClassifier for feature selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mextra_tree_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mextra_tree_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfeature_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_tree_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeature_importance_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mextra_tree_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    303\u001b[0m             )\n\u001b[1;32m    304\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0;32m--> 305\u001b[0;31m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    876\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    879\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 721\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n\u001b[0;32m--> 106\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    107\u001b[0m             )\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# Usage of ExtraTreesClassifier for feature selection\n",
    "extra_tree_forest = ExtraTreesClassifier(n_estimators = 5, criterion ='entropy', max_features = 2)\n",
    "extra_tree_forest.fit(x, y)\n",
    "feature_importance = extra_tree_forest.feature_importances_\n",
    "feature_importance_normalized = np.std([tree.feature_importances_ for tree in  extra_tree_forest.estimators_], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBfWThvfeTNB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plor for the ExtraTreesClassifier output\n",
    "plot.bar(x_columns, feature_importance_normalized)\n",
    "plot.xlabel('Feature Labels')\n",
    "plot.ylabel('Feature Importances')\n",
    "plot.title('Comparison of different feature importances in the current dataset')\n",
    "plot.xticks(rotation = 90)\n",
    "\n",
    "# Plot size\n",
    "plot.rcParams[\"figure.figsize\"] = (70, 40)\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

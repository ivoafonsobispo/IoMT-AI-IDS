{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c89308e",
   "metadata": {},
   "source": [
    "### Declaration of Functions\n",
    "\n",
    "The section below presents all the functions used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb07139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Read the dataset and return a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "def read_data(dataset):\n",
    "    df = pd.read_csv(dataset, nrows=380000)\n",
    "    print('[DONE] Dataset imported successfully')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Delete unnecessary fields\n",
    "def delete_fields(df, fields):\n",
    "    print('[INFO] Deleting unnecessary fields')\n",
    "    for i in fields:\n",
    "        df.drop(i, axis=1, inplace=True)\n",
    "        print(f'[REMOVED] ' + i)\n",
    "    print('[INFO] Unnecessary fields deleted with success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aa2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Z-Score normalization\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def zscore_normalization(df, fields):\n",
    "    for i in fields:\n",
    "        df[i] = zscore(df[i])\n",
    "    print(f'[DONE] Z-Score Normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Fill empty cells with N value\n",
    "def fill_empty_cells(df, fields, n):\n",
    "    for i in fields:\n",
    "        df[i] = df[i].fillna(n)\n",
    "    print(f'[DONE] Empty Cells Filling: ' + n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert fields to dummy variables\n",
    "def dummy_encode(df, fields):\n",
    "    for i in fields:\n",
    "        df = pd.concat([df, pd.get_dummies(df[i], prefix=i, dtype=float)], axis=1)\n",
    "        df.drop(i, axis=1, inplace=True)\n",
    "    print(f'[DONE] Categorical Values (Dummies)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert hexadecimal to int\n",
    "def hexadecimal_convert(df, fields):\n",
    "    for i in fields:\n",
    "        df[i] = df[i].astype(str)\n",
    "        df[i] = df[i].apply(int, base=16)\n",
    "    print(f'[DONE] Integer Convert (Hex - Int)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f83ba",
   "metadata": {},
   "source": [
    "### Declaration of Global Variables\n",
    "\n",
    "The section below presents all the global functions used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = '../../../Datasets/IP-Based/Samples/SlowLoris.csv'\n",
    "DATASET_PRE_PROCESSING = '../../../Datasets/IP-Based/SlowLoris.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577a44d",
   "metadata": {},
   "source": [
    "### Loading Dataset\n",
    "The upcoming step will load the desired dataset and read all the data from it, storing it in the variable `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f25f3f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import dataset and read the data into a dataframe\n",
    "df = read_data(DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c31c433",
   "metadata": {},
   "source": [
    "### Labelling the Dataset\n",
    "\n",
    "This next section will cover the labelling process of the current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a337430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a mask to only contain the malicious IP address\n",
    "mask = (df['frame.protocols'] == 'sll:ethertype:ip:tcp') \\\n",
    "    | (df['frame.protocols'] == 'sll:ethertype:ip:tcp:http:data-text-lines') \\\n",
    "    | (df['frame.protocols'] == 'sll:ethertype:ip:tcp:http')\n",
    "\n",
    "# Filter the DataFrame to keep only the rows matching the IP address\n",
    "df = df[mask]\n",
    "\n",
    "print(f'[DONE] Protocols mask applied on the dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06870175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling the malicious packets\n",
    "import numpy as np\n",
    "\n",
    "# df['ip.addr'] = df['ip.addr'].fillna('')\n",
    "# df['is_malicious'] = np.where(df['ip.addr'] == MALICIOUS_IP, 1, 0)\n",
    "df['is_malicious'] = 1\n",
    "df['attack_type'] = 4\n",
    "print(f'[DONE] Dataset malicious labeling done with success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c916d3",
   "metadata": {},
   "source": [
    "### Data Cleansing\n",
    "\n",
    "This section covers all the data cleaning done in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d763dc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Array: Fields to delete (IDs, Timestamps, Checksums, etc...)\n",
    "fieldsToDelete = [\n",
    "    'frame.encap_type', 'frame.ignored', 'frame.interface_id', 'frame.interface_name', 'frame.marked', \n",
    "    'frame.number', 'frame.offset_shift', 'frame.protocols', 'frame.time', 'frame.time_delta',\n",
    "    'frame.time_delta_displayed', 'frame.time_epoch', 'frame.time_relative', 'ip.addr', 'ip.checksum',\n",
    "    'ip.checksum.status', 'ip.dsfield', 'ip.dsfield.dscp', 'ip.dsfield.ecn', 'ip.dst', 'ip.dst_host', 'ip.hdr_len',\n",
    "    'ip.host', 'ip.id', 'ip.len', 'ip.proto', 'ip.src', 'ip.src_host', 'ip.ttl.lncb', 'tcp.window_size',\n",
    "    'tcp.time_relative', 'tcp.time_delta', 'tcp.stream', 'tcp.srcport', 'tcp.seq_raw', 'tcp.seq',\n",
    "    'tcp.segments', 'tcp.segment_data', 'tcp.segment.count', 'tcp.segment', 'tcp.reassembled.length',\n",
    "    'tcp.reassembled.data', 'tcp.port', 'tcp.payload', 'tcp.options.wscale.shift', 'tcp.options.wscale.multiplier',\n",
    "    'tcp.options.wscale', 'tcp.options.timestamp.tsval', 'tcp.options.timestamp.tsecr', 'tcp.options.sack_perm',\n",
    "    'tcp.options.mss_val', 'tcp.options.mss', 'tcp.options', 'tcp.nxtseq', 'tcp.dstport', 'tcp.checksum',\n",
    "    'tcp.checksum.status', 'tcp.flags.str', 'tcp.analysis.window_full', 'tcp.analysis.reused_ports',\n",
    "    'tcp.analysis.lost_segment', 'tcp.analysis.keep_alive_ack', 'tcp.analysis.keep_alive', 'tcp.analysis.flags',\n",
    "    'tcp.analysis.acks_frame', 'tcp.analysis.ack_lost_segment', 'tcp.analysis', 'tcp.ack_raw', 'tcp.ack',\n",
    "    'eth.padding', 'http.accept_encoding', 'http.connection', 'http.content_length_header', 'http.content_type',\n",
    "    'http.date', 'http.file_data', 'http.last_modified', 'http.referer', 'http.request.full_uri',\n",
    "    'http.request.line', 'http.request.method', 'http.request.uri', 'http.request.version', 'http.request_in',\n",
    "    'http.request_number', 'http.response.code.desc', 'http.response.line', 'http.response.phrase',\n",
    "    'http.response.version', 'http.response_for.uri', 'http.server', 'http.user_agent', 'http.host', 'tcp.len',\n",
    "    'ip.flags', 'ip.ttl', 'tcp.connection.rst'\n",
    "]\n",
    "\n",
    "delete_fields(df, fieldsToDelete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all empty collumns\n",
    "empty_columns = []\n",
    "for column in df.columns:\n",
    "    if df[column].isnull().all():\n",
    "        empty_columns.append(column)\n",
    "list(empty_columns)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25371d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete and print the empty columns\n",
    "print('[INFO] Deleting empty columns')\n",
    "for column in empty_columns:\n",
    "    df.drop(column, axis = 1, inplace = True)\n",
    "    print(f'[REMOVED] ' + column)\n",
    "print('[INFO] Empty columns deleted with success')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d9d7e",
   "metadata": {},
   "source": [
    "### Pre-Processing & Data Encoding\n",
    "\n",
    "This section covers all the pre-processing and data encoding done in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array: Hexadecimal fields to fill with 0x00000000\n",
    "hexadecimalFill = [\n",
    "    'tcp.flags'\n",
    "]\n",
    "\n",
    "fill_empty_cells(df, hexadecimalFill, '0x00000000') # Fill: 0x00000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4639f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array: Fields to convert from Hexadecimal to Integer\n",
    "hexadecimalFields = [\n",
    "    'tcp.flags'\n",
    "]\n",
    "\n",
    "hexadecimal_convert(df, hexadecimalFields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfad27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array: Fields to fill with 0\n",
    "fill_0 = [\n",
    "    'tcp.option_len', 'tcp.option_kind', 'tcp.hdr_len', 'tcp.connection.syn', 'tcp.connection.fin',\n",
    "    'tcp.analysis.bytes_in_flight', 'tcp.analysis.push_bytes_sent', 'tcp.analysis.ack_rtt',\n",
    "    'tcp.analysis.initial_rtt', 'http.chat', 'tcp.connection.synack', 'http.content_length',\n",
    "    'http.response', 'http.response.code', 'http.response_number', 'http.time', 'http.request'\n",
    "]\n",
    "\n",
    "# Array: Fields to fill with 1\n",
    "fill_positive_1 = [\n",
    "    'ip.flags.mf', 'ip.flags.rb', 'ip.frag_offset', 'tcp.urgent_pointer', 'tcp.flags.urg', 'tcp.flags.ns',\n",
    "    'tcp.flags.ecn', 'tcp.flags.cwr'\n",
    "]\n",
    "\n",
    "# Array: Fields to fill with -1\n",
    "fill_negative_1 = [\n",
    "    'ip.flags.df', 'tcp.flags.syn', 'tcp.flags.reset', 'tcp.flags.push', 'tcp.flags.fin', 'tcp.flags.ack', \n",
    "]\n",
    "\n",
    "fill_empty_cells(df, fill_0, '0')            # Fill: 0\n",
    "fill_empty_cells(df, fill_positive_1, '1')   # Fill: 1\n",
    "fill_empty_cells(df, fill_negative_1, '-1')  # Fill: -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d425dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value replacing\n",
    "df['tcp.option_len'] = df['tcp.option_len'].replace(4, 1)\n",
    "df['tcp.option_len'] = df['tcp.option_len'].replace(10, 2)\n",
    "print(f'[DONE] tcp.option_len: values 10 and 4 were replaced.')\n",
    "\n",
    "#df['http.content_length'] = df['http.content_length'].replace(233, 1)\n",
    "#df['http.content_length'] = df['http.content_length'].replace(635, 2)\n",
    "#print(f'[DONE] http.content_length: values 635 and 233 were replaced.')\n",
    "\n",
    "#df['http.response.code'] = df['http.response.code'].replace(400, 1)\n",
    "#print(f'[DONE] http.response.code: value 400 were replaced.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array: Fields to apply z-score normalization\n",
    "zScoreNormalization = [\n",
    "    'frame.cap_len', 'frame.len', 'tcp.hdr_len', 'tcp.flags', 'tcp.analysis.push_bytes_sent',\n",
    "    'tcp.analysis.bytes_in_flight', 'http.time', 'http.content_length', 'http.response.code'\n",
    "]\n",
    "\n",
    "for i in zScoreNormalization:\n",
    "    df[i] = df[i].astype(float)\n",
    "\n",
    "zscore_normalization(df, zScoreNormalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from dtypes to float\n",
    "for i in df:\n",
    "    df[i] = df[i].astype(float)\n",
    "print(f'[DONE] Convertion to float done with success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5754d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replication of rows\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of times to replicate the rows\n",
    "replications = 243170\n",
    "\n",
    "# Randomly select rows from the original DataFrame\n",
    "replicated_rows = df.sample(n=replications, replace=True)\n",
    "\n",
    "# Concatenate the original DataFrame with the replicated rows\n",
    "df = pd.concat([df, replicated_rows], ignore_index=True)\n",
    "\n",
    "# Verify the resulting DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bcaed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset with all the pre-processing and data encoding done\n",
    "df.to_csv(DATASET_PRE_PROCESSING, index=False)\n",
    "print(f'[DONE] Dataset with pre-processing saved with success')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

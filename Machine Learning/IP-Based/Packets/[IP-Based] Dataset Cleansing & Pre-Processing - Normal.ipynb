{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c89308e",
   "metadata": {},
   "source": [
    "### Declaration of Functions\n",
    "\n",
    "The section below presents all the functions used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb07139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Read the dataset and return a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "def read_data(dataset):\n",
    "    # Number of rows in each dataframe\n",
    "    chunksize = 500000\n",
    "    \n",
    "    # List that will contain all the dataframes\n",
    "    list_of_dataframes = []\n",
    "    \n",
    "    for df in pd.read_csv(dataset, chunksize = chunksize):\n",
    "        list_of_dataframes.append(df)\n",
    "        \n",
    "    df = pd.concat(list_of_dataframes)\n",
    "    print(f'[DONE] Dataset imported with success')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e998d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Delete unnecessary fields\n",
    "def delete_fields(df, fields):\n",
    "    print('[INFO] Deleting unnecessary fields \\n')\n",
    "    for i in fields:\n",
    "        df.drop(i, axis = 1, inplace = True)\n",
    "        print(f'[REMOVED] ' + i)\n",
    "    print('\\n[INFO] Unnecessary fields deleted with success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41aa2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Z-Score normalization\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def zscore_normalization(df, fields):\n",
    "    for i in fields:\n",
    "        df[i] = zscore(df[i])\n",
    "    print(f'[DONE] Z-Score Normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464a2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Fill empty cells with N value\n",
    "def fill_empty_cells(df, fields, n):\n",
    "    for i in fields:\n",
    "        df[i] = df[i].fillna(n)\n",
    "    print(f'[DONE] Empty Cells Filling: ' + n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db42dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Replace old value with a new one \n",
    "def value_replacing(df, field, old_value, new_value):\n",
    "    df[field] = df[field].replace(old_value, new_value)\n",
    "    print(f'[DONE] Value Replacing: ' + old_value + ' -- ' + new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d52d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert fields to dummy variables\n",
    "def dummy_encode(df, fields):\n",
    "    for i in fields:\n",
    "        df = pd.concat([df, pd.get_dummies(df[i], prefix = i, dtype = float)], axis = 1)\n",
    "        df.drop(i, axis = 1, inplace = True)\n",
    "    print(f'[DONE] Categorical Values (Dummies)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ca47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert hexadecimal to int\n",
    "def hexadecimal_convert(df, fields):\n",
    "    for i in fields:\n",
    "        df[i] = df[i].astype(str)\n",
    "        df[i] = df[i].apply(int, base = 16)\n",
    "    print(f'[DONE] Integer Convert (Hex - Int)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f83ba",
   "metadata": {},
   "source": [
    "### Declaration of Global Variables\n",
    "\n",
    "The section below presents all the global functions used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ed5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = '../../../Datasets/IP-Based/IPBased_Benign_Dataset.csv'\n",
    "DATASET_PRE_PROCESSING = '../../../Datasets/IP-Based/IPBased_Benign_Dataset_PreProcessing.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577a44d",
   "metadata": {},
   "source": [
    "### Loading Dataset\n",
    "The upcoming step will load the desired dataset and read all the data from it, storing it in the variable `df`.\n",
    "\n",
    "The code below will reproduce an warning saying the following **\"DtypeWarning: Columns (68, 79, 83) have mixed types\"**. Since the collumns 68, 79 and 83 represent the fields <mark>tcp.options.mss</mark>, <mark>tcp.reassembled.data</mark>, and <mark>tcp.segment_data</mark> respectively, and these collumns are going to be deleted later in this notebook, so there is no problem whatsoever about the warning shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f25f3f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9296/489874654.py:11: DtypeWarning: Columns (68,79,83) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in pd.read_csv(dataset, chunksize = chunksize):\n",
      "/tmp/ipykernel_9296/489874654.py:11: DtypeWarning: Columns (68,83) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in pd.read_csv(dataset, chunksize = chunksize):\n",
      "/tmp/ipykernel_9296/489874654.py:11: DtypeWarning: Columns (68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in pd.read_csv(dataset, chunksize = chunksize):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Dataset imported with success\n"
     ]
    }
   ],
   "source": [
    "# Import dataset and read the data into a dataframe\n",
    "df = read_data(DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c916d3",
   "metadata": {},
   "source": [
    "### Data Cleansing\n",
    "\n",
    "This section covers all the data cleaning done in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25371d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Completely Empty Columns --\n"
     ]
    }
   ],
   "source": [
    "# Remove all empty collumns\n",
    "empty_columns = []\n",
    "for column in df.columns:\n",
    "    if df[column].isnull().all():\n",
    "        empty_columns.append(column)\n",
    "\n",
    "# Print the empty columns\n",
    "print('-- Completely Empty Columns --')\n",
    "for column in empty_columns:\n",
    "    df.drop(column, axis = 1, inplace = True)\n",
    "    print(f'[REMOVED] Collum: ' + column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9602b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Deleting unnecessary fields \n",
      "\n",
      "[REMOVED] coap.opt.ctype\n",
      "[REMOVED] coap.opt.desc\n",
      "[REMOVED] coap.opt.name\n",
      "[REMOVED] coap.opt.uri_host\n",
      "[REMOVED] coap.opt.uri_path\n",
      "[REMOVED] coap.opt.uri_path_recon\n",
      "[REMOVED] coap.payload\n",
      "[REMOVED] coap.payload_desc\n",
      "[REMOVED] coap.token_len\n",
      "[REMOVED] data.data\n",
      "[REMOVED] udp.checksum\n",
      "[REMOVED] udp.checksum.status\n",
      "[REMOVED] udp.dstport\n",
      "[REMOVED] udp.length\n",
      "[REMOVED] udp.payload\n",
      "[REMOVED] udp.port\n",
      "[REMOVED] udp.possible_traceroute\n",
      "[REMOVED] udp.srcport\n",
      "[REMOVED] udp.time_delta\n",
      "[REMOVED] udp.stream\n",
      "[REMOVED] frame.encap_type\n",
      "[REMOVED] frame.ignored\n",
      "[REMOVED] frame.interface_id\n",
      "[REMOVED] frame.interface_name\n",
      "[REMOVED] frame.marked\n",
      "[REMOVED] frame.number\n",
      "[REMOVED] frame.offset_shift\n",
      "[REMOVED] frame.protocols\n",
      "[REMOVED] frame.time\n",
      "[REMOVED] frame.time_delta\n",
      "[REMOVED] frame.time_delta_displayed\n",
      "[REMOVED] frame.time_epoch\n",
      "[REMOVED] frame.time_relative\n",
      "[REMOVED] mqtt.hdr_reserved\n",
      "[REMOVED] mqtt.hdrflags\n",
      "[REMOVED] mqtt.len\n",
      "[REMOVED] mqtt.msg\n",
      "[REMOVED] mqtt.msgtype\n",
      "[REMOVED] mqtt.topic\n",
      "[REMOVED] mqtt.topic_len\n",
      "[REMOVED] ip.addr\n",
      "[REMOVED] ip.checksum\n",
      "[REMOVED] ip.checksum.status\n",
      "[REMOVED] ip.dsfield\n",
      "[REMOVED] ip.dsfield.dscp\n",
      "[REMOVED] ip.dsfield.ecn\n",
      "[REMOVED] ip.dst\n",
      "[REMOVED] ip.dst_host\n",
      "[REMOVED] ip.hdr_len\n",
      "[REMOVED] ip.host\n",
      "[REMOVED] ip.id\n",
      "[REMOVED] ip.len\n",
      "[REMOVED] ip.proto\n",
      "[REMOVED] ip.src\n",
      "[REMOVED] ip.src_host\n",
      "[REMOVED] ip.ttl.lncb\n",
      "[REMOVED] tcp.window_size\n",
      "[REMOVED] tcp.time_relative\n",
      "[REMOVED] tcp.time_delta\n",
      "[REMOVED] tcp.stream\n",
      "[REMOVED] tcp.srcport\n",
      "[REMOVED] tcp.seq_raw\n",
      "[REMOVED] tcp.seq\n",
      "[REMOVED] tcp.segments\n",
      "[REMOVED] tcp.segment_data\n",
      "[REMOVED] tcp.segment.count\n",
      "[REMOVED] tcp.segment\n",
      "[REMOVED] tcp.reassembled.length\n",
      "[REMOVED] tcp.reassembled.data\n",
      "[REMOVED] tcp.port\n",
      "[REMOVED] tcp.payload\n",
      "[REMOVED] tcp.options.wscale.shift\n",
      "[REMOVED] tcp.options.wscale.multiplier\n",
      "[REMOVED] tcp.options.wscale\n",
      "[REMOVED] tcp.options.timestamp.tsval\n",
      "[REMOVED] tcp.options.timestamp.tsecr\n",
      "[REMOVED] tcp.options.sack_perm\n",
      "[REMOVED] tcp.options.mss_val\n",
      "[REMOVED] tcp.options.mss\n",
      "[REMOVED] tcp.options\n",
      "[REMOVED] tcp.nxtseq\n",
      "[REMOVED] tcp.dstport\n",
      "[REMOVED] tcp.checksum\n",
      "[REMOVED] tcp.checksum.status\n",
      "[REMOVED] tcp.flags.str\n",
      "[REMOVED] tcp.analysis.window_full\n",
      "[REMOVED] tcp.analysis.reused_ports\n",
      "[REMOVED] tcp.analysis.lost_segment\n",
      "[REMOVED] tcp.analysis.keep_alive_ack\n",
      "[REMOVED] tcp.analysis.keep_alive\n",
      "[REMOVED] tcp.analysis.flags\n",
      "[REMOVED] tcp.analysis.acks_frame\n",
      "[REMOVED] tcp.analysis.ack_lost_segment\n",
      "[REMOVED] tcp.analysis\n",
      "[REMOVED] tcp.ack_raw\n",
      "[REMOVED] tcp.ack\n",
      "[INFO] Unnecessary fields deleted with success\n"
     ]
    }
   ],
   "source": [
    "# Array: Fields to delete (IDs, Timestamps, Checksums, etc...)\n",
    "fieldsToDelete = [\n",
    "    'coap.opt.ctype', 'coap.opt.desc', 'coap.opt.name', 'coap.opt.uri_host', 'coap.opt.uri_path',\n",
    "    'coap.opt.uri_path_recon', 'coap.payload', 'coap.payload_desc', 'coap.token_len', 'data.data', 'udp.checksum',\n",
    "    'udp.checksum.status', 'udp.dstport', 'udp.length', 'udp.payload', 'udp.port', 'udp.possible_traceroute',\n",
    "    'udp.srcport', 'udp.time_delta', 'udp.stream', 'frame.encap_type', 'frame.ignored', 'frame.interface_id',\n",
    "    'frame.interface_name', 'frame.marked', 'frame.number', 'frame.offset_shift', 'frame.protocols', 'frame.time',\n",
    "    'frame.time_delta', 'frame.time_delta_displayed', 'frame.time_epoch', 'frame.time_relative', 'mqtt.hdr_reserved',\n",
    "    'mqtt.hdrflags', 'mqtt.len', 'mqtt.msg', 'mqtt.msgtype', 'mqtt.topic', 'mqtt.topic_len', 'ip.addr',\n",
    "    'ip.checksum', 'ip.checksum.status', 'ip.dsfield', 'ip.dsfield.dscp', 'ip.dsfield.ecn', 'ip.dst', 'ip.dst_host',\n",
    "    'ip.hdr_len', 'ip.host', 'ip.id', 'ip.len', 'ip.proto', 'ip.src', 'ip.src_host', 'ip.ttl.lncb',\n",
    "    'tcp.window_size', 'tcp.time_relative', 'tcp.time_delta', 'tcp.stream', 'tcp.srcport', 'tcp.seq_raw', 'tcp.seq',\n",
    "    'tcp.segments', 'tcp.segment_data', 'tcp.segment.count', 'tcp.segment', 'tcp.reassembled.length',\n",
    "    'tcp.reassembled.data', 'tcp.port', 'tcp.payload', 'tcp.options.wscale.shift', 'tcp.options.wscale.multiplier',\n",
    "    'tcp.options.wscale', 'tcp.options.timestamp.tsval', 'tcp.options.timestamp.tsecr', 'tcp.options.sack_perm',\n",
    "    'tcp.options.mss_val', 'tcp.options.mss', 'tcp.options', 'tcp.nxtseq', 'tcp.dstport', 'tcp.checksum',\n",
    "    'tcp.checksum.status', 'tcp.flags.str', 'tcp.analysis.window_full', 'tcp.analysis.reused_ports',\n",
    "    'tcp.analysis.lost_segment', 'tcp.analysis.keep_alive_ack', 'tcp.analysis.keep_alive', 'tcp.analysis.flags',\n",
    "    'tcp.analysis.acks_frame', 'tcp.analysis.ack_lost_segment', 'tcp.analysis', 'tcp.ack_raw', 'tcp.ack'\n",
    "]\n",
    "\n",
    "delete_fields(df, fieldsToDelete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d9d7e",
   "metadata": {},
   "source": [
    "### Pre-Processing & Data Encoding\n",
    "\n",
    "This section covers all the pre-processing and data encoding done in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8b3dc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Empty Cells Filling: 0x00000000\n"
     ]
    }
   ],
   "source": [
    "# Array: Hexadecimal fields to fill with 0x00000000\n",
    "hexadecimalFill = [\n",
    "    'ip.flags', 'tcp.flags'\n",
    "]\n",
    "\n",
    "fill_empty_cells(df, hexadecimalFill, '0x00000000') # Fill: 0x00000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4639f0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Integer Convert (Hex - Int)\n"
     ]
    }
   ],
   "source": [
    "# Array: Fields to convert from Hexadecimal to Integer\n",
    "hexadecimalFields = [\n",
    "    'ip.flags', 'tcp.flags'\n",
    "]\n",
    "\n",
    "hexadecimal_convert(df, hexadecimalFields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bfad27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Empty Cells Filling: 0\n",
      "[DONE] Empty Cells Filling: 1\n",
      "[DONE] Empty Cells Filling: -1\n"
     ]
    }
   ],
   "source": [
    "# Array: Fields to fill with 0\n",
    "fill_0 = [\n",
    "    'coap.code', 'coap.mid', 'coap.opt.delta', 'coap.opt.end_marker', 'coap.payload_length', 'data.len',\n",
    "    'mqtt.unknown_version', 'tcp.pdu.size', 'tcp.option_len', 'tcp.option_kind', 'tcp.hdr_len', 'tcp.connection.rst',\n",
    "    'tcp.connection.syn', 'tcp.connection.synack', 'tcp.connection.fin', 'tcp.analysis.bytes_in_flight',\n",
    "    'tcp.analysis.push_bytes_sent', 'tcp.analysis.ack_rtt', 'tcp.analysis.initial_rtt'\n",
    "]\n",
    "\n",
    "# Array: Fields to fill with 1\n",
    "fill_positive_1 = [\n",
    "    'coap.opt.length', 'coap.type', 'mqtt.dupflag', 'mqtt.retain', 'ip.flags.mf', 'ip.flags.rb', 'ip.frag_offset',\n",
    "    'tcp.urgent_pointer', 'tcp.flags.urg', 'tcp.flags.ns', 'tcp.flags.ecn', 'tcp.flags.cwr'\n",
    "]\n",
    "\n",
    "# Array: Fields to fill with -1\n",
    "fill_negative_1 = [\n",
    "    'mqtt.qos', 'ip.flags.df', 'ip.ttl', 'tcp.flags.syn', 'tcp.flags.reset', 'tcp.flags.push', 'tcp.flags.fin',\n",
    "    'tcp.flags.ack', \n",
    "]\n",
    "\n",
    "fill_empty_cells(df, fill_0, '0')            # Fill: 0\n",
    "fill_empty_cells(df, fill_positive_1, '1')   # Fill: 1\n",
    "fill_empty_cells(df, fill_negative_1, '-1')  # Fill: -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d425dae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Value Replacing: 255 -- 0\n",
      "[DONE] Value Replacing: 2 -- 1\n",
      "[DONE] Value Replacing: 6 -- 2\n",
      "[DONE] Value Replacing: 4 -- 1\n",
      "[DONE] Value Replacing: 10 -- 2\n"
     ]
    }
   ],
   "source": [
    "# Value replacing\n",
    "value_replacing(df, 'coap.opt.end_marker', '255', '0')\n",
    "value_replacing(df, 'tcp.pdu.size', '2', '1')\n",
    "value_replacing(df, 'tcp.pdu.size', '6', '2')\n",
    "value_replacing(df, 'tcp.option_len', '4', '1')\n",
    "value_replacing(df, 'tcp.option_len', '10', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c0e2139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Z-Score Normalization\n"
     ]
    }
   ],
   "source": [
    "# Array: Fields to apply z-score normalization\n",
    "zScoreNormalization = [\n",
    "    'coap.mid', 'coap.payload_length', 'data.len', 'frame.cap_len', 'frame.len', 'ip.ttl', 'tcp.len', 'tcp.hdr_len',\n",
    "    'tcp.flags', 'tcp.analysis.push_bytes_sent', 'tcp.analysis.bytes_in_flight'\n",
    "]\n",
    "\n",
    "for i in zScoreNormalization:\n",
    "    df[i] = df[i].astype(float)\n",
    "\n",
    "zscore_normalization(df, zScoreNormalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1d89696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Categorical Values (Dummies)\n"
     ]
    }
   ],
   "source": [
    "# Array: Fields to transform into categorical variables\n",
    "dummyEncoding = [\n",
    "    'coap.code', 'coap.opt.delta', 'coap.opt.length', 'coap.type', 'ip.flags'\n",
    "]\n",
    "\n",
    "df = dummy_encode(df, dummyEncoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a264151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Dataset labelling\n"
     ]
    }
   ],
   "source": [
    "# Labelling the dataset\n",
    "df['is_malicious'] = 0\n",
    "df['attack_type'] = 0\n",
    "print(f'[DONE] Dataset labelling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4bcaed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Dataset with pre-processing saved with success\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset with all the pre-processing and data encoding done\n",
    "df.to_csv(DATASET_PRE_PROCESSING, index = False)\n",
    "print(f'[DONE] Dataset with pre-processing saved with success')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

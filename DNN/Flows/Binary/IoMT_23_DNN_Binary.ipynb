{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_T2LCfAN_XF"
   },
   "source": [
    "### Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K1li4zpPN_XH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import display\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0t7965zN_XH"
   },
   "source": [
    "Panda Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "brXljTxkN_XI"
   },
   "outputs": [],
   "source": [
    "# Set options for displaying maximum columns and rows\n",
    "pd.set_option('display.max_columns', None)  \n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoPy7wczN_XI"
   },
   "source": [
    "**Read CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YM-QslAnN_XI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (6,7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id.orig_h</th>\n",
       "      <th>id.orig_p</th>\n",
       "      <th>id.resp_h</th>\n",
       "      <th>id.resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>local_orig</th>\n",
       "      <th>local_resp</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>history</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>tunnel_parents</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>fwd_header_size_max</th>\n",
       "      <th>bwd_header_size_tot</th>\n",
       "      <th>bwd_header_size_min</th>\n",
       "      <th>bwd_header_size_max</th>\n",
       "      <th>flow_FIN_flag_count</th>\n",
       "      <th>flow_SYN_flag_count</th>\n",
       "      <th>flow_RST_flag_count</th>\n",
       "      <th>fwd_PSH_flag_count</th>\n",
       "      <th>bwd_PSH_flag_count</th>\n",
       "      <th>flow_ACK_flag_count</th>\n",
       "      <th>fwd_URG_flag_count</th>\n",
       "      <th>bwd_URG_flag_count</th>\n",
       "      <th>flow_CWR_flag_count</th>\n",
       "      <th>flow_ECE_flag_count</th>\n",
       "      <th>fwd_pkts_payload.min</th>\n",
       "      <th>fwd_pkts_payload.max</th>\n",
       "      <th>fwd_pkts_payload.tot</th>\n",
       "      <th>fwd_pkts_payload.avg</th>\n",
       "      <th>fwd_pkts_payload.std</th>\n",
       "      <th>bwd_pkts_payload.min</th>\n",
       "      <th>bwd_pkts_payload.max</th>\n",
       "      <th>bwd_pkts_payload.tot</th>\n",
       "      <th>bwd_pkts_payload.avg</th>\n",
       "      <th>bwd_pkts_payload.std</th>\n",
       "      <th>flow_pkts_payload.min</th>\n",
       "      <th>flow_pkts_payload.max</th>\n",
       "      <th>flow_pkts_payload.tot</th>\n",
       "      <th>flow_pkts_payload.avg</th>\n",
       "      <th>flow_pkts_payload.std</th>\n",
       "      <th>fwd_iat.min</th>\n",
       "      <th>fwd_iat.max</th>\n",
       "      <th>fwd_iat.tot</th>\n",
       "      <th>fwd_iat.avg</th>\n",
       "      <th>fwd_iat.std</th>\n",
       "      <th>bwd_iat.min</th>\n",
       "      <th>bwd_iat.max</th>\n",
       "      <th>bwd_iat.tot</th>\n",
       "      <th>bwd_iat.avg</th>\n",
       "      <th>bwd_iat.std</th>\n",
       "      <th>flow_iat.min</th>\n",
       "      <th>flow_iat.max</th>\n",
       "      <th>flow_iat.tot</th>\n",
       "      <th>flow_iat.avg</th>\n",
       "      <th>flow_iat.std</th>\n",
       "      <th>payload_bytes_per_second</th>\n",
       "      <th>fwd_subflow_pkts</th>\n",
       "      <th>bwd_subflow_pkts</th>\n",
       "      <th>fwd_subflow_bytes</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>fwd_bulk_bytes</th>\n",
       "      <th>bwd_bulk_bytes</th>\n",
       "      <th>fwd_bulk_packets</th>\n",
       "      <th>bwd_bulk_packets</th>\n",
       "      <th>fwd_bulk_rate</th>\n",
       "      <th>bwd_bulk_rate</th>\n",
       "      <th>active.min</th>\n",
       "      <th>active.max</th>\n",
       "      <th>active.tot</th>\n",
       "      <th>active.avg</th>\n",
       "      <th>active.std</th>\n",
       "      <th>idle.min</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>traffic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.10.10.252</td>\n",
       "      <td>33540</td>\n",
       "      <td>224.0.0.251</td>\n",
       "      <td>5353</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>S0</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>arpspoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.10.10.252</td>\n",
       "      <td>50435</td>\n",
       "      <td>224.0.0.251</td>\n",
       "      <td>5353</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>S0</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>arpspoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.10.10.252</td>\n",
       "      <td>47976</td>\n",
       "      <td>224.0.0.251</td>\n",
       "      <td>5353</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>S0</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>arpspoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.10.10.252</td>\n",
       "      <td>37995</td>\n",
       "      <td>10.10.10.0</td>\n",
       "      <td>137</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>S0</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>arpspoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.10.10.252</td>\n",
       "      <td>38680</td>\n",
       "      <td>224.0.0.251</td>\n",
       "      <td>5353</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>S0</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>arpspoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325373</th>\n",
       "      <td>42.32.107.34</td>\n",
       "      <td>32572</td>\n",
       "      <td>148.94.193.65</td>\n",
       "      <td>52545</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>OTH</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>camoverflow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325374</th>\n",
       "      <td>101.16.71.87</td>\n",
       "      <td>24711</td>\n",
       "      <td>140.132.36.68</td>\n",
       "      <td>64950</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>OTH</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>camoverflow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325375</th>\n",
       "      <td>180.167.106.59</td>\n",
       "      <td>42487</td>\n",
       "      <td>233.22.169.101</td>\n",
       "      <td>42090</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>OTH</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>camoverflow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325376</th>\n",
       "      <td>233.188.148.20</td>\n",
       "      <td>60383</td>\n",
       "      <td>198.201.14.75</td>\n",
       "      <td>61891</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>OTH</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>camoverflow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325377</th>\n",
       "      <td>21.95.75.42</td>\n",
       "      <td>35597</td>\n",
       "      <td>79.22.74.54</td>\n",
       "      <td>59677</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>OTH</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>camoverflow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4325378 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id.orig_h  id.orig_p       id.resp_h  id.resp_p proto service  \\\n",
       "0          10.10.10.252      33540     224.0.0.251       5353   udp     dns   \n",
       "1          10.10.10.252      50435     224.0.0.251       5353   udp     dns   \n",
       "2          10.10.10.252      47976     224.0.0.251       5353   udp     dns   \n",
       "3          10.10.10.252      37995      10.10.10.0        137   udp     dns   \n",
       "4          10.10.10.252      38680     224.0.0.251       5353   udp     dns   \n",
       "...                 ...        ...             ...        ...   ...     ...   \n",
       "4325373    42.32.107.34      32572   148.94.193.65      52545   tcp       -   \n",
       "4325374    101.16.71.87      24711   140.132.36.68      64950   tcp       -   \n",
       "4325375  180.167.106.59      42487  233.22.169.101      42090   tcp       -   \n",
       "4325376  233.188.148.20      60383   198.201.14.75      61891   tcp       -   \n",
       "4325377     21.95.75.42      35597     79.22.74.54      59677   tcp       -   \n",
       "\n",
       "        duration orig_bytes resp_bytes conn_state local_orig local_resp  \\\n",
       "0              -          -          -         S0          T          F   \n",
       "1              -          -          -         S0          T          F   \n",
       "2              -          -          -         S0          T          F   \n",
       "3              -          -          -         S0          T          T   \n",
       "4              -          -          -         S0          T          F   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "4325373        -          -          -        OTH          F          F   \n",
       "4325374        -          -          -        OTH          F          F   \n",
       "4325375        -          -          -        OTH          F          F   \n",
       "4325376        -          -          -        OTH          F          F   \n",
       "4325377        -          -          -        OTH          F          F   \n",
       "\n",
       "         missed_bytes history  orig_pkts  orig_ip_bytes  resp_pkts  \\\n",
       "0                   0       D          1             73          0   \n",
       "1                   0       D          1             74          0   \n",
       "2                   0       D          1             57          0   \n",
       "3                   0       D          1             78          0   \n",
       "4                   0       D          1             67          0   \n",
       "...               ...     ...        ...            ...        ...   \n",
       "4325373             0       -          0              0          0   \n",
       "4325374             0       -          0              0          0   \n",
       "4325375             0       -          0              0          0   \n",
       "4325376             0       -          0              0          0   \n",
       "4325377             0       -          0              0          0   \n",
       "\n",
       "         resp_ip_bytes tunnel_parents  flow_duration  fwd_pkts_tot  \\\n",
       "0                    0              -            0.0             1   \n",
       "1                    0              -            0.0             1   \n",
       "2                    0              -            0.0             1   \n",
       "3                    0              -            0.0             1   \n",
       "4                    0              -            0.0             1   \n",
       "...                ...            ...            ...           ...   \n",
       "4325373              0              -            0.0             1   \n",
       "4325374              0              -            0.0             1   \n",
       "4325375              0              -            0.0             1   \n",
       "4325376              0              -            0.0             1   \n",
       "4325377              0              -            0.0             1   \n",
       "\n",
       "         bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  fwd_pkts_per_sec  \\\n",
       "0                   0                  1                  0               0.0   \n",
       "1                   0                  1                  0               0.0   \n",
       "2                   0                  1                  0               0.0   \n",
       "3                   0                  1                  0               0.0   \n",
       "4                   0                  1                  0               0.0   \n",
       "...               ...                ...                ...               ...   \n",
       "4325373             0                  0                  0               0.0   \n",
       "4325374             0                  0                  0               0.0   \n",
       "4325375             0                  0                  0               0.0   \n",
       "4325376             0                  0                  0               0.0   \n",
       "4325377             0                  0                  0               0.0   \n",
       "\n",
       "         bwd_pkts_per_sec  flow_pkts_per_sec  down_up_ratio  \\\n",
       "0                     0.0                0.0            0.0   \n",
       "1                     0.0                0.0            0.0   \n",
       "2                     0.0                0.0            0.0   \n",
       "3                     0.0                0.0            0.0   \n",
       "4                     0.0                0.0            0.0   \n",
       "...                   ...                ...            ...   \n",
       "4325373               0.0                0.0            0.0   \n",
       "4325374               0.0                0.0            0.0   \n",
       "4325375               0.0                0.0            0.0   \n",
       "4325376               0.0                0.0            0.0   \n",
       "4325377               0.0                0.0            0.0   \n",
       "\n",
       "         fwd_header_size_tot  fwd_header_size_min  fwd_header_size_max  \\\n",
       "0                          8                    8                    8   \n",
       "1                          8                    8                    8   \n",
       "2                          8                    8                    8   \n",
       "3                          8                    8                    8   \n",
       "4                          8                    8                    8   \n",
       "...                      ...                  ...                  ...   \n",
       "4325373                    0                    0                    0   \n",
       "4325374                    0                    0                    0   \n",
       "4325375                    0                    0                    0   \n",
       "4325376                    0                    0                    0   \n",
       "4325377                    0                    0                    0   \n",
       "\n",
       "         bwd_header_size_tot  bwd_header_size_min  bwd_header_size_max  \\\n",
       "0                          0                    0                    0   \n",
       "1                          0                    0                    0   \n",
       "2                          0                    0                    0   \n",
       "3                          0                    0                    0   \n",
       "4                          0                    0                    0   \n",
       "...                      ...                  ...                  ...   \n",
       "4325373                    0                    0                    0   \n",
       "4325374                    0                    0                    0   \n",
       "4325375                    0                    0                    0   \n",
       "4325376                    0                    0                    0   \n",
       "4325377                    0                    0                    0   \n",
       "\n",
       "         flow_FIN_flag_count  flow_SYN_flag_count  flow_RST_flag_count  \\\n",
       "0                          0                    0                    0   \n",
       "1                          0                    0                    0   \n",
       "2                          0                    0                    0   \n",
       "3                          0                    0                    0   \n",
       "4                          0                    0                    0   \n",
       "...                      ...                  ...                  ...   \n",
       "4325373                    0                    0                    0   \n",
       "4325374                    0                    0                    0   \n",
       "4325375                    0                    0                    0   \n",
       "4325376                    0                    0                    0   \n",
       "4325377                    0                    0                    0   \n",
       "\n",
       "         fwd_PSH_flag_count  bwd_PSH_flag_count  flow_ACK_flag_count  \\\n",
       "0                         0                   0                    0   \n",
       "1                         0                   0                    0   \n",
       "2                         0                   0                    0   \n",
       "3                         0                   0                    0   \n",
       "4                         0                   0                    0   \n",
       "...                     ...                 ...                  ...   \n",
       "4325373                   0                   0                    0   \n",
       "4325374                   0                   0                    0   \n",
       "4325375                   0                   0                    0   \n",
       "4325376                   0                   0                    0   \n",
       "4325377                   0                   0                    0   \n",
       "\n",
       "         fwd_URG_flag_count  bwd_URG_flag_count  flow_CWR_flag_count  \\\n",
       "0                         0                   0                    0   \n",
       "1                         0                   0                    0   \n",
       "2                         0                   0                    0   \n",
       "3                         0                   0                    0   \n",
       "4                         0                   0                    0   \n",
       "...                     ...                 ...                  ...   \n",
       "4325373                   0                   0                    0   \n",
       "4325374                   0                   0                    0   \n",
       "4325375                   0                   0                    0   \n",
       "4325376                   0                   0                    0   \n",
       "4325377                   0                   0                    0   \n",
       "\n",
       "         flow_ECE_flag_count  fwd_pkts_payload.min  fwd_pkts_payload.max  \\\n",
       "0                          0                  45.0                  45.0   \n",
       "1                          0                  46.0                  46.0   \n",
       "2                          0                  29.0                  29.0   \n",
       "3                          0                  50.0                  50.0   \n",
       "4                          0                  39.0                  39.0   \n",
       "...                      ...                   ...                   ...   \n",
       "4325373                    0                   0.0                   0.0   \n",
       "4325374                    0                   0.0                   0.0   \n",
       "4325375                    0                   0.0                   0.0   \n",
       "4325376                    0                   0.0                   0.0   \n",
       "4325377                    0                   0.0                   0.0   \n",
       "\n",
       "         fwd_pkts_payload.tot  fwd_pkts_payload.avg  fwd_pkts_payload.std  \\\n",
       "0                        45.0                  45.0                   0.0   \n",
       "1                        46.0                  46.0                   0.0   \n",
       "2                        29.0                  29.0                   0.0   \n",
       "3                        50.0                  50.0                   0.0   \n",
       "4                        39.0                  39.0                   0.0   \n",
       "...                       ...                   ...                   ...   \n",
       "4325373                   0.0                   0.0                   0.0   \n",
       "4325374                   0.0                   0.0                   0.0   \n",
       "4325375                   0.0                   0.0                   0.0   \n",
       "4325376                   0.0                   0.0                   0.0   \n",
       "4325377                   0.0                   0.0                   0.0   \n",
       "\n",
       "         bwd_pkts_payload.min  bwd_pkts_payload.max  bwd_pkts_payload.tot  \\\n",
       "0                         0.0                   0.0                   0.0   \n",
       "1                         0.0                   0.0                   0.0   \n",
       "2                         0.0                   0.0                   0.0   \n",
       "3                         0.0                   0.0                   0.0   \n",
       "4                         0.0                   0.0                   0.0   \n",
       "...                       ...                   ...                   ...   \n",
       "4325373                   0.0                   0.0                   0.0   \n",
       "4325374                   0.0                   0.0                   0.0   \n",
       "4325375                   0.0                   0.0                   0.0   \n",
       "4325376                   0.0                   0.0                   0.0   \n",
       "4325377                   0.0                   0.0                   0.0   \n",
       "\n",
       "         bwd_pkts_payload.avg  bwd_pkts_payload.std  flow_pkts_payload.min  \\\n",
       "0                         0.0                   0.0                   45.0   \n",
       "1                         0.0                   0.0                   46.0   \n",
       "2                         0.0                   0.0                   29.0   \n",
       "3                         0.0                   0.0                   50.0   \n",
       "4                         0.0                   0.0                   39.0   \n",
       "...                       ...                   ...                    ...   \n",
       "4325373                   0.0                   0.0                    0.0   \n",
       "4325374                   0.0                   0.0                    0.0   \n",
       "4325375                   0.0                   0.0                    0.0   \n",
       "4325376                   0.0                   0.0                    0.0   \n",
       "4325377                   0.0                   0.0                    0.0   \n",
       "\n",
       "         flow_pkts_payload.max  flow_pkts_payload.tot  flow_pkts_payload.avg  \\\n",
       "0                         45.0                   45.0                   45.0   \n",
       "1                         46.0                   46.0                   46.0   \n",
       "2                         29.0                   29.0                   29.0   \n",
       "3                         50.0                   50.0                   50.0   \n",
       "4                         39.0                   39.0                   39.0   \n",
       "...                        ...                    ...                    ...   \n",
       "4325373                    0.0                    0.0                    0.0   \n",
       "4325374                    0.0                    0.0                    0.0   \n",
       "4325375                    0.0                    0.0                    0.0   \n",
       "4325376                    0.0                    0.0                    0.0   \n",
       "4325377                    0.0                    0.0                    0.0   \n",
       "\n",
       "         flow_pkts_payload.std  fwd_iat.min  fwd_iat.max  fwd_iat.tot  \\\n",
       "0                          0.0          0.0          0.0          0.0   \n",
       "1                          0.0          0.0          0.0          0.0   \n",
       "2                          0.0          0.0          0.0          0.0   \n",
       "3                          0.0          0.0          0.0          0.0   \n",
       "4                          0.0          0.0          0.0          0.0   \n",
       "...                        ...          ...          ...          ...   \n",
       "4325373                    0.0          0.0          0.0          0.0   \n",
       "4325374                    0.0          0.0          0.0          0.0   \n",
       "4325375                    0.0          0.0          0.0          0.0   \n",
       "4325376                    0.0          0.0          0.0          0.0   \n",
       "4325377                    0.0          0.0          0.0          0.0   \n",
       "\n",
       "         fwd_iat.avg  fwd_iat.std  bwd_iat.min  bwd_iat.max  bwd_iat.tot  \\\n",
       "0                0.0          0.0          0.0          0.0          0.0   \n",
       "1                0.0          0.0          0.0          0.0          0.0   \n",
       "2                0.0          0.0          0.0          0.0          0.0   \n",
       "3                0.0          0.0          0.0          0.0          0.0   \n",
       "4                0.0          0.0          0.0          0.0          0.0   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "4325373          0.0          0.0          0.0          0.0          0.0   \n",
       "4325374          0.0          0.0          0.0          0.0          0.0   \n",
       "4325375          0.0          0.0          0.0          0.0          0.0   \n",
       "4325376          0.0          0.0          0.0          0.0          0.0   \n",
       "4325377          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "         bwd_iat.avg  bwd_iat.std  flow_iat.min  flow_iat.max  flow_iat.tot  \\\n",
       "0                0.0          0.0           0.0           0.0           0.0   \n",
       "1                0.0          0.0           0.0           0.0           0.0   \n",
       "2                0.0          0.0           0.0           0.0           0.0   \n",
       "3                0.0          0.0           0.0           0.0           0.0   \n",
       "4                0.0          0.0           0.0           0.0           0.0   \n",
       "...              ...          ...           ...           ...           ...   \n",
       "4325373          0.0          0.0           0.0           0.0           0.0   \n",
       "4325374          0.0          0.0           0.0           0.0           0.0   \n",
       "4325375          0.0          0.0           0.0           0.0           0.0   \n",
       "4325376          0.0          0.0           0.0           0.0           0.0   \n",
       "4325377          0.0          0.0           0.0           0.0           0.0   \n",
       "\n",
       "         flow_iat.avg  flow_iat.std  payload_bytes_per_second  \\\n",
       "0                 0.0           0.0                       0.0   \n",
       "1                 0.0           0.0                       0.0   \n",
       "2                 0.0           0.0                       0.0   \n",
       "3                 0.0           0.0                       0.0   \n",
       "4                 0.0           0.0                       0.0   \n",
       "...               ...           ...                       ...   \n",
       "4325373           0.0           0.0                       0.0   \n",
       "4325374           0.0           0.0                       0.0   \n",
       "4325375           0.0           0.0                       0.0   \n",
       "4325376           0.0           0.0                       0.0   \n",
       "4325377           0.0           0.0                       0.0   \n",
       "\n",
       "         fwd_subflow_pkts  bwd_subflow_pkts  fwd_subflow_bytes  \\\n",
       "0                     1.0               0.0               45.0   \n",
       "1                     1.0               0.0               46.0   \n",
       "2                     1.0               0.0               29.0   \n",
       "3                     1.0               0.0               50.0   \n",
       "4                     1.0               0.0               39.0   \n",
       "...                   ...               ...                ...   \n",
       "4325373               1.0               0.0                0.0   \n",
       "4325374               1.0               0.0                0.0   \n",
       "4325375               1.0               0.0                0.0   \n",
       "4325376               1.0               0.0                0.0   \n",
       "4325377               1.0               0.0                0.0   \n",
       "\n",
       "         bwd_subflow_bytes  fwd_bulk_bytes  bwd_bulk_bytes  fwd_bulk_packets  \\\n",
       "0                      0.0             0.0             0.0               0.0   \n",
       "1                      0.0             0.0             0.0               0.0   \n",
       "2                      0.0             0.0             0.0               0.0   \n",
       "3                      0.0             0.0             0.0               0.0   \n",
       "4                      0.0             0.0             0.0               0.0   \n",
       "...                    ...             ...             ...               ...   \n",
       "4325373                0.0             0.0             0.0               0.0   \n",
       "4325374                0.0             0.0             0.0               0.0   \n",
       "4325375                0.0             0.0             0.0               0.0   \n",
       "4325376                0.0             0.0             0.0               0.0   \n",
       "4325377                0.0             0.0             0.0               0.0   \n",
       "\n",
       "         bwd_bulk_packets  fwd_bulk_rate  bwd_bulk_rate  active.min  \\\n",
       "0                     0.0            0.0            0.0         0.0   \n",
       "1                     0.0            0.0            0.0         0.0   \n",
       "2                     0.0            0.0            0.0         0.0   \n",
       "3                     0.0            0.0            0.0         0.0   \n",
       "4                     0.0            0.0            0.0         0.0   \n",
       "...                   ...            ...            ...         ...   \n",
       "4325373               0.0            0.0            0.0         0.0   \n",
       "4325374               0.0            0.0            0.0         0.0   \n",
       "4325375               0.0            0.0            0.0         0.0   \n",
       "4325376               0.0            0.0            0.0         0.0   \n",
       "4325377               0.0            0.0            0.0         0.0   \n",
       "\n",
       "         active.max  active.tot  active.avg  active.std  idle.min  idle.max  \\\n",
       "0               0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "1               0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "2               0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "3               0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "4               0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "...             ...         ...         ...         ...       ...       ...   \n",
       "4325373         0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "4325374         0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "4325375         0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "4325376         0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "4325377         0.0         0.0         0.0         0.0       0.0       0.0   \n",
       "\n",
       "         idle.tot  idle.avg  idle.std  fwd_init_window_size  \\\n",
       "0             0.0       0.0       0.0                     0   \n",
       "1             0.0       0.0       0.0                     0   \n",
       "2             0.0       0.0       0.0                     0   \n",
       "3             0.0       0.0       0.0                     0   \n",
       "4             0.0       0.0       0.0                     0   \n",
       "...           ...       ...       ...                   ...   \n",
       "4325373       0.0       0.0       0.0                     0   \n",
       "4325374       0.0       0.0       0.0                     0   \n",
       "4325375       0.0       0.0       0.0                     0   \n",
       "4325376       0.0       0.0       0.0                     0   \n",
       "4325377       0.0       0.0       0.0                     0   \n",
       "\n",
       "         bwd_init_window_size  fwd_last_window_size  bwd_last_window_size  \\\n",
       "0                           0                     0                     0   \n",
       "1                           0                     0                     0   \n",
       "2                           0                     0                     0   \n",
       "3                           0                     0                     0   \n",
       "4                           0                     0                     0   \n",
       "...                       ...                   ...                   ...   \n",
       "4325373                     0                     0                     0   \n",
       "4325374                     0                     0                     0   \n",
       "4325375                     0                     0                     0   \n",
       "4325376                     0                     0                     0   \n",
       "4325377                     0                     0                     0   \n",
       "\n",
       "             traffic  label  \n",
       "0        arpspoofing      1  \n",
       "1        arpspoofing      1  \n",
       "2        arpspoofing      1  \n",
       "3        arpspoofing      1  \n",
       "4        arpspoofing      1  \n",
       "...              ...    ...  \n",
       "4325373  camoverflow      1  \n",
       "4325374  camoverflow      1  \n",
       "4325375  camoverflow      1  \n",
       "4325376  camoverflow      1  \n",
       "4325377  camoverflow      1  \n",
       "\n",
       "[4325378 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"../../../Datasets/Flows/iomt_flows.csv\")\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xEU9UPRN_XI"
   },
   "source": [
    "Fix Dataframe Mixed Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SDKSZ_89N_XJ"
   },
   "outputs": [],
   "source": [
    "# Remove rows with '-' character in columns 6, 7 and 8\n",
    "cols_to_check = ['duration', 'orig_bytes', 'resp_bytes']\n",
    "\n",
    "# Create a boolean mask to identify rows with '-' character\n",
    "mask = df[cols_to_check].apply(lambda x: x.str.contains('-', na=False)).any(axis=1)\n",
    "\n",
    "# Use the mask to filter out rows with '-' character\n",
    "df = df[~mask]\n",
    "\n",
    "# Replace comma with period as decimal separator\n",
    "cols_to_float = ['duration']\n",
    "\n",
    "# Replace ',' with '.' in specified columns\n",
    "df[cols_to_float] = df[cols_to_float].replace(',', '.', regex=True)\n",
    "\n",
    "# Convert columns 7 and 8 to float and int data types\n",
    "cols_to_int = ['orig_bytes', 'resp_bytes']\n",
    "\n",
    "# Convert specified columns to float and int types\n",
    "df[cols_to_float] = df[cols_to_float].astype(float)\n",
    "df[cols_to_int] = df[cols_to_int].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3OxjJEb6fxi"
   },
   "source": [
    "-----------------------------------------------------------\n",
    "\n",
    "## DF Statistics and Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ljdybTvfN_XJ"
   },
   "outputs": [],
   "source": [
    "def display_information_dataframe(df_cop):\n",
    "    # Create a summary of data types, column names, and unique values\n",
    "    summary_data = [{'Data Type': dtype, 'Column Name': col, 'Unique Values': df_cop[col].unique()} for col, dtype in df_cop.dtypes.iteritems()]\n",
    "    \n",
    "    # Create a DataFrame from the summary data\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Set display options to show all rows and columns\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.options.display.max_columns = None\n",
    "    \n",
    "    # Return the summary DataFrame\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4BJ-3JT66fxi",
    "outputId": "38be4775-5564-4772-f561-ed34f559bdd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>object</td>\n",
       "      <td>id.orig_h</td>\n",
       "      <td>[10.10.10.252, 10.10.10.1, 10.10.10.249, 0.0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>int64</td>\n",
       "      <td>id.orig_p</td>\n",
       "      <td>[5353, 36990, 45852, 55492, 59436, 60249, 5084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>object</td>\n",
       "      <td>id.resp_h</td>\n",
       "      <td>[224.0.0.251, 10.10.10.255, 10.10.10.249, 255....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>int64</td>\n",
       "      <td>id.resp_p</td>\n",
       "      <td>[5353, 57621, 80, 22, 48969, 54845, 19582, 355...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>object</td>\n",
       "      <td>proto</td>\n",
       "      <td>[udp, tcp, icmp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>object</td>\n",
       "      <td>service</td>\n",
       "      <td>[dns, -, http, mqtt, dhcp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>float64</td>\n",
       "      <td>duration</td>\n",
       "      <td>[57.262413, 3.002431, 0.208294, 0.209607, 0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>int64</td>\n",
       "      <td>orig_bytes</td>\n",
       "      <td>[1515, 75, 406, 405, 586, 569, 759, 763, 583, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>int64</td>\n",
       "      <td>resp_bytes</td>\n",
       "      <td>[0, 851, 712, 310, 1111456671, 1287165066, 173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>object</td>\n",
       "      <td>conn_state</td>\n",
       "      <td>[S0, SH, RSTR, OTH, RSTRH, S2, RSTOS0, REJ, SH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>object</td>\n",
       "      <td>local_orig</td>\n",
       "      <td>[T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>object</td>\n",
       "      <td>local_resp</td>\n",
       "      <td>[F, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>int64</td>\n",
       "      <td>missed_bytes</td>\n",
       "      <td>[0, 712, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>object</td>\n",
       "      <td>history</td>\n",
       "      <td>[D, ScAD, ScADF, ^cAFr, ScADdFr, DcAc, ^cA, ^c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>int64</td>\n",
       "      <td>orig_pkts</td>\n",
       "      <td>[34, 2, 7, 10, 13, 55, 5, 472, 117, 6, 4, 3, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>int64</td>\n",
       "      <td>orig_ip_bytes</td>\n",
       "      <td>[2467, 131, 602, 601, 866, 849, 1123, 1127, 86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>int64</td>\n",
       "      <td>resp_pkts</td>\n",
       "      <td>[0, 1, 2, 3, 240, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>int64</td>\n",
       "      <td>resp_ip_bytes</td>\n",
       "      <td>[0, 40, 80, 668, 60, 763, 361, 52, 120, 39120,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>object</td>\n",
       "      <td>tunnel_parents</td>\n",
       "      <td>[-]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_duration</td>\n",
       "      <td>[57.262413, 3.002431, 0.208294, 0.209607000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_pkts_tot</td>\n",
       "      <td>[34, 2, 7, 10, 13, 55, 5, 472, 117, 6, 4, 3, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_pkts_tot</td>\n",
       "      <td>[0, 4, 5, 2, 3, 6, 26, 1, 7, 8, 240, 15, 9, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_data_pkts_tot</td>\n",
       "      <td>[34, 2, 7, 10, 13, 55, 5, 472, 117, 1, 0, 74, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_data_pkts_tot</td>\n",
       "      <td>[0, 2, 1, 3, 26, 4, 240, 16, 19, 18, 6, 14, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_per_sec</td>\n",
       "      <td>[0.593758, 0.666127, 33.606359000000005, 33.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_per_sec</td>\n",
       "      <td>[0.0, 60.843008, 61.064015000000005, 61.214630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_per_sec</td>\n",
       "      <td>[0.593758, 0.666127, 33.606359000000005, 33.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>float64</td>\n",
       "      <td>down_up_ratio</td>\n",
       "      <td>[0.0, 0.8, 0.666667, 1.0, 1.25, 0.857143, 0.74...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_header_size_tot</td>\n",
       "      <td>[272, 16, 56, 80, 104, 440, 40, 3776, 936, 168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_header_size_min</td>\n",
       "      <td>[8, 32, 20, 24, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_header_size_max</td>\n",
       "      <td>[8, 40, 44, 32, 24, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_header_size_tot</td>\n",
       "      <td>[0, 136, 168, 52, 72, 188, 832, 32, 104, 64, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_header_size_min</td>\n",
       "      <td>[0, 32, 20, 40, 24, 36, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_header_size_max</td>\n",
       "      <td>[0, 40, 32, 44, 24, 20, 36, 8, 52]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_FIN_flag_count</td>\n",
       "      <td>[0, 2, 3, 1, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_SYN_flag_count</td>\n",
       "      <td>[0, 2, 1, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_RST_flag_count</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_PSH_flag_count</td>\n",
       "      <td>[0, 1, 10, 2, 3, 282, 286, 287, 283, 285, 277,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_PSH_flag_count</td>\n",
       "      <td>[0, 1, 2, 26, 3, 4, 16, 19, 18, 6, 14, 9, 7, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_ACK_flag_count</td>\n",
       "      <td>[0, 8, 9, 7, 3, 4, 11, 61, 2, 6, 5, 10, 12, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_URG_flag_count</td>\n",
       "      <td>[0, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_URG_flag_count</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_CWR_flag_count</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>int64</td>\n",
       "      <td>flow_ECE_flag_count</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_payload.min</td>\n",
       "      <td>[40.0, 29.0, 46.0, 45.0, 39.0, 43.0, 47.0, 50....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_payload.max</td>\n",
       "      <td>[45.0, 46.0, 60.0, 198.0, 118.0, 44.0, 279.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_payload.tot</td>\n",
       "      <td>[1515.0, 75.0, 406.0, 405.0, 586.0, 569.0, 759...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_payload.avg</td>\n",
       "      <td>[44.558824, 37.5, 58.0, 57.85714300000001, 58....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_pkts_payload.std</td>\n",
       "      <td>[1.439511, 12.020814999999999, 5.291503, 5.669...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_payload.min</td>\n",
       "      <td>[0.0, 36.0, 120.0, 94.0, 2.0, 44.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_payload.max</td>\n",
       "      <td>[0.0, 576.0, 850.0, 324.0, 711.0, 309.0, 40.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_payload.tot</td>\n",
       "      <td>[0.0, 850.0, 1124.0, 2168.0, 711.0, 309.0, 142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_payload.avg</td>\n",
       "      <td>[0.0, 212.5, 224.8, 141.666667, 83.384615, 237...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_pkts_payload.std</td>\n",
       "      <td>[0.0, 274.606992, 425.0, 239.401754, 239.34716...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_payload.min</td>\n",
       "      <td>[40.0, 29.0, 46.0, 45.0, 39.0, 43.0, 47.0, 50....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_payload.max</td>\n",
       "      <td>[45.0, 46.0, 60.0, 198.0, 118.0, 44.0, 576.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_payload.tot</td>\n",
       "      <td>[1515.0, 75.0, 406.0, 405.0, 586.0, 569.0, 759...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_payload.avg</td>\n",
       "      <td>[44.558824, 37.5, 58.0, 57.85714300000001, 58....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_pkts_payload.std</td>\n",
       "      <td>[1.439511, 12.020814999999999, 5.291503, 5.669...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_iat.min</td>\n",
       "      <td>[38684.129714999995, 3002430.915833, 5.0067900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_iat.max</td>\n",
       "      <td>[2000760.07843, 3002430.915833, 207557.9166410...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_iat.tot</td>\n",
       "      <td>[57262413.024902, 3002430.915833, 208293.91479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_iat.avg</td>\n",
       "      <td>[1735224.637118, 3002430.915833, 34715.652466,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_iat.std</td>\n",
       "      <td>[642472.5112739999, 0.0, 84675.319676, 84982.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_iat.min</td>\n",
       "      <td>[0.0, 664.949417, 368.118286, 550.031662, 1080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_iat.max</td>\n",
       "      <td>[0.0, 20202.875137, 20545.005798, 20215.034485...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_iat.tot</td>\n",
       "      <td>[0.0, 21582.841872999998, 21459.102631, 21322....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_iat.avg</td>\n",
       "      <td>[0.0, 7194.280623999999, 7153.03421, 7107.3373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_iat.std</td>\n",
       "      <td>[0.0, 11265.80113, 11598.128549, 11351.5992599...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_iat.min</td>\n",
       "      <td>[38684.129714999995, 3002430.915833, 5.0067900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_iat.max</td>\n",
       "      <td>[2000760.07843, 3002430.915833, 207557.9166410...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_iat.tot</td>\n",
       "      <td>[57262413.024902, 3002430.915833, 208293.91479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_iat.avg</td>\n",
       "      <td>[1735224.637118, 3002430.915833, 34715.652466,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>float64</td>\n",
       "      <td>flow_iat.std</td>\n",
       "      <td>[642472.5112739999, 0.0, 84675.319676, 84982.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>float64</td>\n",
       "      <td>payload_bytes_per_second</td>\n",
       "      <td>[26.457146, 24.979759, 1949.1688, 1932.186233,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_subflow_pkts</td>\n",
       "      <td>[1.133333, 1.0, 7.0, 10.0, 13.0, 13.75, 1.0086...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_subflow_pkts</td>\n",
       "      <td>[0.0, 4.0, 5.0, 1.0, 1.5, 2.0, 26.0, 3.0, 2.5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_subflow_bytes</td>\n",
       "      <td>[50.5, 37.5, 406.0, 405.0, 586.0, 569.0, 759.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_subflow_bytes</td>\n",
       "      <td>[0.0, 850.0, 1124.0, 283.333333, 2168.0, 711.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_bulk_bytes</td>\n",
       "      <td>[0.0, 406.0, 405.0, 586.0, 569.0, 759.0, 763.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_bulk_bytes</td>\n",
       "      <td>[0.0, 836.0, 20.0, 24.0, 28.0, 32.0, 36.0, 40....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_bulk_packets</td>\n",
       "      <td>[0.0, 7.0, 10.0, 13.0, 17.666667, 282.0, 286.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_bulk_packets</td>\n",
       "      <td>[0.0, 8.0, 5.0, 6.0, 7.0, 9.0, 10.0, 11.0, 17....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>float64</td>\n",
       "      <td>fwd_bulk_rate</td>\n",
       "      <td>[0.0, 1949.1688, 1932.186233, 2818.109541, 274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>float64</td>\n",
       "      <td>bwd_bulk_rate</td>\n",
       "      <td>[0.0, 46924.251347000005, 51.213504, 51.780188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>float64</td>\n",
       "      <td>active.min</td>\n",
       "      <td>[57262413.024902, 3002430.915833, 208293.91479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>float64</td>\n",
       "      <td>active.max</td>\n",
       "      <td>[57262413.024902, 3002430.915833, 208293.91479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>float64</td>\n",
       "      <td>active.tot</td>\n",
       "      <td>[57262413.024902, 3002430.915833, 208293.91479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>float64</td>\n",
       "      <td>active.avg</td>\n",
       "      <td>[57262413.024902, 3002430.915833, 208293.91479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>float64</td>\n",
       "      <td>active.std</td>\n",
       "      <td>[0.0, 181677.269011, 29231.199666000004, 41902...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>float64</td>\n",
       "      <td>idle.min</td>\n",
       "      <td>[0.0, 8001144.170761, 5795279.026031, 5792163....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>float64</td>\n",
       "      <td>idle.max</td>\n",
       "      <td>[0.0, 8001144.170761, 5795279.026031, 5792163....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>float64</td>\n",
       "      <td>idle.tot</td>\n",
       "      <td>[0.0, 8001144.170761, 5795279.026031, 5792163....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>float64</td>\n",
       "      <td>idle.avg</td>\n",
       "      <td>[0.0, 8001144.170761, 5795279.026031, 5792163....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>float64</td>\n",
       "      <td>idle.std</td>\n",
       "      <td>[0.0, 10012.734441, 4270739.749407, 15102915.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_init_window_size</td>\n",
       "      <td>[0, 1152, 64240, 301, 4584, 501, 1024, 1, 63, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_init_window_size</td>\n",
       "      <td>[0, 65160, 507, 508, 501, 506, 64240, 502, 503...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>int64</td>\n",
       "      <td>fwd_last_window_size</td>\n",
       "      <td>[0, 302, 501, 1152, 4584, 301, 497, 500, 502, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>int64</td>\n",
       "      <td>bwd_last_window_size</td>\n",
       "      <td>[0, 507, 508, 501, 506, 510, 65160, 64240, 509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>object</td>\n",
       "      <td>traffic</td>\n",
       "      <td>[arpspoofing, slowread, rudeadyet, netscan, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>int64</td>\n",
       "      <td>label</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data Type               Column Name  \\\n",
       "0      object                 id.orig_h   \n",
       "1       int64                 id.orig_p   \n",
       "2      object                 id.resp_h   \n",
       "3       int64                 id.resp_p   \n",
       "4      object                     proto   \n",
       "5      object                   service   \n",
       "6     float64                  duration   \n",
       "7       int64                orig_bytes   \n",
       "8       int64                resp_bytes   \n",
       "9      object                conn_state   \n",
       "10     object                local_orig   \n",
       "11     object                local_resp   \n",
       "12      int64              missed_bytes   \n",
       "13     object                   history   \n",
       "14      int64                 orig_pkts   \n",
       "15      int64             orig_ip_bytes   \n",
       "16      int64                 resp_pkts   \n",
       "17      int64             resp_ip_bytes   \n",
       "18     object            tunnel_parents   \n",
       "19    float64             flow_duration   \n",
       "20      int64              fwd_pkts_tot   \n",
       "21      int64              bwd_pkts_tot   \n",
       "22      int64         fwd_data_pkts_tot   \n",
       "23      int64         bwd_data_pkts_tot   \n",
       "24    float64          fwd_pkts_per_sec   \n",
       "25    float64          bwd_pkts_per_sec   \n",
       "26    float64         flow_pkts_per_sec   \n",
       "27    float64             down_up_ratio   \n",
       "28      int64       fwd_header_size_tot   \n",
       "29      int64       fwd_header_size_min   \n",
       "30      int64       fwd_header_size_max   \n",
       "31      int64       bwd_header_size_tot   \n",
       "32      int64       bwd_header_size_min   \n",
       "33      int64       bwd_header_size_max   \n",
       "34      int64       flow_FIN_flag_count   \n",
       "35      int64       flow_SYN_flag_count   \n",
       "36      int64       flow_RST_flag_count   \n",
       "37      int64        fwd_PSH_flag_count   \n",
       "38      int64        bwd_PSH_flag_count   \n",
       "39      int64       flow_ACK_flag_count   \n",
       "40      int64        fwd_URG_flag_count   \n",
       "41      int64        bwd_URG_flag_count   \n",
       "42      int64       flow_CWR_flag_count   \n",
       "43      int64       flow_ECE_flag_count   \n",
       "44    float64      fwd_pkts_payload.min   \n",
       "45    float64      fwd_pkts_payload.max   \n",
       "46    float64      fwd_pkts_payload.tot   \n",
       "47    float64      fwd_pkts_payload.avg   \n",
       "48    float64      fwd_pkts_payload.std   \n",
       "49    float64      bwd_pkts_payload.min   \n",
       "50    float64      bwd_pkts_payload.max   \n",
       "51    float64      bwd_pkts_payload.tot   \n",
       "52    float64      bwd_pkts_payload.avg   \n",
       "53    float64      bwd_pkts_payload.std   \n",
       "54    float64     flow_pkts_payload.min   \n",
       "55    float64     flow_pkts_payload.max   \n",
       "56    float64     flow_pkts_payload.tot   \n",
       "57    float64     flow_pkts_payload.avg   \n",
       "58    float64     flow_pkts_payload.std   \n",
       "59    float64               fwd_iat.min   \n",
       "60    float64               fwd_iat.max   \n",
       "61    float64               fwd_iat.tot   \n",
       "62    float64               fwd_iat.avg   \n",
       "63    float64               fwd_iat.std   \n",
       "64    float64               bwd_iat.min   \n",
       "65    float64               bwd_iat.max   \n",
       "66    float64               bwd_iat.tot   \n",
       "67    float64               bwd_iat.avg   \n",
       "68    float64               bwd_iat.std   \n",
       "69    float64              flow_iat.min   \n",
       "70    float64              flow_iat.max   \n",
       "71    float64              flow_iat.tot   \n",
       "72    float64              flow_iat.avg   \n",
       "73    float64              flow_iat.std   \n",
       "74    float64  payload_bytes_per_second   \n",
       "75    float64          fwd_subflow_pkts   \n",
       "76    float64          bwd_subflow_pkts   \n",
       "77    float64         fwd_subflow_bytes   \n",
       "78    float64         bwd_subflow_bytes   \n",
       "79    float64            fwd_bulk_bytes   \n",
       "80    float64            bwd_bulk_bytes   \n",
       "81    float64          fwd_bulk_packets   \n",
       "82    float64          bwd_bulk_packets   \n",
       "83    float64             fwd_bulk_rate   \n",
       "84    float64             bwd_bulk_rate   \n",
       "85    float64                active.min   \n",
       "86    float64                active.max   \n",
       "87    float64                active.tot   \n",
       "88    float64                active.avg   \n",
       "89    float64                active.std   \n",
       "90    float64                  idle.min   \n",
       "91    float64                  idle.max   \n",
       "92    float64                  idle.tot   \n",
       "93    float64                  idle.avg   \n",
       "94    float64                  idle.std   \n",
       "95      int64      fwd_init_window_size   \n",
       "96      int64      bwd_init_window_size   \n",
       "97      int64      fwd_last_window_size   \n",
       "98      int64      bwd_last_window_size   \n",
       "99     object                   traffic   \n",
       "100     int64                     label   \n",
       "\n",
       "                                         Unique Values  \n",
       "0    [10.10.10.252, 10.10.10.1, 10.10.10.249, 0.0.0...  \n",
       "1    [5353, 36990, 45852, 55492, 59436, 60249, 5084...  \n",
       "2    [224.0.0.251, 10.10.10.255, 10.10.10.249, 255....  \n",
       "3    [5353, 57621, 80, 22, 48969, 54845, 19582, 355...  \n",
       "4                                     [udp, tcp, icmp]  \n",
       "5                           [dns, -, http, mqtt, dhcp]  \n",
       "6    [57.262413, 3.002431, 0.208294, 0.209607, 0.20...  \n",
       "7    [1515, 75, 406, 405, 586, 569, 759, 763, 583, ...  \n",
       "8    [0, 851, 712, 310, 1111456671, 1287165066, 173...  \n",
       "9    [S0, SH, RSTR, OTH, RSTRH, S2, RSTOS0, REJ, SH...  \n",
       "10                                                 [T]  \n",
       "11                                              [F, T]  \n",
       "12                                         [0, 712, 1]  \n",
       "13   [D, ScAD, ScADF, ^cAFr, ScADdFr, DcAc, ^cA, ^c...  \n",
       "14   [34, 2, 7, 10, 13, 55, 5, 472, 117, 6, 4, 3, 3...  \n",
       "15   [2467, 131, 602, 601, 866, 849, 1123, 1127, 86...  \n",
       "16                                [0, 1, 2, 3, 240, 4]  \n",
       "17   [0, 40, 80, 668, 60, 763, 361, 52, 120, 39120,...  \n",
       "18                                                 [-]  \n",
       "19   [57.262413, 3.002431, 0.208294, 0.209607000000...  \n",
       "20   [34, 2, 7, 10, 13, 55, 5, 472, 117, 6, 4, 3, 3...  \n",
       "21   [0, 4, 5, 2, 3, 6, 26, 1, 7, 8, 240, 15, 9, 12...  \n",
       "22   [34, 2, 7, 10, 13, 55, 5, 472, 117, 1, 0, 74, ...  \n",
       "23   [0, 2, 1, 3, 26, 4, 240, 16, 19, 18, 6, 14, 9,...  \n",
       "24   [0.593758, 0.666127, 33.606359000000005, 33.39...  \n",
       "25   [0.0, 60.843008, 61.064015000000005, 61.214630...  \n",
       "26   [0.593758, 0.666127, 33.606359000000005, 33.39...  \n",
       "27   [0.0, 0.8, 0.666667, 1.0, 1.25, 0.857143, 0.74...  \n",
       "28   [272, 16, 56, 80, 104, 440, 40, 3776, 936, 168...  \n",
       "29                                 [8, 32, 20, 24, 40]  \n",
       "30                             [8, 40, 44, 32, 24, 36]  \n",
       "31   [0, 136, 168, 52, 72, 188, 832, 32, 104, 64, 9...  \n",
       "32                          [0, 32, 20, 40, 24, 36, 8]  \n",
       "33                  [0, 40, 32, 44, 24, 20, 36, 8, 52]  \n",
       "34                                     [0, 2, 3, 1, 4]  \n",
       "35                                     [0, 2, 1, 4, 3]  \n",
       "36                                        [0, 1, 2, 3]  \n",
       "37   [0, 1, 10, 2, 3, 282, 286, 287, 283, 285, 277,...  \n",
       "38   [0, 1, 2, 26, 3, 4, 16, 19, 18, 6, 14, 9, 7, 2...  \n",
       "39   [0, 8, 9, 7, 3, 4, 11, 61, 2, 6, 5, 10, 12, 1,...  \n",
       "40                                           [0, 3, 2]  \n",
       "41                                                 [0]  \n",
       "42                                              [0, 2]  \n",
       "43                                              [0, 1]  \n",
       "44   [40.0, 29.0, 46.0, 45.0, 39.0, 43.0, 47.0, 50....  \n",
       "45   [45.0, 46.0, 60.0, 198.0, 118.0, 44.0, 279.0, ...  \n",
       "46   [1515.0, 75.0, 406.0, 405.0, 586.0, 569.0, 759...  \n",
       "47   [44.558824, 37.5, 58.0, 57.85714300000001, 58....  \n",
       "48   [1.439511, 12.020814999999999, 5.291503, 5.669...  \n",
       "49                 [0.0, 36.0, 120.0, 94.0, 2.0, 44.0]  \n",
       "50   [0.0, 576.0, 850.0, 324.0, 711.0, 309.0, 40.0,...  \n",
       "51   [0.0, 850.0, 1124.0, 2168.0, 711.0, 309.0, 142...  \n",
       "52   [0.0, 212.5, 224.8, 141.666667, 83.384615, 237...  \n",
       "53   [0.0, 274.606992, 425.0, 239.401754, 239.34716...  \n",
       "54   [40.0, 29.0, 46.0, 45.0, 39.0, 43.0, 47.0, 50....  \n",
       "55   [45.0, 46.0, 60.0, 198.0, 118.0, 44.0, 576.0, ...  \n",
       "56   [1515.0, 75.0, 406.0, 405.0, 586.0, 569.0, 759...  \n",
       "57   [44.558824, 37.5, 58.0, 57.85714300000001, 58....  \n",
       "58   [1.439511, 12.020814999999999, 5.291503, 5.669...  \n",
       "59   [38684.129714999995, 3002430.915833, 5.0067900...  \n",
       "60   [2000760.07843, 3002430.915833, 207557.9166410...  \n",
       "61   [57262413.024902, 3002430.915833, 208293.91479...  \n",
       "62   [1735224.637118, 3002430.915833, 34715.652466,...  \n",
       "63   [642472.5112739999, 0.0, 84675.319676, 84982.5...  \n",
       "64   [0.0, 664.949417, 368.118286, 550.031662, 1080...  \n",
       "65   [0.0, 20202.875137, 20545.005798, 20215.034485...  \n",
       "66   [0.0, 21582.841872999998, 21459.102631, 21322....  \n",
       "67   [0.0, 7194.280623999999, 7153.03421, 7107.3373...  \n",
       "68   [0.0, 11265.80113, 11598.128549, 11351.5992599...  \n",
       "69   [38684.129714999995, 3002430.915833, 5.0067900...  \n",
       "70   [2000760.07843, 3002430.915833, 207557.9166410...  \n",
       "71   [57262413.024902, 3002430.915833, 208293.91479...  \n",
       "72   [1735224.637118, 3002430.915833, 34715.652466,...  \n",
       "73   [642472.5112739999, 0.0, 84675.319676, 84982.5...  \n",
       "74   [26.457146, 24.979759, 1949.1688, 1932.186233,...  \n",
       "75   [1.133333, 1.0, 7.0, 10.0, 13.0, 13.75, 1.0086...  \n",
       "76   [0.0, 4.0, 5.0, 1.0, 1.5, 2.0, 26.0, 3.0, 2.5,...  \n",
       "77   [50.5, 37.5, 406.0, 405.0, 586.0, 569.0, 759.0...  \n",
       "78   [0.0, 850.0, 1124.0, 283.333333, 2168.0, 711.0...  \n",
       "79   [0.0, 406.0, 405.0, 586.0, 569.0, 759.0, 763.0...  \n",
       "80   [0.0, 836.0, 20.0, 24.0, 28.0, 32.0, 36.0, 40....  \n",
       "81   [0.0, 7.0, 10.0, 13.0, 17.666667, 282.0, 286.0...  \n",
       "82   [0.0, 8.0, 5.0, 6.0, 7.0, 9.0, 10.0, 11.0, 17....  \n",
       "83   [0.0, 1949.1688, 1932.186233, 2818.109541, 274...  \n",
       "84   [0.0, 46924.251347000005, 51.213504, 51.780188...  \n",
       "85   [57262413.024902, 3002430.915833, 208293.91479...  \n",
       "86   [57262413.024902, 3002430.915833, 208293.91479...  \n",
       "87   [57262413.024902, 3002430.915833, 208293.91479...  \n",
       "88   [57262413.024902, 3002430.915833, 208293.91479...  \n",
       "89   [0.0, 181677.269011, 29231.199666000004, 41902...  \n",
       "90   [0.0, 8001144.170761, 5795279.026031, 5792163....  \n",
       "91   [0.0, 8001144.170761, 5795279.026031, 5792163....  \n",
       "92   [0.0, 8001144.170761, 5795279.026031, 5792163....  \n",
       "93   [0.0, 8001144.170761, 5795279.026031, 5792163....  \n",
       "94   [0.0, 10012.734441, 4270739.749407, 15102915.5...  \n",
       "95   [0, 1152, 64240, 301, 4584, 501, 1024, 1, 63, ...  \n",
       "96   [0, 65160, 507, 508, 501, 506, 64240, 502, 503...  \n",
       "97   [0, 302, 501, 1152, 4584, 301, 497, 500, 502, ...  \n",
       "98   [0, 507, 508, 501, 506, 510, 65160, 64240, 509...  \n",
       "99   [arpspoofing, slowread, rudeadyet, netscan, no...  \n",
       "100                                             [1, 0]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_information_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgb20-msN_XI"
   },
   "source": [
    "--------------------------------------------\n",
    "\n",
    "## Pre-processing and Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2L5yxSG6fxk"
   },
   "source": [
    "Split History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "byGEDcyWZtM7"
   },
   "outputs": [],
   "source": [
    "def count_letters(string, is_upper):\n",
    "    count = 0\n",
    "    \n",
    "    # Iterate through each character in the string\n",
    "    for c in string:\n",
    "        if is_upper and c.isupper():  # Check if the character is uppercase\n",
    "            count += 1\n",
    "        elif not is_upper and c.islower():  # Check if the character is lowercase\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IGQEQC_GbWZD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPLIT HISTORY] history_originator\n",
      "[SPLIT HISTORY] history_responder\n"
     ]
    }
   ],
   "source": [
    "print('[SPLIT HISTORY] history_originator')\n",
    "df['history_originator'] = df['history'].apply(lambda x: count_letters(x, True))\n",
    "\n",
    "print('[SPLIT HISTORY] history_responder')\n",
    "df['history_responder'] = df['history'].apply(lambda x: count_letters(x, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decimal Scale Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DECIMAL SCALE NORMALIZATION] flow_duration\n",
      "[DECIMAL SCALE NORMALIZATION] duration\n",
      "[DECIMAL SCALE NORMALIZATION] down_up_ratio\n"
     ]
    }
   ],
   "source": [
    "# Multiply by 1000 for a bigger scale\n",
    "print('[DECIMAL SCALE NORMALIZATION] flow_duration')\n",
    "df['flow_duration'] *= 1000\n",
    "\n",
    "# Multiply by 100 for a bigger scale\n",
    "print('[DECIMAL SCALE NORMALIZATION] duration')\n",
    "df['duration'] *= 100\n",
    "\n",
    "# Multiply by 10 for a bigger scale\n",
    "print('[DECIMAL SCALE NORMALIZATION] down_up_ratio')\n",
    "df['down_up_ratio'] *= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA NORMALIZATION] bwd_PSH_flag_count\n",
      "[DATA NORMALIZATION] bwd_data_pkts_tot\n"
     ]
    }
   ],
   "source": [
    "# Update values in 'bwd_PSH_flag_count' column if they are higher than 4\n",
    "print('[DATA NORMALIZATION] bwd_PSH_flag_count')\n",
    "df.loc[df['bwd_PSH_flag_count'] > 4, 'bwd_PSH_flag_count'] = 5\n",
    "\n",
    "# Update values in 'bwd_data_pkts_tot' column if they are higher than 3\n",
    "print('[DATA NORMALIZATION] bwd_data_pkts_tot')\n",
    "df.loc[df['bwd_data_pkts_tot'] > 3, 'bwd_data_pkts_tot'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSbkiI6JD6vO"
   },
   "source": [
    "Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df,columns,n_std):\n",
    "    for col in columns:\n",
    "        print(f'[REMOVED OUTLIERS] {col}')\n",
    "        \n",
    "        mean = df[col].mean()\n",
    "        sd = df[col].std()\n",
    "        \n",
    "        df = df[(df[col] <= mean+(n_std*sd))]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7G5NkFuBD8lM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REMOVED OUTLIERS] resp_ip_bytes\n",
      "[REMOVED OUTLIERS] orig_pkts\n",
      "[REMOVED OUTLIERS] flow_duration\n",
      "[REMOVED OUTLIERS] duration\n",
      "[REMOVED OUTLIERS] bwd_pkts_tot\n",
      "[REMOVED OUTLIERS] bwd_pkts_payload.avg\n",
      "[REMOVED OUTLIERS] bwd_header_size_tot\n",
      "[REMOVED OUTLIERS] resp_pkts\n"
     ]
    }
   ],
   "source": [
    "outliers = [\n",
    "    'resp_ip_bytes',\n",
    "    'orig_pkts',\n",
    "    'flow_duration',\n",
    "    'duration',\n",
    "    'bwd_pkts_tot',\n",
    "    'bwd_pkts_payload.avg',\n",
    "    'bwd_header_size_tot',\n",
    "    'resp_pkts',\n",
    "]\n",
    "\n",
    "df = remove_outliers(df, outliers, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6MG8V_sC7y3"
   },
   "source": [
    "One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "psGbkLKcFqA_"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(df, columns):\n",
    "    for col in columns:\n",
    "        print(f'[ONE HOT ENCODING] {col}')\n",
    "        df = pd.get_dummies(df, columns=[col], prefix=col)  # Perform one-hot encoding on the column\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoAIe3cv9mE-",
    "outputId": "55a1eb68-aac9-4987-87f3-1e3dbbca521e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONE HOT ENCODING] proto\n",
      "[ONE HOT ENCODING] local_resp\n",
      "[ONE HOT ENCODING] local_orig\n",
      "[ONE HOT ENCODING] fwd_header_size_min\n",
      "[ONE HOT ENCODING] fwd_header_size_max\n",
      "[ONE HOT ENCODING] flow_SYN_flag_count\n",
      "[ONE HOT ENCODING] flow_RST_flag_count\n",
      "[ONE HOT ENCODING] flow_FIN_flag_count\n",
      "[ONE HOT ENCODING] conn_state\n",
      "[ONE HOT ENCODING] bwd_PSH_flag_count\n",
      "[ONE HOT ENCODING] bwd_header_size_min\n",
      "[ONE HOT ENCODING] bwd_header_size_max\n",
      "[ONE HOT ENCODING] resp_pkts\n"
     ]
    }
   ],
   "source": [
    "cols_to_encode = [\n",
    "    'proto',\n",
    "    'local_resp',\n",
    "    'local_orig',\n",
    "    'fwd_header_size_min',\n",
    "    'fwd_header_size_max',\n",
    "    'flow_SYN_flag_count',\n",
    "    'flow_RST_flag_count',\n",
    "    'flow_FIN_flag_count',\n",
    "    'conn_state',\n",
    "    'bwd_PSH_flag_count',\n",
    "    'bwd_header_size_min',\n",
    "    'bwd_header_size_max',\n",
    "    'resp_pkts',\n",
    "]\n",
    "\n",
    "df = one_hot_encoding(df,cols_to_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsIbHSu0N_XK"
   },
   "source": [
    "Normalize, Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "s68skGdoN_XK"
   },
   "outputs": [],
   "source": [
    "def zscore_normalization(df, cols):\n",
    "    # Standardize the selected columns\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"[WARNING] {col} not found in DataFrame.\")\n",
    "            continue\n",
    "        print(f\"[Z-SCORE] {col}\")\n",
    "        df[col] = zscore(df[col])\n",
    "    \n",
    "    print(\"[DONE] Z-score Normalization\")\n",
    "    print(\"[INFO] Current Fields in the DataFrame:\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "nQdNGsJ-N_XK",
    "outputId": "3721d8a8-a9a0-491f-ddd1-da08e37c1e89",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Z-SCORE] resp_ip_bytes\n",
      "[Z-SCORE] resp_bytes\n",
      "[Z-SCORE] payload_bytes_per_second\n",
      "[Z-SCORE] orig_pkts\n",
      "[Z-SCORE] orig_ip_bytes\n",
      "[Z-SCORE] orig_bytes\n",
      "[Z-SCORE] fwd_subflow_pkts\n",
      "[Z-SCORE] fwd_subflow_bytes\n",
      "[Z-SCORE] fwd_PSH_flag_count\n",
      "[Z-SCORE] fwd_pkts_tot\n",
      "[Z-SCORE] fwd_pkts_per_sec\n",
      "[Z-SCORE] fwd_pkts_payload.tot\n",
      "[Z-SCORE] fwd_pkts_payload.std\n",
      "[Z-SCORE] fwd_pkts_payload.min\n",
      "[Z-SCORE] fwd_pkts_payload.max\n",
      "[Z-SCORE] fwd_pkts_payload.avg\n",
      "[Z-SCORE] fwd_last_window_size\n",
      "[Z-SCORE] fwd_init_window_size\n",
      "[Z-SCORE] fwd_iat.tot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:2419: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Z-SCORE] fwd_iat.std\n",
      "[Z-SCORE] fwd_iat.min\n",
      "[Z-SCORE] fwd_iat.max\n",
      "[Z-SCORE] fwd_iat.avg\n",
      "[Z-SCORE] fwd_header_size_tot\n",
      "[Z-SCORE] fwd_data_pkts_tot\n",
      "[Z-SCORE] fwd_bulk_bytes\n",
      "[Z-SCORE] flow_pkts_per_sec\n",
      "[Z-SCORE] flow_pkts_payload.tot\n",
      "[Z-SCORE] flow_pkts_payload.std\n",
      "[Z-SCORE] flow_pkts_payload.min\n",
      "[Z-SCORE] flow_pkts_payload.max\n",
      "[Z-SCORE] flow_pkts_payload.avg\n",
      "[Z-SCORE] flow_iat.tot\n",
      "[Z-SCORE] flow_iat.std\n",
      "[Z-SCORE] flow_iat.min\n",
      "[Z-SCORE] flow_iat.max\n",
      "[Z-SCORE] flow_iat.avg\n",
      "[Z-SCORE] flow_duration\n",
      "[Z-SCORE] flow_ACK_flag_count\n",
      "[Z-SCORE] duration\n",
      "[Z-SCORE] down_up_ratio\n",
      "[Z-SCORE] bwd_subflow_pkts\n",
      "[Z-SCORE] bwd_subflow_bytes\n",
      "[Z-SCORE] bwd_pkts_tot\n",
      "[Z-SCORE] bwd_pkts_per_sec\n",
      "[Z-SCORE] bwd_pkts_payload.tot\n",
      "[Z-SCORE] bwd_pkts_payload.std\n",
      "[Z-SCORE] bwd_pkts_payload.max\n",
      "[Z-SCORE] bwd_pkts_payload.avg\n",
      "[Z-SCORE] bwd_last_window_size\n",
      "[Z-SCORE] bwd_init_window_size\n",
      "[Z-SCORE] bwd_iat.tot\n",
      "[Z-SCORE] bwd_iat.min\n",
      "[Z-SCORE] bwd_iat.max\n",
      "[Z-SCORE] bwd_iat.avg\n",
      "[Z-SCORE] bwd_header_size_tot\n",
      "[Z-SCORE] active.tot\n",
      "[Z-SCORE] active.min\n",
      "[Z-SCORE] active.max\n",
      "[Z-SCORE] active.avg\n",
      "[DONE] Z-score Normalization\n",
      "[INFO] Current Fields in the DataFrame:\n"
     ]
    }
   ],
   "source": [
    "cols_to_zscore = [\n",
    "    'resp_ip_bytes',\n",
    "    'resp_bytes',\n",
    "    'payload_bytes_per_second',\n",
    "    'orig_pkts',\n",
    "    'orig_ip_bytes',\n",
    "    'orig_bytes',\n",
    "    'fwd_subflow_pkts',\n",
    "    'fwd_subflow_bytes',\n",
    "    'fwd_PSH_flag_count',\n",
    "    'fwd_pkts_tot',\n",
    "    'fwd_pkts_per_sec',\n",
    "    'fwd_pkts_payload.tot',\n",
    "    'fwd_pkts_payload.std',\n",
    "    'fwd_pkts_payload.min',\n",
    "    'fwd_pkts_payload.max',\n",
    "    'fwd_pkts_payload.avg',\n",
    "    'fwd_last_window_size',\n",
    "    'fwd_init_window_size',\n",
    "    'fwd_iat.tot',\n",
    "    'fwd_iat.std',\n",
    "    'fwd_iat.min',\n",
    "    'fwd_iat.max', \n",
    "    'fwd_iat.avg',\n",
    "    'fwd_header_size_tot',\n",
    "    'fwd_data_pkts_tot',\n",
    "    'fwd_bulk_bytes',\n",
    "    'flow_pkts_per_sec',\n",
    "    'flow_pkts_payload.tot',\n",
    "    'flow_pkts_payload.std',\n",
    "    'flow_pkts_payload.min',\n",
    "    'flow_pkts_payload.max',\n",
    "    'flow_pkts_payload.avg',\n",
    "    'flow_iat.tot',\n",
    "    'flow_iat.std',\n",
    "    'flow_iat.min',\n",
    "    'flow_iat.max',\n",
    "    'flow_iat.avg',\n",
    "    'flow_duration',\n",
    "    'flow_ACK_flag_count',\n",
    "    'duration',\n",
    "    'down_up_ratio',\n",
    "    'bwd_subflow_pkts',\n",
    "    'bwd_subflow_bytes',\n",
    "    'bwd_pkts_tot',\n",
    "    'bwd_pkts_per_sec',\n",
    "    'bwd_pkts_payload.tot',\n",
    "    'bwd_pkts_payload.std',\n",
    "    'bwd_pkts_payload.max',\n",
    "    'bwd_pkts_payload.avg',\n",
    "    'bwd_last_window_size',\n",
    "    'bwd_init_window_size',\n",
    "    'bwd_iat.tot',\n",
    "    'bwd_iat.min',\n",
    "    'bwd_iat.max',\n",
    "    'bwd_iat.avg',\n",
    "    'bwd_header_size_tot',\n",
    "    'active.tot',\n",
    "    'active.min',\n",
    "    'active.max',\n",
    "    'active.avg',    \n",
    "]\n",
    "\n",
    "df = zscore_normalization(df, cols_to_zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paLhEkkLN_XK"
   },
   "source": [
    "Delete Insignificant Columns from the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gM8kKWVhN_XK"
   },
   "outputs": [],
   "source": [
    "def delete_columns(df, cols):\n",
    "    for col in cols:\n",
    "        df.drop(col, axis = 1, inplace = True)\n",
    "        print(f'[REMOVED] {col}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LC6qBPhN_XK",
    "outputId": "ae158dcd-20b4-4f09-9bf6-63e4ba623aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REMOVED] tunnel_parents\n",
      "[REMOVED] service\n",
      "[REMOVED] missed_bytes\n",
      "[REMOVED] idle.tot\n",
      "[REMOVED] idle.std\n",
      "[REMOVED] idle.min\n",
      "[REMOVED] idle.max\n",
      "[REMOVED] idle.avg\n",
      "[REMOVED] fwd_URG_flag_count\n",
      "[REMOVED] fwd_bulk_rate\n",
      "[REMOVED] fwd_bulk_packets\n",
      "[REMOVED] flow_ECE_flag_count\n",
      "[REMOVED] flow_CWR_flag_count\n",
      "[REMOVED] bwd_URG_flag_count\n",
      "[REMOVED] bwd_pkts_payload.min\n",
      "[REMOVED] bwd_iat.std\n",
      "[REMOVED] bwd_bulk_rate\n",
      "[REMOVED] bwd_bulk_packets\n",
      "[REMOVED] bwd_bulk_bytes\n",
      "[REMOVED] active.std\n",
      "[REMOVED] id.orig_h\n",
      "[REMOVED] id.orig_p\n",
      "[REMOVED] id.resp_h\n",
      "[REMOVED] id.resp_p\n",
      "[REMOVED] history\n"
     ]
    }
   ],
   "source": [
    "cols_to_del = [\n",
    "    'tunnel_parents',\n",
    "    'service',\n",
    "    'missed_bytes',\n",
    "    'idle.tot',\n",
    "    'idle.std',\n",
    "    'idle.min',\n",
    "    'idle.max',\n",
    "    'idle.avg',\n",
    "    'fwd_URG_flag_count',\n",
    "    'fwd_bulk_rate',\n",
    "    'fwd_bulk_packets',\n",
    "    'flow_ECE_flag_count',\n",
    "    'flow_CWR_flag_count',\n",
    "    'bwd_URG_flag_count',\n",
    "    'bwd_pkts_payload.min',\n",
    "    'bwd_iat.std',\n",
    "    'bwd_bulk_rate',\n",
    "    'bwd_bulk_packets',\n",
    "    'bwd_bulk_bytes',\n",
    "    'active.std',\n",
    "    'id.orig_h',\n",
    "    'id.orig_p',\n",
    "    'id.resp_h',\n",
    "    'id.resp_p',\n",
    "    'history',\n",
    "]\n",
    "\n",
    "df = delete_columns(df,cols_to_del)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcHY3Kk_N_XN"
   },
   "source": [
    "---------------------------------------\n",
    "\n",
    "## Create Model & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "j9A5Vaq8Naa2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0          3\n",
       "1    1597187\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['traffic'].apply(lambda x: 0 if x == \"normal\" else 1)\n",
    "df.groupby('label')['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REMOVED] traffic\n"
     ]
    }
   ],
   "source": [
    "df = delete_columns(df,['traffic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "g7ExpPs6N_XN"
   },
   "outputs": [],
   "source": [
    "x_columns = df.columns.drop('label')\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df[\"label\"].values)\n",
    "\n",
    "x = df[x_columns].values\n",
    "y = df[\"label\"].values\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "x_train_train, x_test_train, y_train_train, y_test_train = train_test_split(x_train, y_train, test_size=0.25, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((399298, 105), (399298,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1197892, 105), (1197892,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "kmWyRAR0N_XN",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1197892 samples, validate on 399298 samples\n",
      "Epoch 1/100\n",
      "1197892/1197892 [==============================] - 6s 5us/sample - loss: 0.0336 - accuracy: 0.9996 - val_loss: 2.3100e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.9092e-04 - accuracy: 1.0000 - val_loss: 4.7007e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1197892/1197892 [==============================] - 5s 5us/sample - loss: 7.9712e-05 - accuracy: 1.0000 - val_loss: 3.4816e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.9281e-05 - accuracy: 1.0000 - val_loss: 3.7018e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.0823e-05 - accuracy: 1.0000 - val_loss: 4.0239e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.3285e-05 - accuracy: 1.0000 - val_loss: 4.2908e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.5341e-05 - accuracy: 1.0000 - val_loss: 4.4136e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.0084e-05 - accuracy: 1.0000 - val_loss: 4.5870e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.4332e-05 - accuracy: 1.0000 - val_loss: 4.7171e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.6110e-05 - accuracy: 1.0000 - val_loss: 4.8614e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.7003e-05 - accuracy: 1.0000 - val_loss: 4.9669e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.5732e-05 - accuracy: 1.0000 - val_loss: 4.9926e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1184768/1197892 [============================>.] - ETA: 0s - loss: 3.0037e-05 - accuracy: 1.0000\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.9715e-05 - accuracy: 1.0000 - val_loss: 4.9627e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.4701e-05 - accuracy: 1.0000 - val_loss: 4.9119e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.5650e-05 - accuracy: 1.0000 - val_loss: 4.9124e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.2535e-05 - accuracy: 1.0000 - val_loss: 4.8667e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.5660e-05 - accuracy: 1.0000 - val_loss: 4.9323e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.8633e-05 - accuracy: 1.0000 - val_loss: 4.9609e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.0438e-05 - accuracy: 1.0000 - val_loss: 4.9056e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.3982e-05 - accuracy: 1.0000 - val_loss: 4.9262e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.3421e-05 - accuracy: 1.0000 - val_loss: 4.8951e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.2833e-05 - accuracy: 1.0000 - val_loss: 4.8946e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1194496/1197892 [============================>.] - ETA: 0s - loss: 3.4732e-05 - accuracy: 1.0000\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.4635e-05 - accuracy: 1.0000 - val_loss: 4.9195e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.6215e-05 - accuracy: 1.0000 - val_loss: 4.9966e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.0587e-05 - accuracy: 1.0000 - val_loss: 5.0256e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.0132e-05 - accuracy: 1.0000 - val_loss: 5.0475e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.3309e-05 - accuracy: 1.0000 - val_loss: 5.0200e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.2963e-05 - accuracy: 1.0000 - val_loss: 5.0003e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.4177e-05 - accuracy: 1.0000 - val_loss: 4.9711e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.1718e-05 - accuracy: 1.0000 - val_loss: 4.9687e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.8410e-05 - accuracy: 1.0000 - val_loss: 4.9784e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.4499e-05 - accuracy: 1.0000 - val_loss: 5.0133e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1190400/1197892 [============================>.] - ETA: 0s - loss: 2.6418e-05 - accuracy: 1.0000\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.6258e-05 - accuracy: 1.0000 - val_loss: 5.1027e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.9227e-05 - accuracy: 1.0000 - val_loss: 5.1429e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.4255e-05 - accuracy: 1.0000 - val_loss: 5.1452e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.1138e-05 - accuracy: 1.0000 - val_loss: 5.1464e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.7043e-05 - accuracy: 1.0000 - val_loss: 5.1511e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.3834e-05 - accuracy: 1.0000 - val_loss: 5.1272e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.9671e-05 - accuracy: 1.0000 - val_loss: 5.1126e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.9622e-05 - accuracy: 1.0000 - val_loss: 5.1086e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.4177e-05 - accuracy: 1.0000 - val_loss: 5.0765e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.0933e-05 - accuracy: 1.0000 - val_loss: 5.0608e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1197568/1197892 [============================>.] - ETA: 0s - loss: 2.7722e-05 - accuracy: 1.0000\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.7715e-05 - accuracy: 1.0000 - val_loss: 5.0625e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.9503e-05 - accuracy: 1.0000 - val_loss: 5.0855e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.4889e-05 - accuracy: 1.0000 - val_loss: 5.0934e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.6790e-05 - accuracy: 1.0000 - val_loss: 5.0957e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.3472e-05 - accuracy: 1.0000 - val_loss: 5.0905e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.7749e-05 - accuracy: 1.0000 - val_loss: 5.0867e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.2087e-05 - accuracy: 1.0000 - val_loss: 5.0793e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.0371e-05 - accuracy: 1.0000 - val_loss: 5.0638e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.5893e-05 - accuracy: 1.0000 - val_loss: 5.0508e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.2877e-05 - accuracy: 1.0000 - val_loss: 5.0437e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1191936/1197892 [============================>.] - ETA: 0s - loss: 3.5861e-05 - accuracy: 1.0000\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.5686e-05 - accuracy: 1.0000 - val_loss: 5.0367e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.6093e-05 - accuracy: 1.0000 - val_loss: 5.0344e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.8219e-05 - accuracy: 1.0000 - val_loss: 5.0354e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.0150e-05 - accuracy: 1.0000 - val_loss: 5.0394e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.4572e-05 - accuracy: 1.0000 - val_loss: 5.0507e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1197892/1197892 [==============================] - 5s 5us/sample - loss: 3.3835e-05 - accuracy: 1.0000 - val_loss: 5.0540e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.8975e-05 - accuracy: 1.0000 - val_loss: 5.0489e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.8134e-05 - accuracy: 1.0000 - val_loss: 5.0524e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.6485e-05 - accuracy: 1.0000 - val_loss: 5.0502e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1197892/1197892 [==============================] - 7s 5us/sample - loss: 3.7455e-05 - accuracy: 1.0000 - val_loss: 5.0456e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1194496/1197892 [============================>.] - ETA: 0s - loss: 3.9098e-05 - accuracy: 1.0000\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1197892/1197892 [==============================] - 6s 5us/sample - loss: 3.8988e-05 - accuracy: 1.0000 - val_loss: 5.0399e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1197892/1197892 [==============================] - 6s 5us/sample - loss: 2.7445e-05 - accuracy: 1.0000 - val_loss: 5.0384e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1197892/1197892 [==============================] - 6s 5us/sample - loss: 3.9721e-05 - accuracy: 1.0000 - val_loss: 5.0359e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1197892/1197892 [==============================] - 6s 5us/sample - loss: 3.3566e-05 - accuracy: 1.0000 - val_loss: 5.0395e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.2329e-05 - accuracy: 1.0000 - val_loss: 5.0379e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1197892/1197892 [==============================] - 6s 5us/sample - loss: 4.5747e-05 - accuracy: 1.0000 - val_loss: 5.0339e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1197892/1197892 [==============================] - 7s 6us/sample - loss: 3.2958e-05 - accuracy: 1.0000 - val_loss: 5.0319e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1197892/1197892 [==============================] - 7s 5us/sample - loss: 3.4541e-05 - accuracy: 1.0000 - val_loss: 5.0303e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1197892/1197892 [==============================] - 8s 7us/sample - loss: 3.3961e-05 - accuracy: 1.0000 - val_loss: 5.0291e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1197892/1197892 [==============================] - 8s 6us/sample - loss: 3.1926e-05 - accuracy: 1.0000 - val_loss: 5.0285e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1197568/1197892 [============================>.] - ETA: 0s - loss: 3.8926e-05 - accuracy: 1.0000\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "1197892/1197892 [==============================] - 7s 6us/sample - loss: 3.8916e-05 - accuracy: 1.0000 - val_loss: 5.0291e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1197892/1197892 [==============================] - 7s 6us/sample - loss: 3.2367e-05 - accuracy: 1.0000 - val_loss: 5.0295e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1197892/1197892 [==============================] - 7s 6us/sample - loss: 4.1998e-05 - accuracy: 1.0000 - val_loss: 5.0292e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.8745e-05 - accuracy: 1.0000 - val_loss: 5.0293e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.6194e-05 - accuracy: 1.0000 - val_loss: 5.0296e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.8300e-05 - accuracy: 1.0000 - val_loss: 5.0297e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.2617e-05 - accuracy: 1.0000 - val_loss: 5.0301e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.2323e-05 - accuracy: 1.0000 - val_loss: 5.0297e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.6524e-05 - accuracy: 1.0000 - val_loss: 5.0297e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.5834e-05 - accuracy: 1.0000 - val_loss: 5.0299e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1187328/1197892 [============================>.] - ETA: 0s - loss: 3.2142e-05 - accuracy: 1.0000\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.1864e-05 - accuracy: 1.0000 - val_loss: 5.0294e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.0647e-05 - accuracy: 1.0000 - val_loss: 5.0291e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.5628e-05 - accuracy: 1.0000 - val_loss: 5.0297e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.1010e-05 - accuracy: 1.0000 - val_loss: 5.0301e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.0545e-05 - accuracy: 1.0000 - val_loss: 5.0300e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.2778e-05 - accuracy: 1.0000 - val_loss: 5.0290e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.7210e-05 - accuracy: 1.0000 - val_loss: 5.0289e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.4121e-05 - accuracy: 1.0000 - val_loss: 5.0281e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.8199e-05 - accuracy: 1.0000 - val_loss: 5.0274e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.1949e-05 - accuracy: 1.0000 - val_loss: 5.0269e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188864/1197892 [============================>.] - ETA: 0s - loss: 3.8218e-05 - accuracy: 1.0000\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.7936e-05 - accuracy: 1.0000 - val_loss: 5.0264e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 4.4558e-05 - accuracy: 1.0000 - val_loss: 5.0256e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.7995e-05 - accuracy: 1.0000 - val_loss: 5.0251e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.1917e-05 - accuracy: 1.0000 - val_loss: 5.0249e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.0460e-05 - accuracy: 1.0000 - val_loss: 5.0245e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 2.9114e-05 - accuracy: 1.0000 - val_loss: 5.0243e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.8151e-05 - accuracy: 1.0000 - val_loss: 5.0239e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1197892/1197892 [==============================] - 5s 4us/sample - loss: 3.8909e-05 - accuracy: 1.0000 - val_loss: 5.0234e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# Define early stopping\n",
    "monitor = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor=0.5,mode=\"min\",patience=10,verbose=1,min_lr=1e-7)\n",
    "checkpoint = ModelCheckpoint('best_model_binary.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=512, callbacks=[monitor, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399298/399298 [==============================] - 9s 21us/sample - loss: 3.4816e-05 - accuracy: 1.0000\n",
      "\n",
      "Test loss: 3.481584254011746e-05\n",
      "Test accuracy: 0.9999975\n"
     ]
    }
   ],
   "source": [
    "# Load the best saved model\n",
    "best_model = load_model('best_model_binary.h5')\n",
    "\n",
    "# Evaluate the best saved model\n",
    "score = best_model.evaluate(x_test, y_test)\n",
    "print('')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               27136     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 72,321\n",
      "Trainable params: 71,361\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 16))\n",
    "\n",
    "ax.plot(history.history['loss'], label='train')\n",
    "ax.plot(history.history['val_loss'], label='test')\n",
    "ax.set_title('Model Loss')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hVv8L2EN_XN",
    "outputId": "6d8a189e-7051-42a6-dd0d-b626eb55d212"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "zjwPGzH7cXls"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def calculate_metrics(modelName, yTrue, yPred, average='binary'):\n",
    "    \"\"\"\n",
    "    Calculate and print the performance metrics of a classification model.\n",
    "    \n",
    "    Parameters:\n",
    "    modelName (str): The name of the classification model.\n",
    "    yTrue (array-like): The true labels.\n",
    "    yPred (array-like): The predicted labels.\n",
    "    average (str or None, optional): The averaging method to use for multi-class classification. One of \n",
    "        {'micro', 'macro', 'weighted', 'binary'} or None (default: 'binary'). If None, only binary \n",
    "        classification metrics will be computed.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If `average` is not one of {'micro', 'macro', 'weighted', 'binary'} or None.\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Check if average parameter is valid\n",
    "    if average != 'micro' and average != 'macro' and average != 'weighted' and average != 'binary' and average != None:\n",
    "        print(\"Average must be one of this options: {â€˜microâ€™, â€˜macroâ€™, â€˜samplesâ€™, â€˜weightedâ€™, â€˜binaryâ€™} or None, default=â€™binaryâ€™\")\n",
    "        return\n",
    "    \n",
    "    # Prints the name of the model and calculate accuracy and precision\n",
    "    print(f\"--- Performance of {modelName} ---\")\n",
    "    acc = accuracy_score(y_true = yTrue, y_pred = yPred)\n",
    "    precision = precision_score(y_true = yTrue, y_pred = yPred, average = average)\n",
    "    print(f'Accuracy : {np.round(acc*100,2)}%\\nPrecision: {np.round(precision*100,2)}%')\n",
    "    \n",
    "    # Calculates and print recall and F1-score\n",
    "    f1 = f1_score(y_true = yTrue, y_pred = yPred, average = average)\n",
    "    recall = recall_score(y_true = yTrue, y_pred = yPred, average = average)\n",
    "    print(f'Recall: {np.round(recall*100,2)}%\\nF1-score: {np.round(f1*100,2)}%')\n",
    "    \n",
    "    #auc_sklearn = roc_auc_score(y_true = yTrue, y_score = yPred, average = average)\n",
    "    #print(f'Roc auc: {np.round(auc_sklearn*100,2)}%')\n",
    "    \n",
    "    # Calculates and prints balanced accuracy and classification report\n",
    "    print(f\"Balanced accuracy: {np.round(balanced_accuracy_score(yTrue, yPred)*100,2)}%\")\n",
    "    print(f\"Classification report:\\n{classification_report(yTrue, yPred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "7opqgASr6fxn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance of Binary - DNN ---\n",
      "Accuracy : 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1-score: 100.0%\n",
      "Balanced accuracy: 50.0%\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      1.00      1.00    399297\n",
      "\n",
      "    accuracy                           1.00    399298\n",
      "   macro avg       0.50      0.50      0.50    399298\n",
      "weighted avg       1.00      1.00      1.00    399298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/project/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/project/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred = np.round(pred).astype(int)\n",
    "calculate_metrics(\"Binary - DNN\", y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ihn2qm186fxn"
   },
   "source": [
    "-------------------------------------\n",
    "\n",
    "**Result Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "7oqLlxmicPrp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f7b3f324cf8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "y_pred = np.round(pred).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "cmd = ConfusionMatrixDisplay(cm)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cmd.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_za--boceRr9"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-cd0574415741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Usage of ExtraTreesClassifier for feature selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mextra_tree_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mextra_tree_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfeature_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_tree_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeature_importance_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mextra_tree_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    303\u001b[0m             )\n\u001b[1;32m    304\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0;32m--> 305\u001b[0;31m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    876\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    879\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 721\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n\u001b[0;32m--> 106\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    107\u001b[0m             )\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# Usage of ExtraTreesClassifier for feature selection\n",
    "extra_tree_forest = ExtraTreesClassifier(n_estimators = 5, criterion ='entropy', max_features = 2)\n",
    "extra_tree_forest.fit(x, y)\n",
    "feature_importance = extra_tree_forest.feature_importances_\n",
    "feature_importance_normalized = np.std([tree.feature_importances_ for tree in  extra_tree_forest.estimators_], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBfWThvfeTNB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plor for the ExtraTreesClassifier output\n",
    "plot.bar(x_columns, feature_importance_normalized)\n",
    "plot.xlabel('Feature Labels')\n",
    "plot.ylabel('Feature Importances')\n",
    "plot.title('Comparison of different feature importances in the current dataset')\n",
    "plot.xticks(rotation = 90)\n",
    "\n",
    "# Plot size\n",
    "plot.rcParams[\"figure.figsize\"] = (70, 40)\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
